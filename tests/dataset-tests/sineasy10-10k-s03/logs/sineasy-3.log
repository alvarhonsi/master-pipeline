Start time: 2023-07-04 16:23:21.730552
torch.Size([512, 50]) torch.Size([512, 1])
Sequential(
  (0): Linear(in_features=50, out_features=256, bias=True)
  (1): ReLU()
  (2): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ReLU()
  )
  (3): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ReLU()
  )
  (4): Linear(in_features=256, out_features=1, bias=True)
)
Settings:
DEVICE: cuda:6 INFERENCE_TYPE: svi OBS_MODEL: homoskedastic PRIOR_LOC: 0.0 PRIOR_SCALE: 1.0 LIKELIHOOD_SCALE_LOC: 2.0 LIKELIHOOD_SCALE: 0.3 GUIDE_SCALE: 0.001 TRAIN_SIZE: 20000
Initial parameters:
net_guide.net.0.weight.loc torch.Size([256, 50]) Parameter containing:
tensor([[-0.8841, -0.3310,  0.2433,  ..., -0.5751,  0.1403,  0.2833],
        [-0.0484, -0.0976,  0.1658,  ...,  0.1114, -0.3735, -0.2614],
        [ 0.2796,  0.2313, -0.2709,  ...,  0.0893, -0.4052, -0.2016],
        ...,
        [ 0.5293,  0.1661, -0.2596,  ..., -0.0449,  0.3339,  0.1499],
        [ 0.4339, -0.1121, -0.1852,  ..., -0.4379,  0.3863, -0.3459],
        [-0.1052, -0.3027,  0.0624,  ..., -0.0029, -0.1554, -0.2649]],
       device='cuda:6', requires_grad=True)
net_guide.net.0.weight.scale torch.Size([256, 50]) tensor([[0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        ...,
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]],
       device='cuda:6', grad_fn=<AddBackward0>)
net_guide.net.0.bias.loc torch.Size([256]) Parameter containing:
tensor([ 0.1808,  0.2072, -0.1410,  0.4894, -0.3253, -0.1646,  0.0148, -0.2414,
        -0.0640, -0.0407,  0.4542, -0.3674, -0.0800,  0.0619, -0.1602, -0.1347,
         0.1899,  0.1102,  0.0356,  0.1179, -0.4228,  0.3879, -0.2977,  0.6713,
        -0.2760, -0.6059,  0.3318,  0.3874,  0.0160,  0.4944,  0.0913, -0.5037,
        -0.0163,  0.4074,  0.2410, -0.0671,  0.3606,  0.0601,  0.1219,  0.5330,
        -0.5109, -0.2017,  0.1128, -0.2916,  0.1578,  0.1028,  0.0374, -0.4269,
        -0.7732,  0.5134,  0.2178, -0.0087, -0.0624,  0.2019, -0.3059,  0.2927,
        -0.1671,  0.0478,  0.2770, -0.0516, -0.7641, -0.1987, -0.4100, -0.1566,
        -0.0817, -0.6643,  0.8917, -0.1001,  0.2535,  0.4653,  0.0624,  0.0505,
        -0.0364, -0.0860,  0.0181, -0.5751,  0.2350,  0.3260,  0.0467, -0.2812,
        -0.0196, -0.1194,  0.1288, -0.2144,  0.0645, -0.0824, -0.2515,  0.2654,
        -0.4673,  0.1168, -0.0902, -0.4612, -0.0683, -0.2047,  0.2091, -1.1466,
        -0.1188, -0.0920, -0.3626, -0.1977, -0.0402,  0.0628, -0.0239,  0.3816,
         0.1951,  0.4365,  0.0251, -0.2751, -0.1447,  0.2382,  0.1976, -0.0905,
        -0.2822, -0.1971,  0.2971,  0.1530, -0.2381, -0.1076, -0.2768,  0.1486,
         0.2610, -0.1988, -0.2826, -0.1682,  0.2142,  0.1369,  0.2269,  0.1766,
         0.4503,  0.1435, -0.0472,  0.1221,  0.3567,  0.2918,  0.1171, -0.4205,
         0.0892,  0.0410,  0.1389, -0.3964,  0.1851, -0.2142,  0.5895,  0.1621,
        -0.1516,  0.6712,  0.3656, -0.4191, -0.0854, -0.1078,  0.1904,  0.2177,
         0.0178,  0.0230, -0.0289, -0.0852,  0.2989, -0.0068, -0.0210, -0.5412,
        -0.1298,  0.0214, -0.0204,  0.3805,  0.0395,  0.1694,  0.7563,  0.5016,
         0.0105, -0.0731, -0.7493, -0.5928,  0.2714, -0.0930,  0.6040,  0.3521,
        -0.0262, -0.3736, -0.0726,  0.1446,  0.3284,  0.0992, -0.1595,  0.0018,
         0.0276, -0.0477, -0.2306, -0.0836, -0.1678,  0.0304,  0.2597,  0.0761,
        -0.3537, -0.1245,  0.0470,  0.2726, -0.3536, -0.1341,  0.4765,  0.7599,
        -0.2855, -0.1128, -0.6463,  0.6039, -0.1104,  0.0775, -0.0490,  0.1011,
         0.2289,  0.0957, -0.2523,  0.2732,  0.0756, -0.3211, -0.0557,  0.7312,
         0.0958,  0.1503,  0.0734, -0.1828, -0.1024, -0.1352, -0.3337, -0.6127,
        -0.3475, -0.4207,  0.1432, -0.4627, -0.1973,  0.5449, -0.0115,  0.2209,
        -0.6152,  0.4231,  0.1231, -0.1828, -0.0989,  0.3440,  0.0215, -0.0226,
        -0.3661,  0.6027, -0.4107,  0.7247, -0.2721, -0.0965, -0.2606, -0.4208,
        -0.1486, -0.2558,  0.4621, -0.0705,  0.5264, -0.0977, -0.6471, -0.0293],
       device='cuda:6', requires_grad=True)
net_guide.net.0.bias.scale torch.Size([256]) tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010], device='cuda:6',
       grad_fn=<AddBackward0>)
net_guide.net.2.0.weight.loc torch.Size([256, 256]) Parameter containing:
tensor([[ 0.6745, -0.7163,  0.3276,  ...,  0.3328,  0.2146,  0.3863],
        [ 0.1202, -0.1988,  0.1877,  ...,  0.1566,  0.2621, -0.0196],
        [-0.4870, -0.1207,  0.1080,  ...,  0.2727, -0.1179, -0.0206],
        ...,
        [ 0.1116,  0.2292, -0.3400,  ..., -0.2764,  0.1744,  0.3254],
        [-0.5692,  0.1569,  0.1173,  ..., -0.0533,  0.0217,  0.0994],
        [-0.0499,  0.1291, -0.2275,  ..., -0.5182, -0.0191, -0.0715]],
       device='cuda:6', requires_grad=True)
net_guide.net.2.0.weight.scale torch.Size([256, 256]) tensor([[0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        ...,
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]],
       device='cuda:6', grad_fn=<AddBackward0>)
net_guide.net.2.0.bias.loc torch.Size([256]) Parameter containing:
tensor([-9.6402e-02, -2.3631e-01,  4.5208e-02, -5.3503e-02, -1.9014e-01,
        -9.4313e-02,  2.3823e-01,  3.5397e-01, -8.6376e-02, -3.1167e-01,
         5.9432e-01, -1.6344e-01,  4.0904e-01,  1.5255e-01,  1.0933e-01,
        -5.7125e-01, -1.6956e-01,  5.1888e-01,  7.7078e-02,  1.1944e-01,
         1.8129e-01, -8.9561e-01,  3.8084e-01, -2.3702e-01, -1.2863e-01,
         2.2231e-02, -5.7438e-01,  3.2995e-01, -4.2167e-01, -5.4119e-02,
        -7.7625e-02, -1.0947e-01,  3.7560e-01, -3.3590e-01,  1.4131e-01,
        -1.8746e-01,  4.7900e-01,  3.1033e-01, -9.7040e-02, -5.7953e-01,
         8.7622e-03,  4.2779e-01,  8.2217e-02, -1.3439e-01,  8.1339e-02,
         6.8701e-01,  4.0771e-01,  2.6295e-01,  2.3553e-01, -7.0313e-01,
         1.3736e-01,  3.7160e-02, -1.1806e-01,  3.2961e-01, -3.8911e-01,
         1.5869e-01,  9.3960e-01, -5.9015e-01, -1.3149e-02, -2.1453e-01,
        -1.8397e-01,  2.7646e-01,  1.7219e-01,  1.7042e-01,  2.2861e-01,
        -2.0704e-02,  7.3572e-02, -1.7515e-01, -2.3143e-01, -1.9496e-02,
         2.6253e-01,  2.9907e-01,  7.3735e-02, -4.2134e-02,  3.5677e-01,
        -1.2455e-01,  4.9271e-03, -6.5227e-01, -8.3011e-02, -5.8820e-01,
         4.5650e-01, -4.1180e-02,  2.3881e-02, -5.8087e-02, -1.7040e-01,
        -2.1956e-03, -3.5901e-01, -2.6012e-01,  1.0595e-01, -6.6249e-02,
        -1.6302e-01,  1.0075e-01,  3.9301e-02, -6.3541e-02,  4.9390e-01,
        -1.9337e-01, -9.3062e-02,  6.0942e-01,  2.5068e-01,  1.8531e-01,
         4.1131e-01,  1.6108e-01,  1.9495e-01,  4.3398e-01,  8.5956e-02,
        -1.6527e-02,  1.8384e-01,  3.7668e-01,  5.9669e-01,  1.3947e-01,
         5.3521e-02, -1.9720e-01,  9.3973e-02, -5.1057e-02,  1.6301e-01,
         1.6132e-01,  1.0777e-01,  3.3122e-01, -1.4714e-01,  4.7950e-01,
         2.5905e-01,  3.7858e-02, -1.3896e-01,  2.4627e-01, -2.3409e-01,
         2.6823e-01, -3.5673e-01, -4.1870e-01,  1.8804e-02,  7.3090e-03,
        -2.3590e-01, -5.3828e-01,  3.4735e-01,  3.3215e-01,  4.0212e-01,
        -2.7855e-01, -7.2959e-02, -3.1446e-02, -6.4143e-01, -4.2868e-02,
        -6.7789e-04, -4.0041e-01,  1.1262e-01, -2.0585e-01,  2.9875e-01,
         6.0628e-01, -1.5217e-01, -3.1344e-01, -1.2641e-01,  5.2786e-01,
        -5.1264e-01,  2.6971e-02, -1.0038e-01,  5.0735e-02,  6.2319e-02,
        -6.1797e-02, -1.9460e-01, -6.9751e-01,  4.7737e-02,  1.0155e-01,
        -2.2029e-01, -5.7951e-01, -3.2985e-01, -2.4506e-01, -2.8394e-01,
         2.0112e-01, -1.0136e-04, -9.0884e-02, -1.9466e-01, -4.7223e-03,
        -2.0894e-01,  1.3831e-01, -1.4516e-01, -1.9103e-01, -2.1750e-04,
         1.2204e-01,  1.0628e-01,  4.7746e-02, -3.9541e-01,  4.5301e-01,
        -2.4983e-01, -3.9992e-01,  5.3796e-01, -1.2344e-01,  1.1183e-01,
        -1.9748e-01, -3.3238e-01,  3.0558e-02,  1.8286e-01, -1.3982e-01,
         1.6362e-01,  1.5340e-01, -3.9113e-02,  6.2866e-01, -2.6473e-01,
        -8.4732e-02, -2.7028e-01,  2.9981e-01,  9.2402e-01, -2.6510e-01,
         2.9722e-01,  5.4069e-03,  2.3903e-01, -5.5071e-02,  2.3940e-01,
         3.3977e-01,  4.0255e-01, -8.5160e-02,  2.7084e-01, -2.7050e-01,
        -3.7437e-01, -1.3526e-01, -4.0163e-01, -4.6052e-01, -1.1068e-01,
        -1.8617e-01,  3.9481e-02,  1.3563e-01, -7.0856e-03, -7.4792e-02,
        -5.3008e-01, -5.7324e-01, -8.0610e-02,  8.7845e-02, -4.3004e-02,
         1.0736e-01, -1.8698e-01, -1.5898e-01,  5.1672e-01, -3.3569e-02,
        -1.6489e-01, -6.1863e-01,  3.4280e-01, -2.4454e-01, -3.3029e-01,
        -7.5931e-03,  3.1544e-01,  9.7617e-02, -1.3923e-01,  7.5778e-01,
         5.4451e-01, -5.9864e-01,  2.1223e-01, -5.8968e-02, -1.3724e-01,
        -1.1381e-02, -1.2671e-01, -4.3471e-02,  1.6062e-02,  1.1420e-01,
        -6.5674e-01,  4.8365e-01, -1.3672e-01, -4.0789e-01,  8.4252e-01,
        -8.7780e-02], device='cuda:6', requires_grad=True)
net_guide.net.2.0.bias.scale torch.Size([256]) tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010], device='cuda:6',
       grad_fn=<AddBackward0>)
net_guide.net.3.0.weight.loc torch.Size([256, 256]) Parameter containing:
tensor([[ 0.0121, -0.1152,  0.0586,  ..., -0.4738, -0.2972, -0.1221],
        [-0.4066,  0.1600, -0.7954,  ..., -0.0762,  0.1117,  0.3178],
        [-0.3361, -0.1907,  0.5789,  ...,  0.2115, -0.2853, -0.1116],
        ...,
        [-0.2674, -0.4308, -0.1085,  ..., -0.2876,  0.3349,  0.0648],
        [-0.1993,  0.2488,  0.5051,  ..., -0.0699, -0.3485, -0.2512],
        [ 0.1036,  0.4032,  0.3866,  ...,  0.0613, -0.3672,  0.2213]],
       device='cuda:6', requires_grad=True)
net_guide.net.3.0.weight.scale torch.Size([256, 256]) tensor([[0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        ...,
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]],
       device='cuda:6', grad_fn=<AddBackward0>)
net_guide.net.3.0.bias.loc torch.Size([256]) Parameter containing:
tensor([-0.2012,  0.1519, -0.2732,  0.2522,  0.4648,  0.0240, -0.0756, -0.5152,
         0.2741, -0.0671, -0.0186, -0.0699, -0.1015,  0.1011,  0.2066,  0.1954,
        -0.2458, -0.0132, -0.3206, -0.3210, -0.1192,  0.1330,  0.0324, -0.0070,
        -0.2444,  0.3751,  0.4755,  0.0124,  0.3253,  0.6783,  0.2392,  0.2661,
        -0.1721,  0.3691,  0.3196,  0.2247,  0.2295,  0.5036, -0.2770,  0.3292,
        -0.5615,  0.0451, -0.8193,  0.0286,  0.1515, -0.1384,  0.0968, -0.3921,
         0.3913, -0.8187, -0.4363,  0.1884, -0.2359, -0.1543,  0.0618, -0.0186,
        -0.6086, -0.1463, -0.3644,  0.2219,  0.0198, -0.3222,  0.1253,  0.2642,
        -0.4624,  0.5315,  0.0684, -0.5856, -0.0839,  0.1751, -0.1739,  0.0878,
         0.5450,  0.0616,  0.2945,  0.4452,  0.1753,  0.0678,  0.2604,  0.6721,
        -0.3622, -0.2617, -0.4988, -0.1294,  0.2665,  0.1559, -0.3628,  0.2156,
         0.5496,  0.0031,  0.0988,  0.2573, -0.0780,  0.1347, -0.1524, -0.0769,
         0.1248,  0.1333,  0.1922, -0.3023,  0.1408, -0.1442, -0.1329,  0.3413,
        -0.4037, -0.1714,  0.8201, -0.1850,  0.3083, -0.5520,  0.0355,  0.0053,
         0.4597, -0.2773,  0.1527,  0.0711,  0.2695, -0.4593, -0.1782, -0.5918,
         0.3413,  0.2723,  0.1558, -0.1755,  0.1491, -0.1578, -0.3820,  0.0363,
         0.4248,  0.3822, -0.0658,  0.6343, -0.0785, -0.0867, -0.3390,  0.1499,
        -0.0021,  0.0523,  0.2323, -0.1110, -0.0905, -0.4995, -0.4253, -0.2507,
        -0.0029, -0.0528,  0.0279,  0.0033,  0.1448,  0.1177, -0.2476, -0.1126,
        -0.0471,  0.0117, -0.0014, -0.6038, -0.3689,  0.0644, -0.2756,  0.3625,
        -0.3388,  0.0300,  0.4158,  0.2601,  0.1379,  0.5276, -0.1607, -0.1945,
         0.0619,  0.2706,  0.2202,  0.5370,  0.0401,  0.1340,  0.0382, -0.1267,
        -0.2012, -0.1670, -0.1110,  0.0154,  0.0999, -0.0639, -0.0644, -0.4872,
        -0.0980, -0.6168,  0.4697,  0.3369, -0.0314,  0.3106,  0.2576, -0.1310,
         0.1375, -0.1488, -0.4317,  0.1418,  0.1879,  0.0440,  0.0466, -0.2725,
        -0.5664, -0.1317,  0.0935, -0.2330,  0.5292, -0.1005, -0.2546, -0.0159,
         0.3247, -0.4045,  0.3079, -0.0093, -0.5757, -0.1800, -0.5236,  0.2243,
         0.4106,  0.2075, -0.7541,  0.0735,  0.4070,  0.1222, -0.4076,  0.1887,
        -0.3166, -0.1890, -0.0834, -0.0217, -0.2336,  0.0406,  0.6914,  0.7747,
        -0.0471, -0.0303, -0.3195,  0.1935, -0.2386, -0.6254,  0.3162,  0.2664,
        -0.2753,  0.1179,  0.1202,  0.1244,  0.2974,  0.2854, -0.4575, -0.1317,
        -0.2730,  0.1798, -0.1110,  0.4014,  0.2062, -0.0153,  0.0994, -0.1099],
       device='cuda:6', requires_grad=True)
net_guide.net.3.0.bias.scale torch.Size([256]) tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010], device='cuda:6',
       grad_fn=<AddBackward0>)
net_guide.net.4.weight.loc torch.Size([1, 256]) Parameter containing:
tensor([[ 0.2282, -0.2880, -0.1671, -0.2808, -0.1303, -0.3014,  0.1724,  0.2939,
         -0.4123, -0.1997, -0.0071, -0.0550,  0.1320, -0.0096, -0.0551,  0.4463,
         -0.3960,  0.4755, -0.2136, -0.5229, -0.0719, -0.6154, -0.2980,  0.1639,
          0.1174, -0.1056, -0.0039,  0.0065, -0.2390, -0.2979,  0.0262, -0.1279,
         -0.2009, -0.0067, -0.6073, -0.5364, -0.4424, -0.1583,  0.6203,  0.0965,
          0.3061, -0.3525,  0.0889, -0.0268, -0.2016,  0.0495, -0.4144, -0.3625,
          0.2301, -0.0859,  0.4930,  0.0837,  0.0671, -0.0197,  0.1082, -0.2638,
         -0.3014, -0.1960, -0.4375, -0.0334,  0.3471,  0.3752, -0.1109,  0.4047,
         -0.2300,  0.1252,  0.0575, -0.1467,  0.0119, -0.1071, -0.2048, -0.1848,
         -0.0632, -0.7452,  0.2365,  0.0993,  0.2752,  0.2640, -0.0876, -0.0747,
         -0.1873,  0.0990,  0.2137, -0.4349,  0.1935, -0.2268,  0.2398, -0.2770,
          0.2976,  0.0031, -0.6438, -0.3315, -0.5969, -0.2147, -0.0181, -0.5286,
          0.3596, -0.1220,  0.3930,  0.1544,  0.1515,  0.1008, -0.2463, -0.3451,
          0.4059, -0.3830, -0.1297, -0.6289,  0.0552, -0.0796, -0.3429, -0.1757,
          0.4518, -0.3933,  0.0248,  0.0267,  0.6480,  0.0740, -0.0717,  0.8297,
          0.2205, -0.2020, -0.3289,  0.4676,  0.2161,  0.2503, -0.0165,  0.5662,
         -0.1267, -0.0830,  0.1809, -0.0916,  0.0508,  0.2385, -0.3955,  0.1554,
         -0.1480,  0.2445,  0.3824, -0.3677,  0.5917,  0.4889, -0.1462,  0.1474,
          0.2972, -0.0407, -0.4036,  0.4070, -0.2340,  0.2169,  0.2382,  0.2299,
         -0.0507,  0.0900, -0.0593,  0.3626,  0.5149,  0.0464,  0.2037, -0.2595,
          0.2863,  0.2843,  0.0945,  0.0566, -0.1927,  0.1894, -0.9002,  0.5788,
          0.2057,  0.2960,  0.0633,  0.0623,  0.0128,  0.3393, -0.2517,  0.3773,
         -0.0336, -0.0070,  0.0887, -0.4716, -0.2073,  0.1131,  0.2886,  0.0922,
         -0.0239, -0.2822,  0.8004, -0.3953,  0.4662,  0.2040,  0.0764, -0.3777,
          0.2148,  0.3406, -0.0725, -0.1002, -0.6431,  0.1883,  0.1062, -0.8595,
          0.0356,  0.0794,  0.1828, -0.2400,  0.0325,  0.2061,  0.5506,  0.5237,
          0.3310, -0.5543,  0.6550, -0.0602, -0.2675, -0.2414,  0.0915, -0.2201,
         -0.2652, -0.3067, -0.3414, -0.0434,  0.4765,  0.4385,  0.0421, -0.4169,
          0.4562, -0.2029,  0.4516, -0.2099,  0.3400,  0.2204, -0.6500, -0.0732,
         -0.3598, -0.0762,  0.3170, -0.0484,  0.4703, -0.0276, -0.2258, -0.2217,
          0.0801, -0.2562,  0.1709,  0.2125,  0.2883, -0.3683,  0.0532,  0.1163,
         -0.0387, -0.2753,  0.1673,  0.1993, -0.0570, -0.1142,  0.0245,  0.7568]],
       device='cuda:6', requires_grad=True)
net_guide.net.4.weight.scale torch.Size([1, 256]) tensor([[0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010]], device='cuda:6',
       grad_fn=<AddBackward0>)
net_guide.net.4.bias.loc torch.Size([1]) Parameter containing:
tensor([0.2571], device='cuda:6', requires_grad=True)
net_guide.net.4.bias.scale torch.Size([1]) tensor([0.0010], device='cuda:6', grad_fn=<AddBackward0>)
Using device: cuda:6
===== Training profile sineasy50-3x256-s03 - 1 =====
[0:00:03.383273] epoch: 0 | elbo: 497195781.91999996 | train_rmse: 57.4797 | val_rmse: 58.3373 | val_ll: -2433.9175
[0:02:56.664287] epoch: 50 | elbo: 68896212.61999996 | train_rmse: 24.5605 | val_rmse: 30.1542 | val_ll: -1225.8732
[0:05:52.000144] epoch: 100 | elbo: 46098033.800000004 | train_rmse: 19.7601 | val_rmse: 29.4761 | val_ll: -1284.8459
[0:11:30.685272] epoch: 150 | elbo: 30651729.130000006 | train_rmse: 16.0325 | val_rmse: 30.0142 | val_ll: -1343.264
[0:28:30.034139] epoch: 200 | elbo: 19777551.739999995 | train_rmse: 12.7543 | val_rmse: 31.0055 | val_ll: -1372.693
[0:42:15.552708] epoch: 250 | elbo: 12118581.105 | train_rmse: 9.815 | val_rmse: 32.0566 | val_ll: -1412.3365
[0:45:09.974572] epoch: 300 | elbo: 6931217.880000001 | train_rmse: 7.1398 | val_rmse: 33.032 | val_ll: -1438.5117
[0:48:04.630799] epoch: 350 | elbo: 3775593.0099999993 | train_rmse: 5.0036 | val_rmse: 33.9507 | val_ll: -1444.5189
[0:50:58.319070] epoch: 400 | elbo: 2036472.971249999 | train_rmse: 3.0089 | val_rmse: 34.6899 | val_ll: -1419.9677
[0:53:53.428657] epoch: 450 | elbo: 1236161.6362499997 | train_rmse: 1.5548 | val_rmse: 35.2557 | val_ll: -1428.876
[0:56:46.976002] epoch: 500 | elbo: 968714.5006250001 | train_rmse: 0.5767 | val_rmse: 35.5813 | val_ll: -1422.1311
[0:59:40.717876] epoch: 550 | elbo: 923819.42125 | train_rmse: 0.3114 | val_rmse: 35.6992 | val_ll: -1342.9216
[1:03:35.736568] epoch: 600 | elbo: 923325.8821875 | train_rmse: 0.3526 | val_rmse: 35.6618 | val_ll: -1249.9417
[1:08:35.914133] epoch: 650 | elbo: 914782.8256249998 | train_rmse: 0.4271 | val_rmse: 35.6029 | val_ll: -1166.251
[1:12:21.103091] epoch: 700 | elbo: 909615.1831249997 | train_rmse: 0.5401 | val_rmse: 35.5353 | val_ll: -1108.1057
[1:16:31.143035] epoch: 750 | elbo: 907801.3584375002 | train_rmse: 0.3923 | val_rmse: 35.4681 | val_ll: -1061.9877
[1:19:29.051362] epoch: 800 | elbo: 908868.2993750002 | train_rmse: 0.6088 | val_rmse: 35.4096 | val_ll: -1026.3196
[1:22:30.875910] epoch: 850 | elbo: 907481.28125 | train_rmse: 0.3935 | val_rmse: 35.3443 | val_ll: -981.1622
[1:25:25.390760] epoch: 900 | elbo: 900073.4806250001 | train_rmse: 0.3904 | val_rmse: 35.2794 | val_ll: -970.1271
[1:28:19.855865] epoch: 950 | elbo: 908795.7271875 | train_rmse: 0.376 | val_rmse: 35.2199 | val_ll: -938.4025
[1:31:13.786008] epoch: 1000 | elbo: 902068.2290624998 | train_rmse: 0.4286 | val_rmse: 35.158 | val_ll: -925.299
[1:34:07.439744] epoch: 1050 | elbo: 898739.5678125002 | train_rmse: 0.3654 | val_rmse: 35.0867 | val_ll: -897.8803
[1:37:01.586270] epoch: 1100 | elbo: 899039.9803124999 | train_rmse: 0.3496 | val_rmse: 35.0386 | val_ll: -908.2689
[1:39:55.575075] epoch: 1150 | elbo: 897014.753125 | train_rmse: 0.4166 | val_rmse: 34.9881 | val_ll: -897.2707
[1:42:50.299607] epoch: 1200 | elbo: 898241.4296875 | train_rmse: 0.3792 | val_rmse: 34.9204 | val_ll: -886.3447
[1:45:44.814086] epoch: 1250 | elbo: 893215.5643750001 | train_rmse: 0.3521 | val_rmse: 34.8686 | val_ll: -885.2689
[1:48:39.134832] epoch: 1300 | elbo: 891502.3649999999 | train_rmse: 0.4162 | val_rmse: 34.8156 | val_ll: -871.7535
[1:51:33.356336] epoch: 1350 | elbo: 893307.9865624998 | train_rmse: 0.3744 | val_rmse: 34.7526 | val_ll: -856.3233
[1:54:26.633344] epoch: 1400 | elbo: 902183.2390625 | train_rmse: 0.4339 | val_rmse: 34.7153 | val_ll: -860.8108
[1:57:20.500610] epoch: 1450 | elbo: 892450.2934374999 | train_rmse: 0.3513 | val_rmse: 34.6653 | val_ll: -867.8888
[2:00:15.208929] epoch: 1500 | elbo: 890797.8115625 | train_rmse: 0.3619 | val_rmse: 34.6054 | val_ll: -858.1765
[2:03:09.536053] epoch: 1550 | elbo: 887003.8190624997 | train_rmse: 0.3934 | val_rmse: 34.552 | val_ll: -847.8384
[2:06:04.584308] epoch: 1600 | elbo: 885496.0525000002 | train_rmse: 0.4294 | val_rmse: 34.504 | val_ll: -837.4505
[2:08:58.923855] epoch: 1650 | elbo: 886203.595 | train_rmse: 0.3527 | val_rmse: 34.4508 | val_ll: -828.9633
[2:11:53.114998] epoch: 1700 | elbo: 885069.2553124999 | train_rmse: 0.3663 | val_rmse: 34.4088 | val_ll: -838.3316
[2:14:47.080353] epoch: 1750 | elbo: 885126.8146875001 | train_rmse: 0.5274 | val_rmse: 34.3554 | val_ll: -838.1351
[2:17:46.749990] epoch: 1800 | elbo: 883476.3284375 | train_rmse: 0.3567 | val_rmse: 34.3043 | val_ll: -832.0339
[2:20:43.602274] epoch: 1850 | elbo: 881196.1709375 | train_rmse: 0.3693 | val_rmse: 34.2585 | val_ll: -835.8511
[2:23:37.014257] epoch: 1900 | elbo: 880794.9399999998 | train_rmse: 0.351 | val_rmse: 34.2078 | val_ll: -832.3547
[2:26:36.141853] epoch: 1950 | elbo: 877534.0959374998 | train_rmse: 0.3218 | val_rmse: 34.1721 | val_ll: -833.9683
[2:29:36.389995] epoch: 2000 | elbo: 877330.3256250003 | train_rmse: 0.351 | val_rmse: 34.1248 | val_ll: -834.3778
[2:32:35.858781] epoch: 2050 | elbo: 873990.1056250001 | train_rmse: 0.3402 | val_rmse: 34.0744 | val_ll: -832.2207
[2:35:33.831795] epoch: 2100 | elbo: 877180.8640625002 | train_rmse: 0.3504 | val_rmse: 34.0316 | val_ll: -823.6015
[2:38:31.385316] epoch: 2150 | elbo: 876930.2696875001 | train_rmse: 0.3366 | val_rmse: 33.9951 | val_ll: -824.6874
[2:41:29.004501] epoch: 2200 | elbo: 873638.3175000001 | train_rmse: 0.3755 | val_rmse: 33.9538 | val_ll: -821.1822
[2:44:25.178982] epoch: 2250 | elbo: 880596.5121875003 | train_rmse: 0.3819 | val_rmse: 33.9112 | val_ll: -809.9066
[2:47:21.025135] epoch: 2300 | elbo: 872358.8006249999 | train_rmse: 0.4527 | val_rmse: 33.8614 | val_ll: -804.1285
[2:50:17.563975] epoch: 2350 | elbo: 870627.2828124998 | train_rmse: 0.3425 | val_rmse: 33.8247 | val_ll: -812.6109
[2:53:16.114118] epoch: 2400 | elbo: 871036.8162500001 | train_rmse: 0.3558 | val_rmse: 33.7864 | val_ll: -804.1379
[2:56:13.629373] epoch: 2450 | elbo: 871578.7331249999 | train_rmse: 0.3939 | val_rmse: 33.7351 | val_ll: -810.7556
[2:59:11.020995] epoch: 2500 | elbo: 868436.4840624997 | train_rmse: 0.3224 | val_rmse: 33.6995 | val_ll: -805.6396
[3:02:08.360281] epoch: 2550 | elbo: 869164.3140625001 | train_rmse: 0.4828 | val_rmse: 33.6553 | val_ll: -801.9714
[3:05:08.863572] epoch: 2600 | elbo: 865027.3146875 | train_rmse: 0.3224 | val_rmse: 33.6247 | val_ll: -788.099
[3:08:08.560866] epoch: 2650 | elbo: 869202.9640625 | train_rmse: 0.3649 | val_rmse: 33.5818 | val_ll: -815.0126
[3:11:07.585482] epoch: 2700 | elbo: 869655.3696875001 | train_rmse: 0.4143 | val_rmse: 33.5395 | val_ll: -792.7443
[3:14:06.075132] epoch: 2750 | elbo: 863158.403125 | train_rmse: 0.3224 | val_rmse: 33.4982 | val_ll: -796.8385
[3:17:06.027058] epoch: 2800 | elbo: 860505.7481250002 | train_rmse: 0.3041 | val_rmse: 33.4701 | val_ll: -794.582
[3:20:03.903349] epoch: 2850 | elbo: 860762.4809374999 | train_rmse: 0.429 | val_rmse: 33.4316 | val_ll: -788.9507
[3:23:01.010909] epoch: 2900 | elbo: 862681.3768750003 | train_rmse: 0.4735 | val_rmse: 33.3898 | val_ll: -797.1083
[3:26:00.637696] epoch: 2950 | elbo: 861206.6828124998 | train_rmse: 0.3489 | val_rmse: 33.3557 | val_ll: -779.3823
[3:29:00.363820] epoch: 3000 | elbo: 858550.1634374999 | train_rmse: 0.3278 | val_rmse: 33.3255 | val_ll: -787.0315
[3:32:00.556468] epoch: 3050 | elbo: 859177.1396875 | train_rmse: 0.4124 | val_rmse: 33.2845 | val_ll: -781.3787
[3:35:00.483351] epoch: 3100 | elbo: 857422.9646874999 | train_rmse: 0.348 | val_rmse: 33.2476 | val_ll: -782.9235
[3:38:00.854963] epoch: 3150 | elbo: 859443.6237500003 | train_rmse: 0.374 | val_rmse: 33.208 | val_ll: -773.8782
[3:41:01.635760] epoch: 3200 | elbo: 860209.15625 | train_rmse: 0.5133 | val_rmse: 33.1821 | val_ll: -781.4896
[3:44:01.496879] epoch: 3250 | elbo: 856349.2590625 | train_rmse: 0.3356 | val_rmse: 33.1324 | val_ll: -781.5113
[3:47:02.146631] epoch: 3300 | elbo: 856046.1734375001 | train_rmse: 0.3366 | val_rmse: 33.1127 | val_ll: -782.1678
[3:50:02.956974] epoch: 3350 | elbo: 852549.9065625 | train_rmse: 0.3098 | val_rmse: 33.0754 | val_ll: -783.1147
[3:53:03.282770] epoch: 3400 | elbo: 853065.8112499999 | train_rmse: 0.3829 | val_rmse: 33.0448 | val_ll: -771.607
[3:56:03.368645] epoch: 3450 | elbo: 855270.7996875001 | train_rmse: 0.336 | val_rmse: 33.0163 | val_ll: -770.7524
[3:59:04.499759] epoch: 3500 | elbo: 854934.6737500001 | train_rmse: 0.3783 | val_rmse: 32.9747 | val_ll: -769.7709
[4:02:06.472315] epoch: 3550 | elbo: 865226.4862499998 | train_rmse: 0.5428 | val_rmse: 32.9589 | val_ll: -764.8915
[4:05:09.832541] epoch: 3600 | elbo: 852022.5512499999 | train_rmse: 0.3374 | val_rmse: 32.9164 | val_ll: -776.3884
[4:08:12.951806] epoch: 3650 | elbo: 856171.0875 | train_rmse: 0.3686 | val_rmse: 32.8893 | val_ll: -779.2434
[4:11:14.137330] epoch: 3700 | elbo: 849816.3440625 | train_rmse: 0.3341 | val_rmse: 32.8633 | val_ll: -764.4902
[4:14:12.694182] epoch: 3750 | elbo: 848765.9690625 | train_rmse: 0.3435 | val_rmse: 32.8306 | val_ll: -765.6431
[4:17:12.946470] epoch: 3800 | elbo: 845761.2578124998 | train_rmse: 0.3272 | val_rmse: 32.8044 | val_ll: -756.5121
[4:20:15.024731] epoch: 3850 | elbo: 846989.9746874999 | train_rmse: 0.333 | val_rmse: 32.7611 | val_ll: -764.7084
[4:23:15.333105] epoch: 3900 | elbo: 849847.1878124999 | train_rmse: 0.3405 | val_rmse: 32.7372 | val_ll: -766.7999
[4:26:15.176691] epoch: 3950 | elbo: 845258.3984375 | train_rmse: 0.3415 | val_rmse: 32.7173 | val_ll: -762.124
[4:29:15.073966] epoch: 4000 | elbo: 845837.2821875 | train_rmse: 0.3143 | val_rmse: 32.6848 | val_ll: -764.1741
[4:32:17.166060] epoch: 4050 | elbo: 843149.8275 | train_rmse: 0.4101 | val_rmse: 32.6639 | val_ll: -762.3088
[4:35:19.430950] epoch: 4100 | elbo: 840450.4659375001 | train_rmse: 0.3598 | val_rmse: 32.6309 | val_ll: -745.91
[4:38:21.264642] epoch: 4150 | elbo: 841884.2140625002 | train_rmse: 0.3635 | val_rmse: 32.5948 | val_ll: -750.0251
[4:41:20.527774] epoch: 4200 | elbo: 841842.6893750001 | train_rmse: 0.3304 | val_rmse: 32.5796 | val_ll: -750.8859
[4:44:21.630281] epoch: 4250 | elbo: 840182.1475 | train_rmse: 0.3463 | val_rmse: 32.55 | val_ll: -755.701
[4:47:21.529841] epoch: 4300 | elbo: 839921.056875 | train_rmse: 0.3269 | val_rmse: 32.5258 | val_ll: -756.3572
[4:50:21.357966] epoch: 4350 | elbo: 837203.9724999999 | train_rmse: 0.3297 | val_rmse: 32.4974 | val_ll: -745.9736
[4:53:20.882757] epoch: 4400 | elbo: 838203.7337499999 | train_rmse: 0.407 | val_rmse: 32.4645 | val_ll: -741.5979
[4:56:21.783774] epoch: 4450 | elbo: 842882.97625 | train_rmse: 0.4201 | val_rmse: 32.4537 | val_ll: -751.7682
[4:59:23.147569] epoch: 4500 | elbo: 835605.9346875001 | train_rmse: 0.3999 | val_rmse: 32.4206 | val_ll: -747.9366
[5:02:25.926598] epoch: 4550 | elbo: 834786.1040625002 | train_rmse: 0.3219 | val_rmse: 32.393 | val_ll: -744.2775
[5:05:27.515127] epoch: 4600 | elbo: 832832.1353125 | train_rmse: 0.2984 | val_rmse: 32.3647 | val_ll: -751.6625
[5:08:24.028390] epoch: 4650 | elbo: 834329.77875 | train_rmse: 0.3605 | val_rmse: 32.3402 | val_ll: -744.7582
[5:11:20.502383] epoch: 4700 | elbo: 836464.4678125 | train_rmse: 0.3459 | val_rmse: 32.3193 | val_ll: -735.259
[5:14:17.121739] epoch: 4750 | elbo: 831840.3709375001 | train_rmse: 0.3265 | val_rmse: 32.2929 | val_ll: -741.7927
[5:17:13.164103] epoch: 4800 | elbo: 831489.1174999998 | train_rmse: 0.322 | val_rmse: 32.2654 | val_ll: -743.6374
[5:20:07.738049] epoch: 4850 | elbo: 831079.3003124999 | train_rmse: 0.3208 | val_rmse: 32.2478 | val_ll: -743.2113
[5:23:05.705754] epoch: 4900 | elbo: 830212.5218749999 | train_rmse: 0.4103 | val_rmse: 32.2271 | val_ll: -745.4634
[5:26:02.972220] epoch: 4950 | elbo: 826790.1809375 | train_rmse: 0.3126 | val_rmse: 32.1993 | val_ll: -740.59
[5:28:58.946697] epoch: 5000 | elbo: 834713.67125 | train_rmse: 0.4383 | val_rmse: 32.1786 | val_ll: -745.8115
[5:31:55.454372] epoch: 5050 | elbo: 824650.8975000002 | train_rmse: 0.3759 | val_rmse: 32.156 | val_ll: -737.6431
[5:34:51.632182] epoch: 5100 | elbo: 829690.8662499998 | train_rmse: 0.3222 | val_rmse: 32.1242 | val_ll: -745.6785
[5:37:46.879915] epoch: 5150 | elbo: 825926.3425 | train_rmse: 0.3323 | val_rmse: 32.1084 | val_ll: -738.0097
[5:40:41.990175] epoch: 5200 | elbo: 821036.5278124998 | train_rmse: 0.2844 | val_rmse: 32.0798 | val_ll: -739.5643
[5:43:35.272268] epoch: 5250 | elbo: 825396.040625 | train_rmse: 0.3262 | val_rmse: 32.0552 | val_ll: -736.6571
[5:46:30.045201] epoch: 5300 | elbo: 824034.9465625 | train_rmse: 0.3773 | val_rmse: 32.0355 | val_ll: -730.2134
[5:49:23.640621] epoch: 5350 | elbo: 819814.2006249999 | train_rmse: 0.3694 | val_rmse: 32.0118 | val_ll: -737.6193
[5:52:21.466426] epoch: 5400 | elbo: 822619.9946875 | train_rmse: 0.325 | val_rmse: 31.9903 | val_ll: -726.7552
[5:55:19.814326] epoch: 5450 | elbo: 819452.6868750002 | train_rmse: 0.3565 | val_rmse: 31.9678 | val_ll: -736.7949
[5:58:19.034870] epoch: 5500 | elbo: 818503.6281249999 | train_rmse: 0.3813 | val_rmse: 31.9427 | val_ll: -729.1375
[6:01:18.100249] epoch: 5550 | elbo: 823628.5981249999 | train_rmse: 0.3256 | val_rmse: 31.9204 | val_ll: -741.3114
[6:04:18.680639] epoch: 5600 | elbo: 819813.253125 | train_rmse: 0.3073 | val_rmse: 31.8999 | val_ll: -729.462
[6:07:17.374045] epoch: 5650 | elbo: 819003.9906249999 | train_rmse: 0.3248 | val_rmse: 31.8881 | val_ll: -740.6027
[6:10:15.544399] epoch: 5700 | elbo: 816267.1765625 | train_rmse: 0.3425 | val_rmse: 31.8473 | val_ll: -725.5802
[6:13:12.949476] epoch: 5750 | elbo: 814274.1443749999 | train_rmse: 0.3622 | val_rmse: 31.8218 | val_ll: -720.7667
[6:16:11.591541] epoch: 5800 | elbo: 815674.5571875001 | train_rmse: 0.3179 | val_rmse: 31.8104 | val_ll: -729.8811
[6:19:09.681958] epoch: 5850 | elbo: 811291.8121875002 | train_rmse: 0.2981 | val_rmse: 31.7879 | val_ll: -723.2004
[6:22:07.173613] epoch: 5900 | elbo: 812330.354375 | train_rmse: 0.3111 | val_rmse: 31.7759 | val_ll: -724.428
[6:25:04.286476] epoch: 5950 | elbo: 812990.6315624999 | train_rmse: 0.3621 | val_rmse: 31.7579 | val_ll: -722.5582
[6:28:00.900937] epoch: 6000 | elbo: 810523.9756250002 | train_rmse: 0.3208 | val_rmse: 31.7354 | val_ll: -725.0043
[6:30:55.468567] epoch: 6050 | elbo: 808761.5928125 | train_rmse: 0.3 | val_rmse: 31.7134 | val_ll: -734.9833
[6:33:47.817843] epoch: 6100 | elbo: 809346.5599999998 | train_rmse: 0.3331 | val_rmse: 31.6925 | val_ll: -716.796
[6:36:41.788048] epoch: 6150 | elbo: 808754.14125 | train_rmse: 0.343 | val_rmse: 31.6761 | val_ll: -722.7283
[6:39:34.910517] epoch: 6200 | elbo: 807989.5896875 | train_rmse: 0.317 | val_rmse: 31.6553 | val_ll: -707.2261
[6:42:28.327710] epoch: 6250 | elbo: 805568.9096875001 | train_rmse: 0.441 | val_rmse: 31.6411 | val_ll: -718.0775
[6:45:23.576068] epoch: 6300 | elbo: 805849.8028124999 | train_rmse: 0.312 | val_rmse: 31.6155 | val_ll: -721.95
[6:48:18.091900] epoch: 6350 | elbo: 804343.9171875002 | train_rmse: 0.325 | val_rmse: 31.5992 | val_ll: -717.0459
[6:51:10.765814] epoch: 6400 | elbo: 802333.2728124999 | train_rmse: 0.2976 | val_rmse: 31.5749 | val_ll: -729.6458
[6:54:06.592422] epoch: 6450 | elbo: 802085.1171875002 | train_rmse: 0.2994 | val_rmse: 31.5556 | val_ll: -732.4855
[6:57:02.477451] epoch: 6500 | elbo: 803416.034375 | train_rmse: 0.2922 | val_rmse: 31.5345 | val_ll: -722.7366
[6:59:57.501869] epoch: 6550 | elbo: 802919.1168750002 | train_rmse: 0.3743 | val_rmse: 31.5165 | val_ll: -723.1954
[7:02:51.088165] epoch: 6600 | elbo: 799052.098125 | train_rmse: 0.3007 | val_rmse: 31.4917 | val_ll: -720.8508
[7:05:44.934335] epoch: 6650 | elbo: 799762.1206249999 | train_rmse: 0.3048 | val_rmse: 31.4782 | val_ll: -730.7218
[7:08:40.092488] epoch: 6700 | elbo: 798818.4528125001 | train_rmse: 0.3511 | val_rmse: 31.4503 | val_ll: -708.4811
[7:11:33.927655] epoch: 6750 | elbo: 797157.9184375 | train_rmse: 0.3394 | val_rmse: 31.4333 | val_ll: -713.088
[7:14:31.754042] epoch: 6800 | elbo: 798865.9190625 | train_rmse: 0.393 | val_rmse: 31.4283 | val_ll: -718.1807
[7:17:27.754462] epoch: 6850 | elbo: 794036.0518750001 | train_rmse: 0.2955 | val_rmse: 31.394 | val_ll: -719.9778
[7:20:22.370540] epoch: 6900 | elbo: 794216.2699999999 | train_rmse: 0.3058 | val_rmse: 31.3794 | val_ll: -712.2744
[7:23:17.387205] epoch: 6950 | elbo: 796076.7634375 | train_rmse: 0.3075 | val_rmse: 31.3573 | val_ll: -711.7878
[7:26:15.647933] epoch: 7000 | elbo: 794259.7884374999 | train_rmse: 0.2775 | val_rmse: 31.338 | val_ll: -709.4896
[7:29:13.745565] epoch: 7050 | elbo: 791770.8956250001 | train_rmse: 0.2991 | val_rmse: 31.3319 | val_ll: -713.5355
[7:32:11.074297] epoch: 7100 | elbo: 795742.8465625001 | train_rmse: 0.3895 | val_rmse: 31.3039 | val_ll: -715.7952
[7:35:07.011414] epoch: 7150 | elbo: 791382.3771875 | train_rmse: 0.3385 | val_rmse: 31.2934 | val_ll: -716.0027
[7:38:03.072848] epoch: 7200 | elbo: 790041.3275 | train_rmse: 0.2918 | val_rmse: 31.2747 | val_ll: -707.8516
[7:40:57.415410] epoch: 7250 | elbo: 790848.7931250002 | train_rmse: 0.2939 | val_rmse: 31.2546 | val_ll: -695.8374
[7:43:51.261628] epoch: 7300 | elbo: 790216.971875 | train_rmse: 0.3034 | val_rmse: 31.2357 | val_ll: -700.8798
[7:46:45.617231] epoch: 7350 | elbo: 789140.8584374998 | train_rmse: 0.2955 | val_rmse: 31.228 | val_ll: -702.6761
[7:49:39.197797] epoch: 7400 | elbo: 790410.5296875001 | train_rmse: 0.3085 | val_rmse: 31.216 | val_ll: -707.8738
[7:52:34.301789] epoch: 7450 | elbo: 788543.3896875002 | train_rmse: 0.2953 | val_rmse: 31.2032 | val_ll: -709.0716
[7:55:29.253131] epoch: 7500 | elbo: 789771.679375 | train_rmse: 0.3184 | val_rmse: 31.1779 | val_ll: -701.4335
[7:58:23.482924] epoch: 7550 | elbo: 786689.425 | train_rmse: 0.4026 | val_rmse: 31.1678 | val_ll: -704.1401
[8:01:18.262896] epoch: 7600 | elbo: 786787.6590625 | train_rmse: 0.3647 | val_rmse: 31.1433 | val_ll: -685.6972
[8:04:13.032491] epoch: 7650 | elbo: 785833.8362500002 | train_rmse: 0.2902 | val_rmse: 31.1346 | val_ll: -694.1412
[8:07:09.991566] epoch: 7700 | elbo: 786722.4159375001 | train_rmse: 0.3523 | val_rmse: 31.1224 | val_ll: -698.7197
[8:10:07.801807] epoch: 7750 | elbo: 787576.5034374999 | train_rmse: 0.3129 | val_rmse: 31.0986 | val_ll: -701.5159
[8:13:04.760995] epoch: 7800 | elbo: 784091.9803125001 | train_rmse: 0.338 | val_rmse: 31.0909 | val_ll: -706.0692
[8:16:00.974276] epoch: 7850 | elbo: 786585.3212499999 | train_rmse: 0.3086 | val_rmse: 31.0668 | val_ll: -695.1589
[8:18:55.538005] epoch: 7900 | elbo: 784375.2375 | train_rmse: 0.342 | val_rmse: 31.0569 | val_ll: -693.9476
[8:21:49.065710] epoch: 7950 | elbo: 781550.4462499998 | train_rmse: 0.2817 | val_rmse: 31.0475 | val_ll: -693.2381
[8:24:41.829727] epoch: 8000 | elbo: 782688.1365624999 | train_rmse: 0.2939 | val_rmse: 31.0319 | val_ll: -699.2296
[8:27:35.357127] epoch: 8050 | elbo: 786945.0509375 | train_rmse: 0.3086 | val_rmse: 31.0111 | val_ll: -697.3549
[8:30:29.431205] epoch: 8100 | elbo: 782387.9818750002 | train_rmse: 0.3178 | val_rmse: 30.9951 | val_ll: -692.766
[8:33:24.212461] epoch: 8150 | elbo: 783524.4921874998 | train_rmse: 0.3067 | val_rmse: 30.9882 | val_ll: -692.828
[8:36:19.381887] epoch: 8200 | elbo: 779696.3250000002 | train_rmse: 0.3125 | val_rmse: 30.9656 | val_ll: -696.6142
[8:39:13.240886] epoch: 8250 | elbo: 780362.1568749999 | train_rmse: 0.372 | val_rmse: 30.9624 | val_ll: -694.9299
[8:42:08.040273] epoch: 8300 | elbo: 780395.983125 | train_rmse: 0.3598 | val_rmse: 30.9453 | val_ll: -690.5471
[8:45:01.326705] epoch: 8350 | elbo: 779984.0256249999 | train_rmse: 0.2965 | val_rmse: 30.9457 | val_ll: -693.5463
[8:47:55.874603] epoch: 8400 | elbo: 777636.695 | train_rmse: 0.4013 | val_rmse: 30.9358 | val_ll: -688.3524
[8:50:48.438865] epoch: 8450 | elbo: 781171.1353124998 | train_rmse: 0.3115 | val_rmse: 30.9096 | val_ll: -699.6429
[8:53:41.295453] epoch: 8500 | elbo: 778850.7196875003 | train_rmse: 0.318 | val_rmse: 30.903 | val_ll: -692.171
[8:56:34.972489] epoch: 8550 | elbo: 774624.0059374999 | train_rmse: 0.3037 | val_rmse: 30.8959 | val_ll: -687.6044
[8:59:24.834416] epoch: 8600 | elbo: 776519.9506249999 | train_rmse: 0.3006 | val_rmse: 30.867 | val_ll: -693.9415
[9:02:15.424857] epoch: 8650 | elbo: 775086.4703125003 | train_rmse: 0.295 | val_rmse: 30.8627 | val_ll: -682.0564
[9:05:07.002302] epoch: 8700 | elbo: 775548.2590624999 | train_rmse: 0.3259 | val_rmse: 30.8462 | val_ll: -687.0897
[9:07:56.595610] epoch: 8750 | elbo: 773728.6184375 | train_rmse: 0.2921 | val_rmse: 30.8279 | val_ll: -684.1185
[9:10:45.317862] epoch: 8800 | elbo: 775084.666875 | train_rmse: 0.3577 | val_rmse: 30.8283 | val_ll: -688.1828
[9:13:34.510489] epoch: 8850 | elbo: 772245.1375 | train_rmse: 0.325 | val_rmse: 30.8158 | val_ll: -686.875
[9:16:25.280542] epoch: 8900 | elbo: 771195.3453124998 | train_rmse: 0.2707 | val_rmse: 30.7977 | val_ll: -684.7038
[9:19:15.201689] epoch: 8950 | elbo: 774494.3890624999 | train_rmse: 0.3527 | val_rmse: 30.7916 | val_ll: -682.1479
[9:22:04.572792] epoch: 9000 | elbo: 770355.2721875001 | train_rmse: 0.2907 | val_rmse: 30.7803 | val_ll: -678.5519
[9:24:54.554872] epoch: 9050 | elbo: 771953.4646874999 | train_rmse: 0.3026 | val_rmse: 30.7635 | val_ll: -678.7222
[9:27:44.104256] epoch: 9100 | elbo: 770400.9934375 | train_rmse: 0.3032 | val_rmse: 30.754 | val_ll: -684.5336
[9:30:34.231279] epoch: 9150 | elbo: 770346.0796874999 | train_rmse: 0.2926 | val_rmse: 30.7434 | val_ll: -684.1843
[9:33:25.918068] epoch: 9200 | elbo: 770966.7646874998 | train_rmse: 0.4101 | val_rmse: 30.7293 | val_ll: -697.8537
[9:36:16.173579] epoch: 9250 | elbo: 767252.0446875 | train_rmse: 0.2925 | val_rmse: 30.7247 | val_ll: -680.5414
[9:39:05.843603] epoch: 9300 | elbo: 767305.1103124998 | train_rmse: 0.2807 | val_rmse: 30.7136 | val_ll: -676.501
[9:41:57.848724] epoch: 9350 | elbo: 767819.7759374997 | train_rmse: 0.3334 | val_rmse: 30.7063 | val_ll: -678.0621
[9:44:51.480677] epoch: 9400 | elbo: 767572.0025000002 | train_rmse: 0.3053 | val_rmse: 30.6942 | val_ll: -677.5668
[9:47:42.975760] epoch: 9450 | elbo: 765673.0896874999 | train_rmse: 0.2744 | val_rmse: 30.6786 | val_ll: -682.7529
[9:50:35.067430] epoch: 9500 | elbo: 765120.5159375002 | train_rmse: 0.294 | val_rmse: 30.6686 | val_ll: -672.8295
[9:53:27.083334] epoch: 9550 | elbo: 764988.5146875 | train_rmse: 0.3 | val_rmse: 30.6622 | val_ll: -678.2276
[9:56:17.401626] epoch: 9600 | elbo: 765813.5134375001 | train_rmse: 0.2947 | val_rmse: 30.6353 | val_ll: -680.9511
[9:59:09.901246] epoch: 9650 | elbo: 764922.271875 | train_rmse: 0.3577 | val_rmse: 30.6438 | val_ll: -673.4103
[10:02:01.017445] epoch: 9700 | elbo: 760926.1699999999 | train_rmse: 0.2894 | val_rmse: 30.629 | val_ll: -671.7416
[10:04:51.794873] epoch: 9750 | elbo: 762203.7840624999 | train_rmse: 0.3039 | val_rmse: 30.6124 | val_ll: -680.0513
[10:07:41.417139] epoch: 9800 | elbo: 762542.3709374999 | train_rmse: 0.3165 | val_rmse: 30.604 | val_ll: -667.717
[10:10:32.222986] epoch: 9850 | elbo: 762317.6453125 | train_rmse: 0.3065 | val_rmse: 30.591 | val_ll: -684.3828
[10:13:23.719754] epoch: 9900 | elbo: 759667.4915624999 | train_rmse: 0.2829 | val_rmse: 30.5783 | val_ll: -679.1278
[10:16:15.871242] epoch: 9950 | elbo: 759320.725 | train_rmse: 0.2735 | val_rmse: 30.5766 | val_ll: -685.1458
Training finished in 10:19:03.689774 seconds
Saved SVI model to tests/dataset-tests/sineasy10-10k-s03/models/sineasy50-3x256-s03/checkpoint_1.pt
File Size is 1.1103410720825195 MB
data samples:  (1000, 1000)
Sequential(
  (0): Linear(in_features=50, out_features=256, bias=True)
  (1): ReLU()
  (2): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ReLU()
  )
  (3): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ReLU()
  )
  (4): Linear(in_features=256, out_features=1, bias=True)
)
Settings:
DEVICE: cuda:6 INFERENCE_TYPE: svi OBS_MODEL: homoskedastic PRIOR_LOC: 0.0 PRIOR_SCALE: 1.0 LIKELIHOOD_SCALE_LOC: 2.0 LIKELIHOOD_SCALE: 0.3 GUIDE_SCALE: 0.001 TRAIN_SIZE: 20000
Loaded SVI model from tests/dataset-tests/sineasy10-10k-s03/models/sineasy50-3x256-s03/checkpoint_1.pt
using device: cuda:6
====== evaluating profile sineasy50-3x256-s03 - 1 ======
pred samples:  (1000, 1000)
Evaluating train...
tensor([-3.7569], device='cuda:6')
tensor([[ -3.7151],
        [ -2.3013],
        [  4.6993],
        ...,
        [ 21.0637],
        [-34.4243],
        [ 25.7933]], device='cuda:6')
tensor(-0.3000, device='cuda:6')
tensor([4.5518], device='cuda:6')
tensor([[  4.5270],
        [ 11.8360],
        [ 30.6013],
        ...,
        [-21.8626],
        [ -5.2300],
        [-41.2217]], device='cuda:6')
tensor(0.5505, device='cuda:6')
tensor([-18.4779], device='cuda:6')
tensor([[-18.4575],
        [-19.6989],
        [ 12.5309],
        ...,
        [ -8.8143],
        [ 32.4462],
        [  7.6902]], device='cuda:6')
tensor(-0.9698, device='cuda:6')
tensor([25.4320], device='cuda:6')
tensor([[ 25.4332],
        [ -6.8750],
        [-21.5326],
        ...,
        [ -3.4378],
        [-18.1321],
        [  8.7247]], device='cuda:6')
tensor(1.2211, device='cuda:6')
tensor([13.2497], device='cuda:6')
tensor([[ 13.2419],
        [-47.6562],
        [ 32.5492],
        ...,
        [ -7.8097],
        [-20.8797],
        [ 23.6066]], device='cuda:6')
tensor(-0.0414, device='cuda:6')
tensor([-39.7449], device='cuda:6')
tensor([[-39.7439],
        [-45.1708],
        [  0.8940],
        ...,
        [  4.4872],
        [ -4.6731],
        [ 24.3540]], device='cuda:6')
tensor(0.8784, device='cuda:6')
tensor([17.4225], device='cuda:6')
tensor([[17.4895],
        [ 6.5742],
        [15.2283],
        ...,
        [14.9358],
        [17.3264],
        [35.4055]], device='cuda:6')
tensor(-2.1833, device='cuda:6')
tensor([-25.5734], device='cuda:6')
tensor([[-25.6085],
        [  8.7497],
        [  2.8915],
        ...,
        [ 10.3583],
        [  9.8300],
        [ 17.5121]], device='cuda:6')
tensor(0.4191, device='cuda:6')
tensor([-2.3603], device='cuda:6')
tensor([[ -2.3262],
        [ 15.4353],
        [-29.2866],
        ...,
        [  7.2716],
        [  5.6298],
        [ -4.8440]], device='cuda:6')
tensor(-0.3991, device='cuda:6')
tensor([7.9215], device='cuda:6')
tensor([[  7.9411],
        [ 27.9715],
        [-50.5915],
        ...,
        [  6.8547],
        [ 25.0810],
        [-12.5163]], device='cuda:6')
tensor(0.3511, device='cuda:6')
tensor([6.7474], device='cuda:6')
tensor([[  6.7465],
        [ 47.7043],
        [-33.7466],
        ...,
        [-25.7203],
        [ 40.2429],
        [ 53.9112]], device='cuda:6')
tensor(-0.0858, device='cuda:6')
tensor([-51.7995], device='cuda:6')
tensor([[-51.8264],
        [ 10.7915],
        [ 20.9098],
        ...,
        [ 11.7541],
        [ 49.8840],
        [ -9.4393]], device='cuda:6')
tensor(0.1133, device='cuda:6')
tensor([-19.4528], device='cuda:6')
tensor([[-19.4949],
        [ 31.8445],
        [ 43.9906],
        ...,
        [  5.4533],
        [  8.3163],
        [ 13.2790]], device='cuda:6')
tensor(0.3581, device='cuda:6')
tensor([6.0001], device='cuda:6')
tensor([[  6.0133],
        [-10.1734],
        [  9.2655],
        ...,
        [-35.8111],
        [  1.6318],
        [  3.9780]], device='cuda:6')
tensor(1.0391, device='cuda:6')
tensor([26.1350], device='cuda:6')
tensor([[ 26.1215],
        [ 36.5311],
        [-28.8638],
        ...,
        [-41.7070],
        [ 14.1973],
        [ -3.8762]], device='cuda:6')
tensor(0.4333, device='cuda:6')
tensor([-19.2342], device='cuda:6')
tensor([[-19.2961],
        [ 24.9579],
        [-11.1507],
        ...,
        [ -2.3489],
        [  1.7490],
        [ -9.4526]], device='cuda:6')
tensor(-0.6880, device='cuda:6')
tensor([-9.2958], device='cuda:6')
tensor([[ -9.2642],
        [-25.0494],
        [  8.2031],
        ...,
        [-13.9280],
        [ -5.3249],
        [ -2.1669]], device='cuda:6')
tensor(1.6099, device='cuda:6')
tensor([34.0890], device='cuda:6')
tensor([[ 34.1704],
        [ 17.4309],
        [ -2.7882],
        ...,
        [-12.2783],
        [-18.3467],
        [ -5.8488]], device='cuda:6')
tensor(1.1775, device='cuda:6')
tensor([8.2677], device='cuda:6')
tensor([[  8.2744],
        [-26.5112],
        [  2.9677],
        ...,
        [-20.0168],
        [-12.5636],
        [-19.0440]], device='cuda:6')
tensor(1.0266, device='cuda:6')
tensor([-11.8883], device='cuda:6')
tensor([[-11.9254],
        [ 15.8707],
        [ 29.3877],
        [-45.6187],
        [ -3.7502],
        [ 15.3465],
        [ 27.8752],
        [  3.3946],
        [ 41.9156],
        [ 20.7281],
        [  9.8464],
        [-17.5770],
        [ 36.7852],
        [  8.9619],
        [-11.2566],
        [ 11.5683],
        [  8.8514],
        [ -1.7229],
        [-31.1066],
        [  8.7822],
        [-17.5255],
        [ -9.1276],
        [-14.0500],
        [ 14.8543],
        [  0.1787],
        [ 20.5605],
        [ 29.8171],
        [-32.9280],
        [-47.8746],
        [ 10.6049],
        [ 24.8321],
        [  9.9553],
        [-24.1428],
        [ -9.3675],
        [ -8.3666],
        [ 25.7578],
        [-21.1817],
        [-24.8580],
        [ 39.8909],
        [ -7.5578],
        [-37.2421],
        [ 11.7302],
        [-21.1419],
        [-24.9605],
        [-35.4713],
        [ 16.6563],
        [ -3.2024],
        [ 17.9896],
        [ 45.5832],
        [ 28.6409],
        [  6.4461],
        [-17.9187],
        [ -1.0565],
        [ 31.1128],
        [-12.6657],
        [ -3.5309],
        [ 41.5180],
        [-36.5000],
        [-10.9741],
        [ -2.5142],
        [ 10.7367],
        [ 26.4679],
        [ 18.9694],
        [-11.9690],
        [ -4.4555],
        [ -5.0244],
        [-19.5870],
        [ -5.8122],
        [  4.4689],
        [-11.3676],
        [-57.4327],
        [-24.3298],
        [  5.0183],
        [-24.5034],
        [-22.0790],
        [-27.5070],
        [  2.1575],
        [ 20.6152],
        [-39.2149],
        [  6.0722],
        [-26.0453],
        [-27.1899],
        [-62.8397],
        [-21.6881],
        [-12.3629],
        [-10.9670],
        [ 36.2118],
        [ 27.1027],
        [ -4.5178],
        [-19.1894],
        [ 29.8287],
        [-54.9445],
        [ 39.1355],
        [ -7.4483],
        [-25.8273],
        [ 41.1716],
        [-31.4879],
        [-24.3099],
        [-21.4067],
        [ 22.0206],
        [  5.2491],
        [ 31.0892],
        [-14.1301],
        [  7.4752],
        [  9.1274],
        [  5.5275],
        [-45.5964],
        [ 40.4363],
        [-60.8433],
        [ -1.5138],
        [-17.9915],
        [-26.8511],
        [ -9.4649],
        [-12.0391],
        [-67.4688],
        [ 57.8040],
        [-13.7128],
        [-13.2984],
        [ 18.4512],
        [-10.4364],
        [ 36.7956],
        [-17.4211],
        [-53.5530],
        [-32.4653],
        [-17.0792],
        [-47.8608],
        [-13.3171],
        [ -8.1973],
        [ -2.1463],
        [-10.8094],
        [  6.5424],
        [-33.1172],
        [  4.6197],
        [ 75.6630],
        [ -1.8010],
        [ -2.2167],
        [-53.8108],
        [ 10.7155],
        [ 84.1059],
        [-14.5731],
        [  6.7911],
        [ -2.0476],
        [  7.9088],
        [-24.4268],
        [-31.4661],
        [ 13.7356],
        [-78.5270],
        [-31.8080],
        [ 30.5685],
        [ -8.1660],
        [-10.9608],
        [ 11.3483],
        [ 44.2103],
        [-36.4866],
        [ -2.9185],
        [-63.0593],
        [ -3.2645],
        [ 23.7613],
        [ 40.2985],
        [  3.3565],
        [ 35.8136],
        [-19.2842],
        [-14.9497],
        [-30.7973],
        [  3.7093],
        [ 15.8023],
        [-14.5594],
        [-18.2061],
        [ 31.1021],
        [ 14.6982],
        [-19.6599],
        [ 37.9261],
        [-18.9494],
        [-10.5170],
        [-21.7273],
        [  2.0645],
        [-30.4470],
        [ -9.3989],
        [-71.0500],
        [ 52.3838],
        [-10.3685],
        [-54.3679],
        [  2.0999],
        [-27.7704],
        [ 56.0467],
        [  0.2801],
        [  9.6737],
        [ 21.9152],
        [-26.4263],
        [ -8.1247],
        [-16.9654],
        [-19.8534],
        [-58.8845],
        [ 30.7018],
        [ 26.3882],
        [ 10.6819],
        [ -5.4389],
        [ 33.7895],
        [  4.1765],
        [  8.6365],
        [-60.7754],
        [-40.4337],
        [-28.1654],
        [-15.8641],
        [-26.1442],
        [  2.3332],
        [-31.4641],
        [-10.9636],
        [-12.8494],
        [ 32.5424],
        [-31.0393],
        [-19.1851],
        [-27.1162],
        [ 15.4182],
        [-38.1069],
        [  5.4875],
        [-19.4200],
        [-21.6015],
        [ -9.5517],
        [ 46.1330],
        [-12.3805],
        [-32.8790],
        [ 10.5609],
        [ 45.3904],
        [-20.7825],
        [  1.5609],
        [-15.6423],
        [ 54.9661],
        [-25.9815],
        [ 18.4682],
        [ 32.6173],
        [ 11.5172],
        [  1.9684],
        [ -3.0873],
        [  0.7691],
        [ 30.7283],
        [  4.1596],
        [-34.7167],
        [ -9.0887],
        [  8.6876],
        [-14.7141],
        [ 38.1496],
        [ 11.3863],
        [-18.0864],
        [-10.4910],
        [ -1.6601],
        [-17.9672],
        [ 22.9566],
        [ 14.0212],
        [ 12.8229],
        [-34.1283],
        [ -5.4038],
        [-10.6637],
        [  4.3376],
        [ -7.5057],
        [ -1.0199],
        [-17.0196],
        [-35.1183],
        [ 35.6652],
        [-24.7272],
        [  9.2682],
        [ 19.6331],
        [  7.6138],
        [ 11.4447],
        [ 30.3298],
        [-14.5506],
        [ 36.1857],
        [-16.0814],
        [-11.6462],
        [-74.7324],
        [ 55.2004],
        [-15.9124],
        [ -1.5641],
        [  2.0636],
        [ -7.7612],
        [-35.5304],
        [-12.2242],
        [-27.6346],
        [ 14.3098],
        [ 23.2218],
        [-20.2287],
        [  1.5657],
        [-41.2473],
        [-12.8214],
        [-46.4807],
        [-18.1890],
        [ -3.8191],
        [ 36.2157],
        [-16.0624],
        [ -2.4511],
        [ 46.8821],
        [-15.0704],
        [  2.1546],
        [-22.1880],
        [ 17.4146],
        [ 17.6431],
        [ 57.5986],
        [ 12.8387],
        [  4.9154],
        [  9.8751],
        [-18.6844],
        [-31.7600],
        [-18.3888],
        [-17.2037],
        [ -6.8968],
        [ 18.2325],
        [ 15.2335],
        [ -6.1690],
        [-10.6684],
        [ -1.6340],
        [-19.0098],
        [ 45.4761],
        [ -8.6441],
        [ 18.1980],
        [  4.4916],
        [-43.2673],
        [ -8.9442],
        [ 39.1994],
        [ 21.2787],
        [ 15.1794],
        [  2.0312],
        [-11.2339],
        [-37.2427],
        [  3.1968],
        [ -7.6412],
        [ 20.7874],
        [ 12.4523],
        [ -5.6852],
        [ 11.2642],
        [-11.6302],
        [ 21.5562],
        [ -3.0359],
        [ 44.4168],
        [-59.5931],
        [  8.8252],
        [-13.1561],
        [  8.5224],
        [ 10.5124],
        [ 29.2900],
        [-21.2236],
        [ 59.3472],
        [-42.6650],
        [ -6.7279],
        [ 39.7131],
        [-47.4941],
        [  9.3683],
        [  0.7457],
        [  7.9408],
        [ 36.7156],
        [ 12.7007],
        [  2.4864],
        [ 22.5674],
        [-20.6855],
        [ 12.8253],
        [  1.0089],
        [ -1.0830],
        [ 19.7029],
        [  4.9538],
        [  7.9084],
        [ -0.6405],
        [ -2.5284],
        [ 23.6515],
        [ 11.5273],
        [ -3.4285],
        [-27.1285],
        [-16.0142],
        [  4.6345],
        [-10.2821],
        [-27.2505],
        [ 17.9764],
        [ -0.9524],
        [-10.6909],
        [-24.6720],
        [ 20.5653],
        [-33.7214],
        [ 24.8317],
        [  6.7589],
        [ 28.9281],
        [ 10.8691],
        [ -8.5206],
        [  1.1468],
        [ 24.7095],
        [ 31.3023],
        [-20.8787],
        [ -7.5539],
        [  7.6514],
        [ -4.3884],
        [-22.0259],
        [ 18.5917],
        [ -2.2311],
        [ 11.0639],
        [-21.3671],
        [-13.2434],
        [ 38.7469],
        [ -8.2082],
        [-15.0385],
        [  7.9945],
        [-22.4497],
        [-45.4805],
        [-42.5846],
        [ 40.3738],
        [-23.4578],
        [-35.0843],
        [ 25.0832],
        [-33.3636],
        [  4.7198],
        [  8.5869],
        [  1.4089],
        [  4.4021],
        [-10.4489],
        [ -3.7855],
        [ 32.7961],
        [ 14.6691],
        [ 13.2558],
        [-18.0151],
        [ 18.0406],
        [  2.9524],
        [  2.8369],
        [-36.4087],
        [ 10.5895],
        [-12.9133],
        [ -5.4736],
        [ 43.1107],
        [-23.5261],
        [ -6.8422],
        [ 22.5627],
        [ -6.5662],
        [ 25.2767],
        [-10.2870],
        [-34.7731],
        [  7.4846],
        [-29.4159],
        [-30.6223],
        [-26.2069],
        [ 28.2018],
        [ 13.7274],
        [ -5.9611],
        [-60.1911],
        [  9.8451],
        [  8.0601],
        [  2.7471],
        [ 22.3674],
        [ -2.9539],
        [-46.6004],
        [ 14.1578],
        [-29.1171],
        [-24.9072],
        [-46.5974],
        [-31.6218],
        [ 22.0280],
        [-26.6740],
        [  4.8807],
        [ 36.0980],
        [-20.2927],
        [  9.8650],
        [-22.1912],
        [-28.9089],
        [ -7.9230],
        [  8.1230],
        [-19.2288],
        [ -7.6381],
        [ 26.9946],
        [ -7.3934],
        [-14.0995],
        [ 22.2735],
        [ 22.8325],
        [  7.1474],
        [  6.6535],
        [ 13.5860],
        [ 16.0101],
        [-30.1584],
        [ 11.0507],
        [ 40.3958],
        [ -7.2959],
        [-27.2753],
        [ 26.0846],
        [  4.8345],
        [  0.3731],
        [ -1.1152],
        [ -8.1239],
        [  7.7935],
        [  8.3530],
        [-41.9618],
        [  8.7300],
        [-36.2612],
        [ -2.6432],
        [ 17.5693],
        [ 15.9451],
        [-16.5769],
        [-17.9722],
        [ -2.4490],
        [-17.6071],
        [ 15.1235],
        [ -7.1985],
        [-35.5398],
        [ 33.6127],
        [ -2.0849],
        [ -8.9010],
        [-41.9201],
        [-21.4416],
        [  8.9181],
        [  1.8258],
        [-36.7033],
        [ 10.3238],
        [  5.3410],
        [  2.7168],
        [ 27.8798],
        [-23.0405],
        [ -9.0988],
        [-37.2679],
        [-31.2258],
        [ 24.9717],
        [-13.0696],
        [-17.1505],
        [-34.1690],
        [ -8.4066],
        [ 16.6170],
        [ 11.2695],
        [ 25.6031],
        [-22.8382],
        [  6.2579],
        [ 12.7208],
        [ 29.6048],
        [ -9.1987],
        [-14.7432],
        [ 29.8348],
        [ -6.9944],
        [-12.2269],
        [-32.9791],
        [-10.7386],
        [  6.6502],
        [ 14.1878],
        [ 47.0083],
        [ -5.3935],
        [ 28.8770],
        [-20.7958],
        [  3.2104],
        [ 17.0918],
        [ 14.8553],
        [ 34.0537],
        [  4.4628],
        [-19.5907],
        [-12.3338],
        [-28.7113]], device='cuda:6')
tensor(-2.3614, device='cuda:6')
Evaluating test...
tensor([18.4879], device='cuda:6')
tensor([[ 18.4804],
        [ 24.2125],
        [-13.9626],
        ...,
        [-62.3528],
        [ 36.7132],
        [-26.4220]], device='cuda:6')
tensor(-0.2559, device='cuda:6')
tensor([121.9454], device='cuda:6')
tensor([[ 1.2184e+02],
        [ 8.2738e+00],
        [-6.1465e+00],
        ...,
        [ 2.3892e+00],
        [ 3.1015e+01],
        [ 7.4266e-02]], device='cuda:6')
tensor(0.4097, device='cuda:6')
tensor([-56.2933], device='cuda:6')
tensor([[-56.3455],
        [ 12.2680],
        [-26.0422],
        ...,
        [-34.9572],
        [  9.0775],
        [117.5940]], device='cuda:6')
tensor(0.9807, device='cuda:6')
tensor([2.1056], device='cuda:6')
tensor([[  2.1314],
        [  7.7436],
        [  1.4828],
        ...,
        [-54.0104],
        [  6.1171],
        [  7.3749]], device='cuda:6')
tensor(1.0716, device='cuda:6')
tensor([8.4854], device='cuda:6')
tensor([[  8.4547],
        [ -1.5009],
        [-27.1142],
        ...,
        [-24.3251],
        [ 27.2566],
        [ 25.9445]], device='cuda:6')
tensor(3.2976, device='cuda:6')
tensor([-5.9507], device='cuda:6')
tensor([[ -6.0358],
        [  9.4121],
        [ -9.0859],
        ...,
        [-22.2590],
        [-15.9560],
        [ 20.5568]], device='cuda:6')
tensor(1.3451, device='cuda:6')
tensor([1.8156], device='cuda:6')
tensor([[  1.7532],
        [ 13.9461],
        [  8.0933],
        ...,
        [  3.0350],
        [-66.0286],
        [115.1231]], device='cuda:6')
tensor(-1.5790, device='cuda:6')
tensor([51.0244], device='cuda:6')
tensor([[ 51.0603],
        [ 40.7875],
        [-54.6176],
        ...,
        [-48.4706],
        [ 20.5997],
        [ -7.6961]], device='cuda:6')
tensor(0.0512, device='cuda:6')
tensor([-8.5880], device='cuda:6')
tensor([[ -8.5775],
        [-13.9472],
        [-66.6972],
        ...,
        [ 21.3514],
        [-54.0638],
        [ 32.0155]], device='cuda:6')
tensor(-0.2040, device='cuda:6')
tensor([35.0254], device='cuda:6')
tensor([[ 3.4981e+01],
        [ 2.7996e+01],
        [-1.2101e+02],
        [-9.7091e+00],
        [-9.7474e+00],
        [ 9.6757e+00],
        [-2.1365e+01],
        [ 2.0855e+01],
        [-3.9732e+01],
        [-3.2540e+01],
        [-9.8698e+00],
        [ 5.1073e+01],
        [-1.3585e+01],
        [-4.1537e+01],
        [-5.5885e+01],
        [ 2.6495e+01],
        [-3.4216e-01],
        [ 1.8005e+01],
        [-5.5132e+01],
        [-3.1723e+01],
        [ 3.7242e+00],
        [-2.4405e+01],
        [ 3.0019e+01],
        [ 5.5985e+00],
        [-1.6721e+01],
        [ 2.9773e+01],
        [-5.1935e+01],
        [ 3.0881e+00],
        [-7.6639e+00],
        [ 1.6698e+01],
        [-7.1551e+00],
        [ 3.3669e+01],
        [ 9.2378e-01],
        [-1.3135e+00],
        [ 1.8337e+01],
        [-1.9316e+00],
        [-1.9431e+01],
        [-4.1506e+00],
        [ 3.6877e+01],
        [-1.4101e+01],
        [-7.0092e+01],
        [ 6.8716e+01],
        [ 4.0702e+01],
        [-2.0960e+01],
        [-1.0855e+01],
        [-1.6078e+01],
        [-1.4170e+01],
        [ 2.1991e+01],
        [-2.2810e+01],
        [ 1.3635e+00],
        [-5.7757e+01],
        [ 6.9738e+00],
        [-8.5744e-01],
        [ 7.1219e+01],
        [-2.4581e+00],
        [ 9.7600e+00],
        [ 1.0174e+01],
        [ 4.2532e+01],
        [ 4.1182e+01],
        [ 4.5855e+01],
        [ 1.8710e+02],
        [-5.1258e+00],
        [ 4.6976e+00],
        [-3.6007e+01],
        [-2.4254e+01],
        [ 1.6813e+01],
        [-9.0043e+00],
        [-4.3075e+01],
        [-2.7353e+01],
        [-2.2745e+01],
        [-1.3964e+01],
        [-4.4704e+01],
        [ 6.8371e+01],
        [ 3.9604e+01],
        [ 1.0656e+01],
        [ 5.9327e+01],
        [ 1.7146e+01],
        [ 3.6185e+00],
        [-3.7143e+01],
        [ 3.2437e+01],
        [ 4.8505e+01],
        [ 7.6355e+00],
        [ 7.2446e+01],
        [ 5.0981e+00],
        [ 1.0042e+01],
        [-7.0554e+00],
        [ 6.3797e+00],
        [-1.9935e+01],
        [ 1.2478e+01],
        [-2.5760e+01],
        [ 4.0388e+01],
        [ 1.4720e+01],
        [ 4.5788e+01],
        [-8.8756e+01],
        [-1.5363e+01],
        [-1.2568e+00],
        [-5.7626e+01],
        [ 2.6040e+01],
        [ 4.5841e+00],
        [-3.4675e-02],
        [ 9.1960e+00],
        [ 1.8651e+01],
        [ 1.0301e+01],
        [-8.1679e+00],
        [-3.3258e+01],
        [ 2.3038e+01],
        [-6.0544e+00],
        [ 5.5851e+01],
        [-3.9655e+01],
        [-2.2255e+01],
        [-3.2599e+01],
        [ 4.1953e+01],
        [ 8.7010e+00],
        [-3.1694e+01],
        [ 3.1220e+01],
        [ 5.0403e+01],
        [-1.5752e+01],
        [ 1.7468e+01],
        [-5.5275e+01],
        [ 6.7838e+01],
        [-4.6024e+00],
        [ 1.5270e+01],
        [ 3.4967e+01],
        [ 1.3577e+02],
        [ 7.9258e+01],
        [-4.0320e+01],
        [ 5.0994e+01],
        [ 1.0595e+01],
        [-2.0259e+01],
        [-5.2863e+01],
        [-2.3115e+00],
        [-8.4581e+01],
        [ 1.3279e+01],
        [-8.9645e+00],
        [ 4.8732e+01],
        [-1.2036e+01],
        [ 4.3423e+01],
        [-7.5091e+01],
        [-1.4826e+01],
        [ 1.4470e+01],
        [ 1.0313e+01],
        [ 7.4594e+01],
        [ 2.2820e+01],
        [ 6.9996e+01],
        [-3.7476e+00],
        [ 1.9307e+01],
        [ 9.4093e+00],
        [ 2.6544e+01],
        [-2.0698e+01],
        [-1.8022e+00],
        [-2.1180e+01],
        [-4.6772e+00],
        [ 2.6582e+01],
        [ 2.6933e+00],
        [-1.7066e+01],
        [-7.5216e+01],
        [-3.5983e+01],
        [-6.4488e+00],
        [ 6.8246e+01],
        [ 1.4732e+01],
        [ 1.8007e+01],
        [ 5.2309e+01],
        [-8.8612e+00],
        [ 7.9432e-01],
        [ 2.2431e+01],
        [-4.3980e+00],
        [-6.5357e+01],
        [-4.5144e+00],
        [-8.9688e+00],
        [ 6.8488e+01],
        [ 3.1478e+01],
        [ 8.3807e+00],
        [-2.2124e+01],
        [ 1.8091e+01],
        [-1.7175e+01],
        [ 2.0027e+01],
        [ 1.2842e+01],
        [ 5.9455e+01],
        [ 6.8129e+00],
        [-1.5081e+01],
        [ 3.0292e+01],
        [-2.5487e+01],
        [-8.4933e+01],
        [ 8.4704e+00],
        [ 1.8419e+01],
        [ 4.1981e+01],
        [-1.8216e+00],
        [ 4.7417e+00],
        [-4.3346e+01],
        [-6.6060e+01],
        [-2.0267e+01],
        [-2.7703e+01],
        [-9.0429e+00],
        [ 3.2798e+01],
        [ 2.2355e-01],
        [-4.3040e+00],
        [-2.3031e+01],
        [-5.0835e-01],
        [-3.4024e+01],
        [-2.3490e+01],
        [-3.4378e+01],
        [-1.1244e+01],
        [ 7.3073e+00],
        [-5.5737e-01],
        [ 1.6724e+01],
        [ 2.7278e+01],
        [ 3.1386e+01],
        [ 1.9362e+01],
        [ 3.9672e+00],
        [-3.2661e+01],
        [ 2.1338e+01],
        [ 1.1278e+01],
        [-1.4625e+01],
        [ 5.2877e+01],
        [ 1.1269e+01],
        [ 6.3279e+01],
        [ 6.7691e+00],
        [ 4.9852e-01],
        [-3.9390e+00],
        [ 1.0334e+01],
        [-4.7684e+01],
        [-3.2595e+01],
        [-2.0464e+00],
        [-1.0611e+02],
        [-7.5250e+00],
        [-3.7803e+00],
        [ 2.5528e+01],
        [ 3.7482e+01],
        [-9.5772e+01],
        [-9.0053e+00],
        [ 2.7178e+01],
        [ 4.5711e+01],
        [ 2.5548e+01],
        [-1.8079e+01],
        [-1.0115e+01],
        [ 7.6396e+01],
        [ 1.0354e+01],
        [-3.2639e+01],
        [-3.0476e+01],
        [ 3.2129e+00],
        [ 1.4892e+01],
        [ 1.8032e+01],
        [ 3.7919e+01],
        [-3.7278e+01],
        [ 2.5328e+01],
        [ 8.5430e+00],
        [ 5.9638e+01],
        [ 4.4362e+01],
        [-1.1537e+01],
        [ 1.4573e+01],
        [ 8.2371e+00],
        [ 8.3943e+00],
        [-8.4682e+01],
        [-2.3607e+01],
        [-1.8087e+02],
        [-3.2234e+01],
        [ 2.3173e+01],
        [-1.5216e+01],
        [-9.9833e+00],
        [ 7.2371e+00],
        [ 3.3255e+00],
        [-6.8957e+01],
        [ 1.1622e+01],
        [-6.8543e+00],
        [ 4.2378e+00],
        [-7.7544e+00],
        [ 3.9051e+01],
        [ 2.9574e+01],
        [-4.8869e+01],
        [-1.1098e+02],
        [ 2.2148e+01],
        [ 1.6013e+02],
        [ 2.3756e+01],
        [-4.5731e+01],
        [ 1.2089e+02],
        [ 1.5924e+01],
        [ 4.9181e+01],
        [-6.0553e+01],
        [-6.2419e+00],
        [ 1.1910e+01],
        [ 1.3598e+01],
        [ 7.7927e+00],
        [ 5.6700e+01],
        [-3.5085e+00],
        [ 8.9727e+01],
        [ 8.2351e+00],
        [ 6.3025e+01],
        [ 1.1996e+02],
        [ 2.8240e+01],
        [-5.1845e+00],
        [ 2.0113e+00],
        [ 1.1037e+01],
        [ 5.4131e+00],
        [-1.0411e+01],
        [-7.5941e-01],
        [-9.3341e+01],
        [ 3.9313e+01],
        [ 1.4820e+01],
        [-5.5154e+01],
        [ 3.0918e+01],
        [ 1.7230e+01],
        [-4.9782e+01],
        [-4.6722e+01],
        [ 2.9379e+01],
        [ 1.4618e+01],
        [ 2.7477e+01],
        [-3.3840e+01],
        [ 1.9420e+01],
        [-7.3348e+01],
        [ 5.3536e+00],
        [-3.1293e+01],
        [-9.3398e+00],
        [ 4.4226e+00],
        [-2.2525e+01],
        [ 9.1665e+00],
        [ 2.3827e+01],
        [-3.0782e+00],
        [-4.7563e+00],
        [ 6.9437e+01],
        [-3.9573e+01],
        [ 1.0176e+02],
        [-3.9717e+01],
        [-3.9591e+01],
        [-7.7092e+00],
        [ 2.2065e+01],
        [-1.4828e+01],
        [-1.3971e+01],
        [ 8.5542e+00],
        [-2.6734e+01],
        [ 2.7771e+01],
        [ 4.8705e+01],
        [ 9.4328e+00],
        [-5.0871e+01],
        [-1.1188e+01],
        [-5.0502e+01],
        [-8.1406e+01],
        [ 1.3501e+01],
        [-9.1029e+01],
        [-2.0397e+00],
        [ 2.7053e+01],
        [ 2.3238e+01],
        [-1.7779e+01],
        [-7.1104e+00],
        [ 4.3815e+01],
        [ 2.9604e+00],
        [ 4.1930e+01],
        [ 3.0791e+01],
        [ 1.5379e+01],
        [ 2.3509e+01],
        [ 3.7627e+01],
        [-6.8387e+01],
        [-1.4803e+01],
        [ 1.0156e+01],
        [-1.5982e+01],
        [ 1.5046e+01],
        [ 2.7544e+01],
        [ 8.7101e+00],
        [-4.0077e+01],
        [-6.3353e+00],
        [-2.2416e+01],
        [ 2.3481e+01],
        [ 1.5646e+01],
        [ 4.7780e+00],
        [-4.8175e+01],
        [ 3.0437e+00],
        [ 4.0557e+01],
        [-3.5591e+00],
        [ 7.6844e+00],
        [-3.2012e+01],
        [ 2.6947e+01],
        [ 2.0166e+01],
        [-9.5993e+00],
        [-3.0912e+01],
        [-6.9978e+01],
        [ 1.6058e+01],
        [-1.9883e+01],
        [-4.7294e+00],
        [ 3.3285e+01],
        [ 5.1594e+00],
        [ 2.7290e+01],
        [-6.9692e+01],
        [-9.4256e+00],
        [-2.1998e-01],
        [ 1.5225e+01],
        [-1.8414e+01],
        [ 3.5830e+01],
        [-2.1913e+01],
        [-6.4849e+00],
        [ 7.0652e+00],
        [ 2.9149e+01],
        [ 2.2605e+00],
        [ 2.1323e+01],
        [-8.6781e+00],
        [-1.4302e+01],
        [ 1.0713e+01],
        [ 7.0865e+00],
        [-6.8893e+00],
        [ 6.8731e+00],
        [ 3.1954e+01],
        [-3.4530e+00],
        [ 4.5544e+00],
        [ 1.9590e+01],
        [ 6.5478e+01],
        [-7.5888e+01],
        [-1.3593e-01],
        [ 2.7150e+01],
        [ 2.5663e+00],
        [-3.7153e+01],
        [-2.8959e+01],
        [ 1.4528e+02],
        [-5.6049e+00],
        [ 4.3398e+01],
        [-3.4914e+01],
        [ 7.9110e+00],
        [ 1.0011e+01],
        [-6.3083e+01],
        [ 8.2864e+00],
        [ 4.5636e+00],
        [-3.6527e-01],
        [-8.7958e+00],
        [-1.4142e+01],
        [ 1.6580e+01],
        [-9.4355e+00],
        [ 8.6362e-02],
        [-1.6168e+00],
        [-7.0311e+01],
        [ 1.2908e+01],
        [ 1.0942e+01],
        [ 4.6598e+01],
        [ 1.2539e+02],
        [-6.0872e+01],
        [ 6.8226e+01],
        [-2.8992e+01],
        [ 4.5699e+00],
        [-9.8180e-01],
        [-5.1851e-01],
        [-8.1386e+01],
        [-9.2713e+00],
        [ 2.6876e+01],
        [ 1.9753e+00],
        [-2.1162e+01],
        [ 8.7613e+00],
        [-7.3958e+01],
        [ 4.1090e+00],
        [-1.1253e+01],
        [-5.1925e+01],
        [-2.4351e+01],
        [ 1.6209e+01],
        [-3.0469e+01],
        [-4.9087e+01],
        [-6.2377e+01],
        [ 1.0078e+01],
        [-4.7931e+01],
        [ 2.4531e+01],
        [ 9.2987e+00],
        [-4.9238e-01],
        [-3.7286e+01],
        [-3.2651e+01],
        [ 6.9749e+00],
        [ 7.0328e+00],
        [-4.6473e+00],
        [-2.3445e+01],
        [-2.2393e+00],
        [ 3.0679e+01],
        [ 1.6517e+01],
        [-2.0957e+01],
        [ 1.1969e+01],
        [-2.0093e+01],
        [-1.1825e+01],
        [-2.5838e+01],
        [-4.5415e+01],
        [-2.4286e+01],
        [-1.0489e+02],
        [ 2.4017e+00],
        [-1.4325e+01],
        [ 4.4349e+00],
        [ 1.9544e+01],
        [ 3.9751e+00],
        [-1.7798e+01],
        [ 3.9343e+01],
        [-2.5017e+01],
        [ 1.8736e+01],
        [ 1.5207e+01],
        [-2.0338e+00],
        [ 4.0659e+00],
        [-1.5630e+01],
        [-8.3471e+00],
        [ 2.3879e+01],
        [-1.3602e+01],
        [ 7.0136e+00],
        [-1.6713e+01],
        [ 1.0026e+02],
        [ 3.0868e+01],
        [-6.2343e+01],
        [ 1.1747e+01],
        [ 2.6951e+00],
        [ 1.0068e+02],
        [ 1.1192e+02],
        [ 1.6886e+01],
        [ 4.4647e+00],
        [ 6.8735e-01],
        [ 7.6808e+00],
        [ 6.5868e+00],
        [ 2.5772e+01],
        [-3.1646e+01],
        [ 5.2857e+01],
        [ 1.3775e+01],
        [ 1.5819e+01],
        [ 1.4648e+01],
        [ 1.9570e+01],
        [ 1.8169e+00],
        [ 1.4627e+01],
        [-2.3447e+01],
        [ 5.3183e+01],
        [ 1.4527e+01],
        [ 1.9013e+01],
        [ 2.5109e+01],
        [-6.7331e+00],
        [ 4.0314e+00],
        [-1.5293e+01],
        [-2.1910e+01],
        [ 1.2664e+01],
        [ 4.2996e+01],
        [ 4.6970e+01],
        [-8.1371e+01],
        [-3.8229e+01],
        [-7.4123e+00],
        [ 2.8215e+01],
        [-5.2681e+01],
        [ 8.4536e+01],
        [ 1.5003e+02],
        [ 2.0147e+01],
        [ 1.6122e+00],
        [ 1.3965e+01],
        [ 1.7275e+01],
        [-5.9881e+01],
        [ 5.7828e+01],
        [ 8.2854e+00],
        [ 7.4589e+00],
        [ 1.5227e+01],
        [-3.2667e+01],
        [ 3.8112e+00],
        [ 5.5689e+01],
        [ 1.1373e+02],
        [ 1.2618e+01],
        [-2.3991e+01],
        [ 1.0009e+01],
        [-1.6667e+01],
        [ 6.3066e+01],
        [-5.0590e+00],
        [-2.3140e+00],
        [-1.2177e+01],
        [-1.6300e+01],
        [-1.4352e+01],
        [ 1.2849e+01],
        [-8.5708e+01],
        [ 1.1519e+01],
        [-1.4981e+01],
        [ 1.0525e+01],
        [ 8.3811e+00],
        [ 2.9853e+01],
        [ 6.7110e+01],
        [-3.9065e+01],
        [ 6.4504e+00],
        [ 1.4376e+01],
        [-2.1471e+01],
        [-1.0334e+02],
        [-5.2824e+01],
        [ 2.0463e+01],
        [ 3.3993e+01],
        [ 1.6971e+01],
        [ 4.5177e+00],
        [ 2.6037e+01],
        [ 7.9556e+00],
        [-2.9204e+01],
        [ 5.2016e+01],
        [ 5.7067e+01],
        [ 8.8054e+01],
        [ 2.9825e+01],
        [ 1.5840e+01],
        [ 1.3992e+02],
        [-7.0398e+00],
        [-1.2540e+01],
        [ 3.5826e+01],
        [ 2.5376e+01],
        [-1.0435e+01],
        [-1.7246e+01],
        [ 2.0773e+01],
        [-2.4951e+01],
        [-1.7643e+01],
        [ 6.3256e+01],
        [ 5.0023e+01],
        [ 7.3239e+00],
        [-5.0937e+01],
        [ 1.3769e+01],
        [ 2.7761e+01],
        [ 1.4934e+01],
        [-2.5621e+01],
        [ 9.6270e+00],
        [ 4.1958e+01],
        [ 4.1500e+01],
        [ 2.1226e+01],
        [-1.0286e+01],
        [ 1.2597e+01],
        [-1.0856e+01],
        [-1.9587e+01],
        [-6.8118e+01],
        [-3.7981e+01],
        [-3.6689e+01],
        [-3.5990e+00],
        [ 4.5565e+01],
        [ 8.3049e+01],
        [ 6.7889e+01],
        [ 1.0077e+01],
        [-1.3202e+01],
        [-6.3252e+01],
        [ 8.8928e+00],
        [-2.3536e+01],
        [ 7.9445e+01],
        [ 1.4022e+01],
        [-6.0573e+00],
        [-2.9374e+01],
        [ 1.2231e+01],
        [-9.6243e+01],
        [ 3.5026e+01],
        [ 1.3872e+01],
        [ 1.3662e+01],
        [-6.5954e+01],
        [ 1.3792e+01],
        [ 3.1070e+01],
        [ 4.0310e+01],
        [ 4.3988e+01],
        [-3.4754e+01],
        [-1.6911e+01],
        [ 3.8158e+01],
        [-6.8526e+00],
        [ 4.1351e+01],
        [ 3.4321e+01],
        [-1.8525e+01],
        [-1.5714e+01],
        [-4.0827e+00],
        [-7.6209e+00],
        [-6.0159e+00],
        [-7.6042e+00],
        [-1.0012e+01],
        [-2.8946e+01],
        [-5.2288e+01],
        [ 4.2915e+01],
        [ 1.7641e+02],
        [ 2.9361e+01],
        [-5.6700e+01],
        [ 7.7420e+01],
        [-5.4352e+01],
        [ 1.5517e+01],
        [ 2.1046e+01],
        [-5.2436e+01],
        [ 7.3742e+01],
        [ 1.2038e+01],
        [ 4.9432e+01],
        [ 2.8789e+01],
        [-5.9914e+01],
        [ 1.6021e+01],
        [-3.9695e+00],
        [-2.4146e+01],
        [-5.7901e+00],
        [-2.1206e+01],
        [ 4.8559e+01],
        [-8.1250e+01],
        [-1.9150e+01],
        [-1.1388e+01],
        [-1.2863e+01],
        [-1.9924e+01],
        [ 4.6499e+01],
        [ 1.4429e+01],
        [-4.3398e+01],
        [-3.0007e+01],
        [-5.7798e+01],
        [ 6.5775e+01],
        [-3.2947e+01],
        [ 5.4039e+01],
        [-5.5483e+00],
        [-6.2821e+01],
        [-4.7948e+01],
        [-2.1844e+00],
        [ 7.8850e+00],
        [ 3.7827e+01],
        [-3.2905e+01],
        [ 2.8934e+01],
        [ 3.7787e+01],
        [ 4.8871e+01],
        [-4.5491e+01],
        [ 4.1384e+01],
        [ 5.6023e+01],
        [-3.9484e+01],
        [ 9.8979e+01],
        [ 2.2503e+01],
        [-2.1750e+01],
        [-1.3818e+01],
        [ 6.8883e+00],
        [-2.8052e+01],
        [-4.4136e+01],
        [ 9.0600e+00],
        [-8.2661e+00],
        [-9.1369e-01],
        [ 3.2535e+00],
        [-4.0149e+01],
        [ 4.1332e-02],
        [ 3.7339e+01],
        [ 3.4265e+01],
        [-4.5059e+00],
        [ 4.2739e+00],
        [-3.2086e+01],
        [-2.3899e+00],
        [-9.4793e+01],
        [-3.0832e+00],
        [ 1.3982e+00],
        [ 1.1532e+01],
        [-1.8674e+01],
        [-3.9771e+00],
        [ 1.4483e+01],
        [-3.0207e+01],
        [-1.9915e+01],
        [ 2.6358e+01],
        [-6.8448e+01],
        [ 6.1624e+01],
        [-2.7648e+01],
        [ 1.2012e+01],
        [ 6.5308e+01],
        [ 1.0522e+02],
        [ 5.3913e+01],
        [ 1.5616e+00],
        [-4.2214e+00],
        [-3.9883e+01],
        [ 3.9047e+00],
        [-6.3978e+01],
        [ 1.3417e+02],
        [ 3.2974e+01],
        [ 3.1862e+01],
        [ 7.1200e+01],
        [ 4.0970e+01],
        [ 6.8486e+01],
        [ 3.0286e+01],
        [-1.4254e+01],
        [ 6.6774e+00],
        [-4.2586e-01],
        [ 2.7138e+01],
        [ 6.7583e+00],
        [ 5.5815e+00],
        [ 3.9187e+01],
        [-5.6132e+01],
        [ 3.4296e+00],
        [ 1.3707e+01],
        [ 2.8579e+01],
        [-2.2458e+01],
        [ 5.6361e+01],
        [ 8.0872e+01],
        [ 2.1203e+01],
        [ 1.5039e+01],
        [-6.2941e+01],
        [-1.9883e+01],
        [-1.1656e+01],
        [-4.3131e+01],
        [ 9.3827e+00],
        [-2.9737e+00],
        [-5.2407e+01],
        [-9.5828e+00],
        [-2.1255e+01],
        [-9.2208e+00],
        [ 1.1967e+01],
        [ 2.6242e+01],
        [ 9.2723e+01],
        [ 2.3940e+01],
        [-1.5757e+01],
        [ 2.5756e+00],
        [-1.5550e+01],
        [ 2.9978e+01],
        [-3.7400e+01],
        [ 2.8730e+00],
        [-2.4407e+01],
        [ 2.7767e+01],
        [-3.9124e+01],
        [-2.4384e+01],
        [ 1.5544e+01],
        [ 2.1265e+00]], device='cuda:6')
tensor(2.9775, device='cuda:6')
Evaluating in_domain...
tensor([-8.9353], device='cuda:6')
tensor([[ -8.9598],
        [  4.7799],
        [-30.3179],
        ...,
        [ 34.0207],
        [-17.0734],
        [-16.7464]], device='cuda:6')
tensor(0.9887, device='cuda:6')
tensor([-8.5116], device='cuda:6')
tensor([[ -8.5299],
        [ -9.7692],
        [-11.9862],
        ...,
        [  0.2961],
        [  4.7253],
        [-12.7019]], device='cuda:6')
tensor(-0.2060, device='cuda:6')
tensor([9.4537], device='cuda:6')
tensor([[  9.4579],
        [ -5.5271],
        [-20.1281],
        ...,
        [ 24.3863],
        [-15.2767],
        [  9.4804]], device='cuda:6')
tensor(0.0266, device='cuda:6')
tensor([0.0114], device='cuda:6')
tensor([[ 1.9989e-02],
        [-5.1596e-01],
        [-1.7904e+01],
        ...,
        [-1.1315e+00],
        [ 9.1074e+00],
        [ 4.4929e+01]], device='cuda:6')
tensor(0.6646, device='cuda:6')
tensor([19.8401], device='cuda:6')
tensor([[ 1.9854e+01],
        [-1.1402e+01],
        [-2.8767e+01],
        [ 1.2124e+01],
        [ 1.6130e+01],
        [ 2.1455e+00],
        [-2.4566e+01],
        [-1.3906e+01],
        [ 8.4415e+00],
        [ 1.7265e+01],
        [-2.7466e+00],
        [ 2.6231e+00],
        [ 5.0137e+00],
        [-2.9719e+01],
        [ 1.5125e+01],
        [ 6.5377e+00],
        [ 2.5400e+01],
        [-4.9203e+01],
        [ 4.6788e+00],
        [ 1.3678e+01],
        [ 2.8816e+01],
        [ 3.7260e+00],
        [ 2.8624e+01],
        [-4.4412e+01],
        [-9.0153e+00],
        [-1.6466e+01],
        [ 5.8324e-01],
        [ 1.3393e+01],
        [ 2.2989e+00],
        [-5.4533e-01],
        [ 1.5113e+01],
        [-2.2351e+01],
        [-1.2928e+01],
        [ 1.6999e+01],
        [-1.8329e+00],
        [ 1.1648e+01],
        [-1.4644e+00],
        [-2.4910e+00],
        [ 2.9447e+00],
        [-3.0928e+01],
        [ 3.0420e+00],
        [ 2.7027e+01],
        [ 2.3328e+01],
        [ 2.5487e+01],
        [ 2.8779e+01],
        [-1.3427e+00],
        [ 7.7968e+00],
        [-7.5945e+00],
        [-4.4139e+00],
        [ 1.7108e+01],
        [ 1.2065e+01],
        [ 2.2084e+01],
        [ 8.0166e+00],
        [-6.0169e+00],
        [-3.2325e+00],
        [ 2.1000e+01],
        [ 2.4798e+00],
        [-2.5914e+01],
        [-1.4981e+01],
        [-1.0007e+01],
        [-6.5185e+00],
        [-5.2629e-01],
        [-2.2571e+01],
        [ 3.4596e+01],
        [-1.1404e+01],
        [ 1.2428e+01],
        [-2.1798e+00],
        [-1.1721e+01],
        [ 1.9572e+00],
        [-6.2151e+00],
        [-1.5610e+01],
        [ 1.0074e+01],
        [-1.3553e+01],
        [ 2.7591e+01],
        [-4.5690e+00],
        [ 3.9210e+01],
        [ 1.3305e+01],
        [-1.2030e+01],
        [-1.4354e-01],
        [ 4.1440e+01],
        [-4.1187e+01],
        [ 4.8176e+00],
        [-1.9194e+00],
        [-6.7105e+00],
        [-2.8374e+01],
        [ 2.2514e+00],
        [-2.2174e+00],
        [-1.2141e+01],
        [ 2.7347e+01],
        [ 2.0085e+01],
        [-2.8821e+01],
        [ 1.8904e+01],
        [-1.3301e+01],
        [-4.3904e+00],
        [ 4.3405e+01],
        [ 2.4472e+01],
        [-2.6658e+00],
        [ 1.9822e+01],
        [ 3.2709e+01],
        [ 3.2059e+01],
        [-3.6270e+00],
        [-1.1975e+01],
        [ 2.4808e+01],
        [ 2.6753e+01],
        [-2.9266e+01],
        [-3.0111e+01],
        [-4.2056e+01],
        [ 2.4328e+00],
        [ 2.0730e+01],
        [-1.3945e+01],
        [-5.3315e-01],
        [ 1.0147e+01],
        [-7.2877e+00],
        [ 6.5502e+00],
        [ 5.5396e+00],
        [ 1.2723e+01],
        [-2.9824e+01],
        [ 2.0404e+01],
        [ 4.3761e+00],
        [ 2.1345e+01],
        [-2.8588e+00],
        [-6.0801e+00],
        [-9.5708e+00],
        [ 2.5600e+01],
        [-1.5382e+01],
        [-2.2876e+01],
        [-3.1061e+01],
        [-2.2144e+01],
        [-9.1457e+00],
        [-8.6342e+00],
        [-2.1627e+01],
        [-9.9877e+00],
        [-2.7262e+01],
        [-4.3451e+00],
        [ 1.7710e+01],
        [ 1.4060e+00],
        [-1.6908e+01],
        [-1.9318e+01],
        [ 9.2178e+00],
        [ 7.2652e+00],
        [-4.2993e+01],
        [-1.6793e+01],
        [-5.0539e+00],
        [ 5.0824e-01],
        [ 1.5585e+01],
        [ 1.9457e+00],
        [-1.5113e+01],
        [-2.3644e+01],
        [ 5.2302e+01],
        [-1.2670e+01],
        [-1.0950e+00],
        [-2.9549e+00],
        [-3.0206e+01],
        [-1.7625e+01],
        [-1.3975e+01],
        [-1.2233e+01],
        [ 4.3202e+00],
        [ 7.3380e+00],
        [ 1.1527e+01],
        [ 2.1685e+01],
        [ 2.1451e+00],
        [ 1.4748e+01],
        [-1.3615e+01],
        [ 1.7540e+01],
        [-1.2701e+01],
        [-9.3807e+00],
        [ 1.9089e+01],
        [-6.4316e+00],
        [ 4.1794e+00],
        [-3.6151e+01],
        [ 4.1911e+01],
        [-8.2397e+00],
        [-1.5911e+00],
        [ 5.8093e+00],
        [-1.1109e+00],
        [-9.3973e+00],
        [-1.7059e+01],
        [-6.5491e+00],
        [-2.7603e+00],
        [ 1.6687e+01],
        [ 1.8197e+01],
        [ 4.9521e+00],
        [ 1.9095e+00],
        [-2.3423e+01],
        [-1.8082e+01],
        [ 3.7780e+01],
        [-7.0465e+00],
        [-2.5317e+01],
        [-5.3545e+01],
        [-1.5171e+01],
        [-1.0832e+01],
        [ 1.4830e+01],
        [-1.4025e+01],
        [-1.7913e+01],
        [-2.9621e+01],
        [ 1.8745e+01],
        [-3.6334e+01],
        [-1.9009e+01],
        [-3.2099e+01],
        [ 4.0260e+01],
        [-1.7086e+01],
        [-5.0190e+01],
        [-2.1401e+01],
        [ 1.4753e+01],
        [-1.1710e+01],
        [ 2.1239e+01],
        [-1.0860e+01],
        [ 1.4581e+01],
        [ 1.8028e+00],
        [-2.4453e+00],
        [-7.2853e+00],
        [ 2.2593e+01],
        [-1.2529e+01],
        [-6.8994e+00],
        [ 4.7987e+01],
        [-4.1082e+01],
        [-2.2958e+01],
        [ 5.9991e+00],
        [-8.9455e+00],
        [-1.1466e+01],
        [ 6.1329e+00],
        [-5.9897e+00],
        [ 1.7099e+01],
        [ 9.0486e+00],
        [ 7.6811e+00],
        [-1.4446e+01],
        [ 1.6396e+01],
        [-6.3750e+00],
        [-4.2777e+01],
        [-7.8154e+00],
        [-1.4063e+01],
        [-6.0307e+00],
        [ 5.5547e+00],
        [ 1.2125e-01],
        [-1.0090e+01],
        [ 6.0433e+01],
        [ 2.5737e+00],
        [ 3.1561e+00],
        [-1.7876e+00],
        [ 9.0061e+00],
        [-1.5697e+00],
        [ 5.4832e+00],
        [-1.9339e+01],
        [ 8.3035e+00],
        [-3.7739e+00],
        [ 3.7561e+01],
        [-3.0601e+01],
        [-5.0489e+00],
        [ 3.9221e+00],
        [-2.6017e+01],
        [ 1.6976e+01],
        [-4.7865e+01],
        [ 2.5856e+01],
        [ 8.6515e+00],
        [ 8.3810e+00],
        [-2.4384e+00],
        [-2.1028e+00],
        [ 3.0016e+01],
        [-3.0797e+00],
        [ 1.8464e+01],
        [-5.4539e+00],
        [ 2.8940e+01],
        [-2.2780e+01],
        [ 7.1532e+00],
        [ 1.9497e+01],
        [-2.9072e+01],
        [-2.9693e+01],
        [ 2.2640e+01],
        [-4.8137e+00],
        [-8.3284e+00],
        [-1.7394e+01],
        [-2.0353e+01],
        [-3.2883e+01],
        [-3.4627e+01],
        [ 2.6391e+01],
        [-1.2867e+01],
        [ 3.1498e+01],
        [ 7.1372e+00],
        [ 5.2780e+01],
        [-5.6134e+01],
        [-3.1132e+00],
        [ 6.9708e+00],
        [-7.9842e+00],
        [ 2.1846e+01],
        [ 3.0519e+01],
        [ 2.4643e+01],
        [ 2.3534e+00],
        [ 5.9795e+00],
        [-1.3754e+01],
        [ 2.3654e+01],
        [ 2.2075e+01],
        [ 3.2074e+00],
        [ 2.6751e+01],
        [-2.5536e+01],
        [-2.3386e+01],
        [ 2.3848e+01],
        [-2.2578e+00],
        [-2.7384e+01],
        [-1.9944e+01],
        [-2.0502e+01],
        [ 1.4683e+01],
        [-1.3936e+01],
        [-1.2774e+01],
        [-1.3882e+01],
        [ 2.7809e+00],
        [ 1.5236e+01],
        [-8.2833e+00],
        [-2.7253e+01],
        [ 1.9313e+01],
        [-1.0155e+01],
        [ 3.3048e+00],
        [ 6.0563e+00],
        [ 1.1050e+01],
        [-1.3421e+01],
        [ 1.3527e+01],
        [-5.1310e+00],
        [-1.1548e+01],
        [ 3.9581e+00],
        [-4.8749e+00],
        [-1.0182e+01],
        [-2.5507e+01],
        [ 4.1483e-02],
        [ 1.5449e+01],
        [ 9.7220e+00],
        [ 5.7338e+00],
        [ 2.0290e+01],
        [-1.6728e+01],
        [-9.7928e+00],
        [ 4.7306e-02],
        [-1.1331e+01],
        [ 5.6629e+01],
        [ 1.3100e+00],
        [-7.4974e-01],
        [ 9.1444e+00],
        [-2.4883e+01],
        [-1.8285e+01],
        [ 9.9844e+00],
        [ 5.9585e+00],
        [ 1.8738e+01],
        [-3.8291e+01],
        [ 1.0421e+01],
        [-1.3294e+01],
        [-6.3920e+00],
        [ 6.2788e+01],
        [-6.0304e+00],
        [-2.0730e+01],
        [-2.3961e+01],
        [-6.8311e+00],
        [-2.2623e+01],
        [ 1.2821e+01],
        [-1.5731e+01],
        [ 2.6292e+00],
        [-3.6405e+01],
        [ 1.8121e+01],
        [-2.8971e+01],
        [ 2.2205e+01],
        [ 2.0655e+01],
        [-1.7006e+01],
        [ 1.4198e+01],
        [-4.9995e+00],
        [ 1.0143e+01],
        [ 3.0820e+01],
        [ 1.2381e+01],
        [-3.1405e+00],
        [ 2.3389e+01],
        [ 7.5283e+00],
        [ 3.5831e+01],
        [-2.0143e+01],
        [-8.9179e+00],
        [ 2.7940e+00],
        [ 1.0579e+01],
        [ 7.4996e+00],
        [-3.8942e+00],
        [-3.0284e+01],
        [ 1.4418e+01],
        [-6.0647e+00],
        [-2.7204e+01],
        [ 3.2514e+00],
        [-1.7336e+01],
        [ 2.2632e+01],
        [ 1.2757e+01],
        [ 2.1402e+01],
        [-2.3796e+01],
        [-5.4528e+00],
        [ 1.4204e+01],
        [ 2.1563e+01],
        [-2.9321e+01],
        [-3.1403e+01],
        [-1.0889e+01],
        [ 2.8917e+01],
        [-1.8115e+01],
        [-2.2985e+01],
        [ 2.7822e+01],
        [ 1.3092e+00],
        [ 8.4277e+00],
        [ 3.1065e+01],
        [-2.5648e+01],
        [ 1.1624e+01],
        [-8.3149e+00],
        [ 1.6909e+01],
        [ 3.2185e+01],
        [ 2.2433e+01],
        [ 3.9620e+00],
        [-1.8077e+01],
        [ 1.0476e+01],
        [ 3.1429e+00],
        [-3.3561e+01],
        [-1.0604e+01],
        [-3.0749e+01],
        [ 3.2000e+01],
        [-1.2797e+01],
        [ 2.0085e+01],
        [-4.8089e+01],
        [-1.8268e+01],
        [ 1.4663e+01],
        [ 2.1788e+01],
        [-1.3245e+01],
        [ 9.5079e+00],
        [-4.4212e+01],
        [ 1.0355e+01],
        [-1.1804e+01],
        [-2.2122e+00],
        [ 4.4143e+01],
        [ 7.9875e+00],
        [ 2.3556e+01],
        [-7.5017e+00],
        [-7.9854e+00],
        [-6.0050e+00],
        [ 1.6610e+00],
        [ 1.6425e+01],
        [ 4.5041e+00],
        [ 1.7690e+01],
        [-2.8441e+00],
        [-3.1658e+00],
        [-1.3483e+00],
        [ 6.7702e+00],
        [ 5.7605e+00],
        [-1.3956e+01],
        [-4.9834e+00],
        [ 8.8855e+00],
        [ 1.5318e+01],
        [-8.9981e+00],
        [ 5.0566e+00],
        [-3.9786e+00],
        [ 7.2547e+00],
        [-2.3292e+00],
        [ 1.9882e+01],
        [ 2.2129e-01],
        [ 5.8982e-01],
        [ 3.5370e+01],
        [-1.4531e+01],
        [-1.0177e+00],
        [-1.0821e+01],
        [ 1.2789e+01],
        [-5.2851e+00],
        [-4.8339e+01],
        [ 9.6122e+00],
        [-1.6764e+01],
        [ 1.8112e+01],
        [-1.4690e+01],
        [ 8.7702e+00],
        [ 1.0587e+01],
        [ 2.5108e+01],
        [-7.4831e+00],
        [ 3.0773e+01],
        [-5.5811e+00],
        [-2.3430e+01],
        [ 8.3011e+01],
        [ 2.0951e+01],
        [-7.6921e+00],
        [-2.0436e+01],
        [-3.9999e+01],
        [-5.1956e+00],
        [-2.9472e-01],
        [-1.2325e+01],
        [ 5.8854e-01],
        [ 9.9081e-01],
        [-2.9063e+01],
        [-1.1398e+01],
        [-3.2420e-01],
        [-1.4510e+01],
        [-2.8105e+00],
        [-2.6144e+00],
        [-2.3278e+00],
        [-5.7915e+01],
        [-2.2449e+01],
        [ 1.3030e+00],
        [ 3.5396e+01],
        [ 1.7548e+01],
        [ 1.5331e+01],
        [ 9.6044e+00],
        [-8.9300e+00],
        [-1.7606e+01],
        [ 5.0368e+01],
        [ 3.1303e+01],
        [-1.3050e+01],
        [-4.6727e+01],
        [ 5.0671e+00],
        [-1.1750e+01],
        [ 1.4916e+01],
        [ 7.5115e+00],
        [ 1.1793e+01],
        [-1.5130e+01],
        [-1.1282e+01],
        [-2.8447e+00],
        [ 8.4195e+00],
        [-7.7276e+00],
        [-4.8405e+00],
        [ 1.4833e+01],
        [ 5.4451e+01],
        [-7.6917e+00],
        [ 3.1437e+01],
        [ 4.5687e+00],
        [-3.2984e+01],
        [-2.1674e+01],
        [ 8.0037e-01],
        [ 2.8507e+01],
        [-2.2367e+01],
        [-5.7975e+00],
        [-9.7687e+00],
        [-1.7364e+01],
        [ 1.7549e+01],
        [-2.1559e+01],
        [-4.5372e+00],
        [ 8.4782e+00],
        [ 1.7792e+01],
        [-7.3497e+00],
        [ 1.7301e+01],
        [ 1.2078e+01],
        [-2.8752e+01],
        [ 1.0524e+00],
        [ 4.9384e+00],
        [-2.3465e+01],
        [ 2.4460e+01],
        [-3.0108e+00],
        [-6.3062e+00],
        [ 5.7745e-02],
        [-6.0283e+00],
        [-1.1827e+01],
        [ 2.3671e+01],
        [ 1.3618e+00],
        [-4.6760e+01],
        [ 5.4109e+00],
        [-3.6647e+01],
        [ 2.2482e+01],
        [ 2.3792e+00],
        [-1.6327e+01],
        [ 1.3191e+01],
        [ 2.1275e+01],
        [ 1.6442e+01],
        [-2.6928e+01],
        [-1.9653e+00],
        [ 2.3200e+01],
        [-2.0030e+01],
        [-1.2969e+01],
        [ 1.6556e+01],
        [-4.1929e+00],
        [ 7.5608e+00],
        [-5.3063e+00],
        [-1.2388e+01],
        [ 3.3642e+01],
        [-2.9522e+01],
        [ 9.7742e+00],
        [ 1.1786e-01],
        [ 8.4756e+00],
        [-1.3321e+01],
        [ 3.7110e+01],
        [-1.7977e+01],
        [-3.9652e+01],
        [-5.9623e+00],
        [-1.4105e+01],
        [-3.1712e+00],
        [-2.3829e+01],
        [ 1.9943e+01],
        [ 8.7646e+00],
        [-2.5051e+01],
        [-9.4520e+00],
        [-2.2022e+01],
        [ 1.0585e+01],
        [-1.5432e+01],
        [ 6.3622e+00],
        [-9.3249e+00],
        [ 7.8797e+00],
        [-1.2368e+01],
        [-2.6211e+01],
        [ 1.8589e+01],
        [-8.5172e+00],
        [ 2.9241e+01],
        [ 2.0849e+01],
        [ 6.0090e-01],
        [-4.0514e+00],
        [ 3.2985e+01],
        [-3.2124e+01],
        [ 2.0140e+01],
        [-2.2087e-01],
        [-2.4511e+01],
        [ 2.3153e+01],
        [ 9.4822e+00],
        [ 1.5685e+01],
        [-4.6343e+01],
        [ 2.3439e+01],
        [ 1.0836e+01],
        [-5.3500e+00],
        [ 5.8107e+00],
        [-6.1158e+00],
        [-1.1054e+01],
        [-3.1459e+01],
        [ 1.3150e+01],
        [-3.4688e-01],
        [ 1.5532e+00],
        [ 7.0477e+00],
        [ 1.0565e+00],
        [ 4.3022e+01],
        [-1.6159e+01],
        [-1.1368e+01],
        [ 1.2302e+00],
        [ 1.5182e+01],
        [ 3.4075e+01],
        [ 2.0891e+01],
        [ 3.0640e+00],
        [ 1.4071e+01],
        [ 5.2411e-01],
        [-4.5939e+00],
        [ 2.8128e+01],
        [-3.3304e+01],
        [ 7.2965e+00],
        [ 1.6929e+01],
        [ 7.4891e-01],
        [ 2.0400e+01],
        [-1.3083e-02],
        [ 1.7215e+01],
        [-1.3181e+00],
        [ 2.6718e+01],
        [-3.2849e+01],
        [-6.0478e-01],
        [-7.1812e+00],
        [ 1.1086e+01],
        [ 3.2622e+01],
        [ 6.9348e+00],
        [-2.9069e+00],
        [ 8.8606e+00],
        [ 1.3193e+01],
        [-1.2807e+01],
        [ 3.5658e+01],
        [ 2.1458e+01],
        [ 2.1098e+01],
        [ 1.5597e-01],
        [ 4.9222e+00],
        [-1.1745e+01],
        [ 1.5215e+01],
        [ 9.1683e+00],
        [ 4.6270e-01],
        [ 2.8193e+01],
        [-2.3221e+01],
        [-4.9607e+00],
        [ 4.5090e+00],
        [ 1.0796e+01],
        [-3.0680e+00],
        [-1.0833e+01],
        [ 2.8711e+01],
        [-2.5977e+01],
        [ 3.4219e+01],
        [-1.3883e+01],
        [-1.6306e+00],
        [-2.0672e+01],
        [ 3.2649e+00],
        [ 1.9772e+00],
        [ 4.8414e+00],
        [ 5.2309e+00],
        [ 2.0445e+01],
        [ 2.3497e+01],
        [-1.0707e+01],
        [ 6.7271e+00],
        [-3.3625e-01],
        [ 6.5826e+00],
        [ 9.3793e+00],
        [ 9.3434e+00],
        [-4.7140e-01],
        [-3.1040e+01],
        [-2.2746e+01],
        [ 9.1087e+00],
        [-1.9112e+01],
        [-4.5540e-01],
        [-9.3462e+00],
        [-3.3923e+00],
        [ 2.8695e+01],
        [ 2.7499e+01],
        [-1.8781e+01],
        [-1.3067e+01],
        [-1.1963e+01],
        [-1.5185e+01],
        [ 1.0980e+01],
        [ 1.3318e+01],
        [ 2.2078e+01],
        [-1.1794e+00],
        [ 5.7338e+00],
        [ 1.5687e+01],
        [-2.2081e+00],
        [ 2.0026e+01],
        [-7.9887e+00],
        [-1.7964e+00],
        [ 2.2957e+01],
        [ 2.6356e+01],
        [ 4.5251e+00],
        [-4.4835e+00],
        [-2.8213e+01],
        [-3.1997e+01],
        [ 2.0835e+00],
        [ 2.7040e+01],
        [ 1.6268e+01],
        [-4.7459e+00],
        [-2.0561e+01],
        [ 1.5069e+01],
        [-1.9942e+01],
        [ 3.2708e+01],
        [-1.0892e+01],
        [ 1.4215e+01],
        [-5.5100e+00],
        [-1.2948e+01],
        [-5.0755e-01],
        [ 2.2679e+00],
        [-2.0263e+01],
        [ 7.7463e+00],
        [-6.2856e-01],
        [-1.5684e+01],
        [-1.7388e+01],
        [-1.3061e+01],
        [-6.1796e+00],
        [ 6.9546e+00],
        [-2.1988e+01],
        [ 1.5790e+01],
        [ 3.5564e+01],
        [ 1.8136e+01],
        [-5.0645e+00],
        [ 1.8343e+01],
        [ 2.7008e+01],
        [-1.8057e+01],
        [-3.9776e+00],
        [ 2.4300e+01],
        [-1.0557e+00],
        [ 6.5661e+00],
        [-2.6056e+01],
        [ 1.8992e+01],
        [ 1.7005e+00],
        [ 7.6201e+00],
        [ 7.0291e+00],
        [ 1.9434e+00],
        [-2.0841e+01],
        [ 1.6947e+01],
        [-2.1041e+01],
        [ 3.9357e+01],
        [ 1.6989e+01],
        [ 8.4891e+00],
        [ 1.0785e+01],
        [-1.8000e+00],
        [-3.1588e+00],
        [ 2.9964e+01],
        [ 1.7600e+01],
        [ 1.1301e+01],
        [-3.5615e+00],
        [-1.4478e+01],
        [ 2.4346e+01],
        [-2.2324e+01],
        [ 4.7419e+01],
        [ 3.5648e+01],
        [ 2.4097e+01],
        [ 3.3710e+00],
        [ 1.4610e+01],
        [-3.5019e+01],
        [ 3.6588e+00],
        [-1.3987e+01],
        [ 3.4215e+01],
        [-4.6186e+00],
        [-2.6863e+01],
        [-1.3726e+01],
        [ 1.2771e+01],
        [ 3.6797e+00],
        [ 2.5483e+00],
        [ 2.3611e+01],
        [-1.4626e+01],
        [ 1.3703e+01],
        [-9.4382e+00],
        [ 6.6905e+00],
        [ 2.3334e+01],
        [-1.6154e+01],
        [ 3.9245e+00],
        [-3.3673e+01],
        [-3.0727e+01],
        [ 1.2597e+01],
        [ 5.0842e+00],
        [ 1.3598e+01],
        [ 1.2586e+00],
        [ 1.5860e+01],
        [-4.2600e-01],
        [ 1.0937e+01],
        [-9.0291e+00],
        [ 1.4364e+01],
        [ 2.0366e+01],
        [-8.1416e+00],
        [ 4.2485e+01],
        [ 1.9938e+00],
        [-1.5541e+01],
        [-1.2967e+01],
        [-1.3020e+01],
        [ 1.6453e+01],
        [-1.9395e+01],
        [ 5.9212e+01],
        [-2.0279e+01],
        [ 5.4561e+00],
        [ 3.5832e+01],
        [ 4.1421e+01],
        [-6.5520e+00],
        [ 8.2230e+00],
        [ 3.4122e+01],
        [-8.1387e+00],
        [-9.0148e+00],
        [-1.3154e+01],
        [ 5.8216e+00],
        [ 9.3359e+00],
        [-1.7807e+01],
        [-1.5687e+01],
        [ 1.2779e+01],
        [ 6.9562e+00],
        [-3.8457e+00],
        [-4.6991e+00],
        [-1.8195e+01],
        [-1.1778e+00],
        [ 2.0604e+01],
        [-2.5174e+01],
        [-1.2576e+01],
        [-4.4388e+01],
        [-4.0780e+01],
        [-1.6182e+01],
        [ 3.9830e+01],
        [ 3.0173e+01],
        [-1.7344e+01],
        [-3.1879e+00],
        [-7.1373e+00],
        [-1.8693e+00],
        [-2.2118e+01],
        [ 3.7485e+01],
        [-2.6912e+01],
        [ 3.1221e+00],
        [ 1.5731e+01],
        [ 2.6973e+01],
        [ 8.8026e+00],
        [ 7.8375e+00],
        [-3.8065e+01],
        [ 4.1594e+00],
        [ 2.4533e+01],
        [ 1.9015e+01],
        [ 6.6315e-01],
        [ 6.0795e+00],
        [ 5.9954e+00],
        [-3.0737e+01],
        [-9.0912e-02],
        [ 5.9778e+01],
        [-1.5854e+01],
        [ 2.2160e+01],
        [ 1.8074e+01],
        [ 2.1414e+01],
        [ 2.7409e+01],
        [ 1.8580e+01],
        [ 9.4672e+00],
        [-3.0808e+00],
        [-7.2783e+00],
        [ 1.3630e+01],
        [ 1.2741e+01],
        [ 2.7119e+01],
        [ 4.8483e+01],
        [-1.9770e+01],
        [ 1.1856e+01],
        [ 2.6660e+00],
        [-2.2925e+01],
        [ 2.0862e+01],
        [ 4.6212e+01],
        [ 7.8768e+00],
        [ 1.2641e+01],
        [-2.7751e+00],
        [-3.2961e+01],
        [-2.7639e+01],
        [-2.5362e+01],
        [ 1.0407e+01],
        [ 2.6638e+01],
        [ 2.7675e+01],
        [ 1.0674e+01],
        [-2.0566e+01],
        [ 1.1052e-01],
        [ 5.8427e-02],
        [ 1.9427e+01],
        [ 1.9714e+01],
        [ 5.9615e+01],
        [ 1.8790e+01],
        [ 1.4115e+00],
        [-1.4206e+01],
        [ 7.8504e+00],
        [-1.7814e+01],
        [-6.9695e+00],
        [ 5.9736e+00],
        [ 1.1172e+01],
        [ 4.4037e-01],
        [ 1.8252e+01],
        [ 8.1087e+00],
        [ 1.1156e+00]], device='cuda:6')
tensor(0.9126, device='cuda:6')
Evaluating out_domain...
tensor([9.6867], device='cuda:6')
tensor([[  9.6554],
        [ 40.3071],
        [ 14.5679],
        ...,
        [-15.6291],
        [-73.5459],
        [ 14.9614]], device='cuda:6')
tensor(2.2748, device='cuda:6')
tensor([18.6315], device='cuda:6')
tensor([[ 18.7460],
        [ 24.4407],
        [-21.3111],
        ...,
        [ 33.3309],
        [-36.4914],
        [  3.9540]], device='cuda:6')
tensor(1.1337, device='cuda:6')
tensor([-43.1995], device='cuda:6')
tensor([[-43.2145],
        [-55.6600],
        [ 62.9190],
        ...,
        [  5.4333],
        [-42.6266],
        [-44.8911]], device='cuda:6')
tensor(-0.3632, device='cuda:6')
tensor([-14.5976], device='cuda:6')
tensor([[-14.6368],
        [  6.5514],
        [-31.4061],
        ...,
        [ 80.2132],
        [ 31.6025],
        [-93.5276]], device='cuda:6')
tensor(0.7402, device='cuda:6')
tensor([-33.9972], device='cuda:6')
tensor([[-3.4026e+01],
        [-5.5634e+01],
        [ 7.2787e+01],
        [ 3.2031e+01],
        [-7.5777e+01],
        [-8.4276e+01],
        [ 6.0778e+01],
        [ 3.1243e+00],
        [ 2.6706e+01],
        [-5.9856e+01],
        [ 1.7529e+01],
        [-2.2122e+01],
        [-4.1942e+01],
        [-5.1272e+01],
        [ 6.7206e+01],
        [-1.8651e+00],
        [-1.1572e+02],
        [ 3.0864e+01],
        [-1.4396e+01],
        [-2.2239e+01],
        [ 7.6557e+01],
        [-7.3031e+01],
        [ 1.5125e+01],
        [ 8.4518e+01],
        [-2.8266e+01],
        [ 1.3916e+01],
        [-2.0004e+01],
        [-9.3556e+00],
        [ 3.3441e-01],
        [-3.7937e+01],
        [ 1.6228e+01],
        [-3.9567e+01],
        [ 5.8027e+01],
        [ 6.5369e+01],
        [ 7.1168e+01],
        [ 1.5021e+01],
        [-6.2289e+01],
        [ 1.3122e+01],
        [-9.3159e+00],
        [-3.5069e+00],
        [ 7.8088e+01],
        [ 2.0208e+01],
        [ 1.3662e+02],
        [-1.3718e+01],
        [ 5.3173e+01],
        [ 1.9735e+01],
        [-4.7035e+01],
        [ 1.4801e+01],
        [ 2.1118e+01],
        [-1.3735e+01],
        [ 2.2323e+01],
        [-6.9979e+01],
        [-2.8672e+01],
        [ 2.3506e+01],
        [ 3.6527e+01],
        [-1.5091e+00],
        [-6.8349e+01],
        [-1.2893e+02],
        [-3.9213e+01],
        [-1.9784e+00],
        [ 5.6404e+01],
        [-1.8273e+01],
        [-2.0405e+01],
        [-4.3592e+01],
        [ 1.0904e+01],
        [ 7.8421e+01],
        [-8.6674e+01],
        [ 1.5736e+00],
        [ 8.2373e+00],
        [ 5.9058e+01],
        [ 1.4504e+01],
        [ 6.5139e+01],
        [-1.8809e+01],
        [-5.3763e+01],
        [ 5.2010e+01],
        [-2.2284e+01],
        [-8.0148e+01],
        [ 8.5471e+01],
        [-7.1568e+01],
        [-4.0430e+01],
        [-2.9259e+01],
        [-4.3243e+01],
        [-5.5384e+01],
        [-3.7076e+01],
        [-4.3337e+01],
        [-3.7964e+01],
        [-1.2452e+01],
        [-4.6817e-01],
        [-4.0929e+00],
        [-7.7742e+00],
        [-9.5186e+01],
        [ 6.0897e+01],
        [ 9.6636e+01],
        [ 5.6034e+01],
        [-3.5206e+01],
        [ 1.5256e+01],
        [ 8.4855e+00],
        [-3.0223e+00],
        [ 1.2967e+02],
        [-6.4212e+01],
        [ 1.5701e+02],
        [-9.6528e+01],
        [-3.6821e+01],
        [ 3.0392e+01],
        [ 8.5117e+01],
        [ 1.2890e+01],
        [-6.7610e+01],
        [ 8.6881e+01],
        [ 1.7690e+01],
        [-2.8317e+01],
        [ 9.5813e+00],
        [-1.2058e+01],
        [ 4.3393e+01],
        [ 3.5641e+01],
        [ 7.5370e+01],
        [ 8.4594e+01],
        [ 1.5461e+02],
        [-2.7747e+01],
        [ 5.4109e+01],
        [ 5.0230e+01],
        [ 7.9203e+01],
        [ 4.4975e+01],
        [ 5.5613e+01],
        [ 5.9170e+01],
        [ 6.1295e+01],
        [-1.0188e+02],
        [-6.5132e+01],
        [-5.4504e+01],
        [-5.8181e+01],
        [-7.5603e+00],
        [-2.1432e+01],
        [-3.2773e+01],
        [ 3.6905e+01],
        [ 6.2927e+01],
        [-8.1384e+01],
        [-1.0079e+02],
        [-5.0904e+01],
        [ 2.0070e+01],
        [ 8.1147e+00],
        [ 1.2161e+02],
        [ 6.3016e+01],
        [-4.0661e+01],
        [-7.1507e+01],
        [-8.0992e+01],
        [ 6.8273e+01],
        [-8.4327e+01],
        [ 2.5523e+01],
        [ 3.7623e+01],
        [ 1.8419e+01],
        [ 2.2649e+01],
        [-2.9098e+01],
        [ 6.3793e+01],
        [ 2.7486e+01],
        [ 7.3318e+00],
        [-8.1534e+01],
        [ 3.2773e+01],
        [ 8.2883e+01],
        [-5.4671e+01],
        [ 2.0812e+01],
        [ 5.7503e+01],
        [ 7.6415e+01],
        [-9.5865e+01],
        [ 2.0306e+01],
        [ 9.9951e+00],
        [-3.6441e+01],
        [ 1.2547e+01],
        [-2.2110e+01],
        [ 6.1214e+01],
        [ 7.1389e+01],
        [-3.2037e+00],
        [ 2.5879e+01],
        [-3.2342e+01],
        [ 3.3288e+01],
        [ 4.7760e+01],
        [ 4.3926e+01],
        [ 5.1765e+01],
        [ 2.4685e+01],
        [ 5.7973e+00],
        [-1.9362e+01],
        [ 5.7494e+01],
        [ 1.1373e+02],
        [ 2.1263e+01],
        [ 1.1108e+01],
        [-3.0672e+01],
        [-1.6521e+01],
        [-1.6297e+01],
        [-2.5832e+01],
        [ 1.0503e+02],
        [ 7.7867e+01],
        [ 3.2441e+01],
        [-2.4609e+01],
        [ 1.1154e+01],
        [ 3.0488e+01],
        [-8.3936e+01],
        [-5.9181e+01],
        [ 5.4472e+01],
        [-5.8144e+01],
        [-9.9235e+00],
        [-6.7022e+01],
        [-4.8389e+01],
        [ 5.9649e+01],
        [-2.6926e+01],
        [ 6.4092e+01],
        [-2.2274e+01],
        [-3.0636e+01],
        [ 5.2342e+01],
        [ 2.9309e+01],
        [-1.4674e+02],
        [-9.4745e+00],
        [-1.0133e+02],
        [ 6.8885e+00],
        [-9.4848e+01],
        [ 3.5906e+00],
        [-5.2686e+01],
        [ 5.5272e+00],
        [ 3.4024e+01],
        [-1.2700e+02],
        [-6.2991e+01],
        [-5.7169e+01],
        [ 2.2996e+01],
        [ 3.6232e+01],
        [-5.0370e+01],
        [ 1.8844e+01],
        [ 3.6289e+00],
        [-5.4718e+01],
        [-1.3305e+02],
        [ 3.0500e+01],
        [-1.1471e+01],
        [ 8.7170e+01],
        [ 6.4685e+00],
        [-1.8397e+01],
        [ 7.2369e+01],
        [-4.1490e+00],
        [-8.3932e+01],
        [ 1.0079e+01],
        [-3.9065e+00],
        [-1.3757e+01],
        [-1.4883e+00],
        [-4.9933e+01],
        [ 6.0762e+00],
        [ 5.7521e+01],
        [ 1.2412e+01],
        [-2.8537e+01],
        [-6.8645e+00],
        [-3.8785e+01],
        [ 3.1829e+01],
        [ 5.4169e+01],
        [ 5.1815e+01],
        [ 3.1403e+00],
        [-5.4402e+01],
        [-2.7331e+01],
        [-9.8127e+01],
        [-3.9666e+01],
        [-3.0694e+01],
        [-5.9599e+01],
        [-4.6351e+01],
        [ 5.4020e+01],
        [-6.0807e+01],
        [ 3.6102e+01],
        [ 1.3374e+01],
        [-3.1525e+01],
        [-8.1408e+01],
        [ 3.5073e+01],
        [ 1.8541e+01],
        [-3.6888e+01],
        [-4.9352e+01],
        [ 3.1512e+01],
        [-2.5649e+00],
        [-2.3504e+01],
        [ 1.5047e+01],
        [ 2.6801e+01],
        [ 6.5437e+00],
        [ 3.4416e+00],
        [-5.3865e+01],
        [ 1.1276e+02],
        [ 4.5375e+01],
        [ 1.9834e+01],
        [-9.6925e+01],
        [-2.7036e+01],
        [-3.4483e+01],
        [ 4.0227e+01],
        [-1.7965e+01],
        [ 1.4803e+01],
        [ 1.7934e+01],
        [ 2.1644e+01],
        [ 2.3921e+01],
        [ 3.2682e+01],
        [ 4.2569e+01],
        [-6.2716e+01],
        [-5.7942e+01],
        [ 3.9919e+01],
        [ 9.1791e+01],
        [-2.8486e+01],
        [-1.5895e+02],
        [ 4.4717e+01],
        [ 1.6101e+01],
        [ 5.1279e+01],
        [ 2.5232e+01],
        [-1.0583e+01],
        [ 1.6520e+01],
        [-1.7265e+01],
        [ 2.3771e+01],
        [ 4.8658e+00],
        [ 6.4499e+01],
        [-1.2146e+01],
        [-1.0169e+02],
        [ 2.5256e+00],
        [ 4.6213e+01],
        [-9.2225e+00],
        [-4.9682e+01],
        [-3.7496e+01],
        [ 7.3968e+01],
        [ 3.8463e+01],
        [-1.6066e+01],
        [-2.9429e+01],
        [-5.8848e+01],
        [ 4.4055e+00],
        [-3.3140e+01],
        [-3.3515e+01],
        [ 3.9095e+01],
        [-5.2923e+00],
        [ 3.0389e+01],
        [ 1.5616e+01],
        [-5.0173e+01],
        [-1.2037e+02],
        [-1.1310e+01],
        [ 2.1063e+01],
        [-2.7599e+01],
        [ 1.2190e+01],
        [ 3.5664e+01],
        [ 1.5364e+01],
        [-1.7422e+01],
        [ 2.5827e+01],
        [ 3.3516e+01],
        [-3.0681e+01],
        [ 6.0280e+01],
        [ 3.9058e+01],
        [ 4.9886e+01],
        [-1.7580e+01],
        [-6.6642e+00],
        [ 6.1882e+01],
        [ 6.0265e+01],
        [-4.3029e+01],
        [-2.7598e+01],
        [-1.3008e+02],
        [ 1.1191e+02],
        [-4.1616e+01],
        [ 1.1286e+02],
        [-1.6535e+01],
        [-1.6461e+01],
        [ 6.1623e+01],
        [ 6.8005e+01],
        [ 4.6566e+01],
        [-5.4685e+00],
        [ 3.9385e+01],
        [ 6.8648e+01],
        [-3.7827e+01],
        [ 5.0110e+01],
        [-6.6512e+01],
        [-6.9814e+01],
        [ 4.1401e+01],
        [ 2.7647e+01],
        [-3.2069e+01],
        [-3.5888e+01],
        [ 6.8414e+01],
        [-1.1836e+01],
        [ 9.6045e+00],
        [-1.6617e+01],
        [-5.2151e+01],
        [ 9.0925e+00],
        [ 3.6266e+01],
        [ 7.3058e+01],
        [ 2.1227e+01],
        [-1.0816e+02],
        [ 2.3986e+01],
        [-1.9064e+01],
        [ 9.2030e+00],
        [-4.8168e+01],
        [-3.3472e+01],
        [ 4.5307e+01],
        [ 4.3111e+01],
        [-1.5178e+02],
        [-9.3455e+01],
        [-1.2720e+01],
        [ 1.0671e+02],
        [-8.5677e+00],
        [-8.1512e+01],
        [-4.0551e+01],
        [-3.1736e+01],
        [ 6.1114e+01],
        [ 3.4307e+00],
        [ 8.0937e+01],
        [ 4.2809e+01],
        [-4.0092e+01],
        [ 1.4451e-01],
        [ 7.2235e+00],
        [-2.6295e+01],
        [ 1.3271e+01],
        [-3.3462e+01],
        [-5.3602e+00],
        [-1.0598e+00],
        [-1.7187e+01],
        [ 3.8766e+01],
        [ 9.6405e+01],
        [-1.1411e+00],
        [ 1.1931e+01],
        [-6.0546e+01],
        [-8.6898e+01],
        [-4.0922e+01],
        [ 9.6182e+01],
        [ 3.1097e+01],
        [-3.8153e+01],
        [ 6.5681e+01],
        [ 3.6343e+01],
        [ 1.4814e+01],
        [ 2.8175e+00],
        [ 6.0791e+01],
        [-1.6780e+01],
        [-3.7421e+01],
        [-7.4253e+01],
        [-4.4754e+01],
        [ 7.9280e+00],
        [-8.3077e+00],
        [-1.5596e+01],
        [-5.3963e+01],
        [ 1.8383e+01],
        [ 5.0752e+01],
        [ 3.6156e+01],
        [-1.3481e+02],
        [ 1.2788e+02],
        [-1.6894e+00],
        [-6.6330e+01],
        [-3.1602e+01],
        [ 7.8613e+01],
        [ 1.2602e+02],
        [ 2.2213e+01],
        [ 4.3295e+01],
        [ 3.9186e+01],
        [-4.8018e+00],
        [-9.5044e+01],
        [-6.0933e+00],
        [-2.2605e+01],
        [ 9.9281e+00],
        [ 4.5876e+01],
        [-7.0733e+01],
        [-2.4230e+01],
        [ 4.2625e+01],
        [ 7.1785e+01],
        [-8.7616e+00],
        [ 1.0643e+02],
        [-9.7489e+01],
        [-1.1178e+01],
        [-6.1433e+01],
        [ 6.1718e+01],
        [-2.6846e+01],
        [-8.1546e+01],
        [-2.5718e+01],
        [-8.6862e+01],
        [-1.0646e+01],
        [ 7.8497e+01],
        [-7.8234e+01],
        [ 1.0550e+01],
        [ 9.0379e+00],
        [ 5.8161e+01],
        [-2.9392e+01],
        [-1.3702e+00],
        [-3.5641e+01],
        [-1.1303e+01],
        [ 4.4115e+01],
        [-4.7318e+01],
        [-1.3279e+00],
        [ 2.7267e+01],
        [ 3.5910e+01],
        [-3.8183e+01],
        [ 1.6106e+01],
        [ 1.5219e+01],
        [ 7.6586e+01],
        [ 1.0068e+02],
        [-7.4041e+00],
        [-8.6554e+01],
        [ 5.3943e+01],
        [ 1.9130e+01],
        [-8.0814e+01],
        [ 9.3210e-01],
        [ 4.4297e+01],
        [ 6.6176e+01],
        [-4.0137e+01],
        [ 1.6253e+01],
        [ 2.6102e+01],
        [ 1.7305e+01],
        [ 1.9636e+01],
        [-3.2753e+01],
        [ 7.3306e+01],
        [ 4.4483e+01],
        [-1.8136e+01],
        [-6.4256e+01],
        [-7.2743e+00],
        [ 1.6076e+01],
        [-2.8846e+01],
        [ 6.1648e+01],
        [-8.5741e+01],
        [ 7.9569e+01],
        [ 2.6886e+01],
        [-1.2081e+01],
        [-5.8436e+01],
        [ 6.0153e+01],
        [ 4.1316e+00],
        [ 3.6961e+01],
        [ 3.9623e+01],
        [ 9.4058e+00],
        [ 2.5680e+01],
        [-5.1724e+01],
        [-8.6862e+01],
        [ 3.6339e+01],
        [ 3.7626e+01],
        [ 5.1658e+01],
        [-1.8026e+01],
        [-3.0917e+01],
        [-3.7034e+01],
        [-3.2703e+01],
        [ 5.0584e+01],
        [-5.2324e+01],
        [ 7.1300e+00],
        [-1.3551e+01],
        [ 3.8929e+01],
        [ 8.1601e+01],
        [ 5.2959e+01],
        [ 2.5436e+01],
        [ 3.6772e+00],
        [-1.0354e+01],
        [ 2.5871e+01],
        [ 4.7817e+01],
        [-3.1273e+01],
        [ 1.8338e+01],
        [ 3.3547e-01],
        [-3.2649e+01],
        [ 1.3778e+01],
        [ 7.0512e+01],
        [-1.4244e+00],
        [ 2.4517e+01],
        [-1.6975e+01],
        [-3.7072e+00],
        [-1.5213e+02],
        [ 4.2163e+01],
        [-8.1398e+01],
        [ 1.5888e+01],
        [-3.7868e+01],
        [ 3.4827e+01],
        [-7.2418e+01],
        [-6.9907e+01],
        [ 1.4585e+02],
        [-5.6309e+01],
        [ 4.8675e+01],
        [ 4.8313e+01],
        [-8.2743e+01],
        [ 1.1510e+02],
        [-6.4257e+01],
        [ 1.0723e+02],
        [-6.3731e+01],
        [ 1.7038e+01],
        [-3.1083e+01],
        [-6.9602e+01],
        [-1.0243e+02],
        [-1.1956e+01],
        [-1.9759e+01],
        [ 2.9246e+01],
        [-4.9915e+01],
        [ 1.3316e+01],
        [-3.5657e+01],
        [ 3.3967e+01],
        [ 3.9834e+01],
        [-2.5934e+01],
        [ 4.5151e+00],
        [-1.4878e+00],
        [ 4.6040e+01],
        [ 6.5560e+01],
        [-2.6113e+01],
        [ 2.8839e+01],
        [-1.9121e+01],
        [ 1.2573e+01],
        [-1.3115e+00],
        [-2.4490e+01],
        [ 4.2169e+01],
        [ 9.0321e+01],
        [-3.2724e+01],
        [-6.5744e+01],
        [-1.0827e+01],
        [-3.5629e+01],
        [ 8.6669e+01],
        [ 3.2754e+01],
        [ 4.4828e+01],
        [ 6.7108e+01],
        [-4.1276e+01],
        [ 6.1950e+01],
        [-6.7767e+00],
        [-1.9590e+00],
        [-8.9281e+01],
        [-5.3232e+01],
        [-1.3928e+02],
        [ 7.9536e+01],
        [-5.2137e+01],
        [-2.7121e+01],
        [-5.7775e+01],
        [-3.6684e+01],
        [-2.8546e+01],
        [-8.9324e+00],
        [-3.6154e+01],
        [ 8.9289e+01],
        [-3.6852e+01],
        [-4.3745e+01],
        [ 5.3771e+01],
        [-7.6258e+01],
        [ 1.5116e+01],
        [-4.4730e+01],
        [ 3.0548e+01],
        [ 8.8806e+01],
        [ 1.3537e+00],
        [ 9.1969e+01],
        [-2.1710e+01],
        [ 5.7268e+01],
        [ 1.0795e+02],
        [ 1.9779e+01],
        [ 3.5754e+01],
        [ 3.8533e+00],
        [ 4.8893e+01],
        [-1.7298e+01],
        [-5.3656e+01],
        [ 2.0623e+01],
        [ 1.7500e+01],
        [ 1.5047e+01],
        [ 5.6884e+01],
        [ 1.1082e+02],
        [-6.2856e+01],
        [ 1.0931e+02],
        [-5.8982e+01],
        [ 3.2466e+01],
        [ 3.5187e+01],
        [ 1.2073e+02],
        [ 6.1099e+01],
        [ 7.1821e+01],
        [ 1.0384e+02],
        [ 1.9880e+01],
        [-3.1841e+01],
        [-3.8156e+01],
        [-2.6637e+01],
        [-2.6367e+01],
        [-2.8881e+01],
        [-5.8671e+01],
        [ 5.8960e+01],
        [ 2.6643e+01],
        [ 5.1284e+01],
        [-1.5103e+02],
        [-6.4413e+01],
        [-2.3786e+01],
        [ 8.3696e+00],
        [ 3.8955e+01],
        [-2.4369e+01],
        [ 6.8737e+01],
        [ 3.1265e+01],
        [ 4.7362e+01],
        [-7.8704e+01],
        [ 8.3978e+01],
        [ 4.1491e+01],
        [-3.7077e+01],
        [-2.3484e+01],
        [ 1.2152e+02],
        [ 8.0609e+00],
        [-1.9867e+00],
        [-1.1358e+01],
        [-1.4535e+01],
        [-1.0134e+02],
        [-4.1773e+01],
        [-2.2994e+01],
        [-5.9255e+01],
        [-6.2004e+01],
        [-7.3826e+01],
        [-1.5389e+01],
        [-4.7288e+01],
        [ 5.3076e+01],
        [-4.5983e+01],
        [ 5.9983e+01],
        [ 8.7543e+00],
        [ 4.7501e+01],
        [-2.4264e+01],
        [-4.1825e+01],
        [-1.5774e+01],
        [ 4.0243e+01],
        [ 6.9028e+01],
        [-2.2653e+01],
        [ 5.4984e+01],
        [-2.4003e+01],
        [-2.6126e+01],
        [-1.2584e+01],
        [ 2.5312e+01],
        [-9.4338e+01],
        [ 5.3840e+01],
        [-8.9064e+01],
        [ 2.5046e+00],
        [ 3.7549e+00],
        [ 5.5524e+01],
        [-2.0146e+01],
        [-7.8858e+01],
        [-1.6932e+01],
        [-5.5324e+01],
        [ 1.1084e+02],
        [ 2.3301e+01],
        [-3.3346e+00],
        [ 8.1741e+01],
        [-4.3075e+01],
        [ 4.2052e+01],
        [-3.6995e+01],
        [-8.5916e+01],
        [-1.1385e+02],
        [-5.1785e+01],
        [ 6.6206e+01],
        [-3.5914e+01],
        [-3.9742e+01],
        [-5.9763e+01],
        [ 1.7145e+01],
        [-3.6021e+01],
        [-6.2464e+01],
        [ 4.2869e+01],
        [-1.7738e+01],
        [-7.8399e+01],
        [ 2.9430e+01],
        [ 3.2396e+01],
        [-3.5097e+01],
        [ 7.4560e+01],
        [-4.0518e+00],
        [-8.4709e+01],
        [-4.6913e+01],
        [-8.2131e+01],
        [ 6.9130e+01],
        [-2.6434e+01],
        [ 9.0776e+00],
        [-4.4396e+00],
        [ 6.1579e+01],
        [-9.6261e+01],
        [ 2.6910e+01],
        [ 7.2752e+01],
        [-6.4868e+01],
        [-3.4839e+01],
        [-8.2137e+00],
        [-6.7692e+01],
        [ 9.8981e+00],
        [ 8.2071e+01],
        [-7.5414e+01],
        [ 2.3149e+01],
        [ 4.8603e+01],
        [ 1.4946e+01],
        [-1.2804e+01],
        [-1.4695e+01],
        [-1.1664e+02],
        [-9.3898e+01],
        [-5.1837e+00],
        [ 4.1560e+01],
        [-5.8879e+01],
        [-8.5653e+00],
        [-4.5126e+01],
        [ 4.5370e+01],
        [ 9.8439e+00],
        [-1.5480e+01],
        [-6.2150e+01],
        [ 7.8696e+01],
        [ 7.3608e+01],
        [-6.6755e+00],
        [-1.1290e+01],
        [-5.8171e+00],
        [ 9.3532e+01],
        [-4.3137e+01],
        [ 6.5150e+01],
        [-9.0773e+01],
        [-1.9953e+00],
        [ 1.0346e+01],
        [ 7.9044e+01],
        [-2.6156e+01],
        [ 9.0495e+00],
        [ 3.6166e+01],
        [ 9.9363e+00],
        [-4.8471e+01],
        [-8.6808e+01],
        [ 7.7289e+01],
        [-1.4532e+01],
        [ 1.1070e+01],
        [ 2.6672e+00],
        [-1.8771e+01],
        [-4.7058e+01],
        [-1.1497e+01],
        [ 1.0175e+02],
        [ 6.6620e+01],
        [ 7.2636e+01],
        [ 4.8824e+01],
        [ 5.8807e+01],
        [ 5.9673e+01],
        [-1.4591e+01],
        [ 8.6214e+01],
        [-1.9937e+01],
        [-4.4355e+00],
        [ 6.5533e+01],
        [ 1.8220e+01],
        [-1.5688e+01],
        [ 7.5570e+01],
        [ 6.7604e+01],
        [-2.8058e+01],
        [-1.5143e+01],
        [-2.2788e+01],
        [ 6.7652e+01],
        [ 4.5769e+01],
        [-4.3255e+01],
        [-1.4394e+01],
        [-3.5304e+01],
        [ 2.0711e+01],
        [-6.9752e+01],
        [ 1.1258e+02],
        [ 2.0548e+01],
        [-6.5131e+01],
        [ 3.5317e+01],
        [ 4.3201e+01],
        [ 5.0964e+01],
        [ 3.8668e+01],
        [ 4.5179e+00],
        [-4.7128e+01],
        [-3.0157e+01],
        [ 7.0219e+00],
        [ 3.8266e+01],
        [ 1.4326e+01],
        [-5.6423e+01],
        [-8.7527e+00],
        [-4.7541e+01],
        [-1.9345e+01],
        [-4.5935e+01],
        [ 6.8057e+00],
        [ 1.4035e+01],
        [-3.0284e+01],
        [-1.9236e+01],
        [ 4.9153e+01],
        [-7.4448e+01],
        [ 2.7226e+01],
        [-1.2065e+02],
        [ 4.7741e+01],
        [ 8.0378e+01],
        [-1.1194e+02],
        [-3.0025e+01],
        [-4.3967e+00],
        [ 1.5399e+01],
        [ 8.7856e+00],
        [-9.1464e+00],
        [ 2.0180e+01],
        [ 1.8998e+01],
        [-6.7696e+01],
        [ 9.0868e+00],
        [-2.0790e+01],
        [-1.5215e+02],
        [-2.1994e+01],
        [ 4.7043e+01],
        [ 3.5243e+01],
        [ 4.0841e+01],
        [-4.4867e+01],
        [-5.7410e+00],
        [ 2.6565e+01],
        [ 4.2892e+01],
        [-1.8092e+01],
        [ 9.5010e+01],
        [ 1.5894e+01],
        [ 7.2038e+01],
        [-3.7011e+01],
        [ 3.8585e+01],
        [-5.8271e+00],
        [-1.9439e+01],
        [ 3.8891e+01],
        [-3.3609e+01],
        [-3.8776e+01],
        [ 1.0025e+02],
        [-2.3630e+01],
        [ 3.2509e+01],
        [ 4.9705e+01],
        [ 1.9597e+01],
        [ 6.0736e+01],
        [ 9.2121e+01],
        [ 1.0889e+01],
        [-1.3745e+01],
        [ 3.5964e+00],
        [-2.9098e+01],
        [ 4.8578e+01],
        [ 6.5545e+01],
        [ 9.2300e+00],
        [-1.1836e+01],
        [ 4.5149e+00],
        [ 5.3491e+01],
        [ 9.5715e+00],
        [ 1.2114e+00],
        [ 2.2728e+01],
        [ 4.8888e+01],
        [-3.1504e+01],
        [ 7.2651e+00],
        [ 3.7467e+01],
        [-2.9230e+01],
        [ 1.1699e+01],
        [ 4.6031e+01],
        [-1.4664e+00],
        [ 1.1857e+02],
        [ 6.4591e+00],
        [ 7.2258e+01],
        [ 1.7171e+01]], device='cuda:6')
tensor(1.5112, device='cuda:6')
Eval done in 0:03:39.438274
End time: 2023-07-05 02:46:14.088971
Total time: 10:22:52.358415
