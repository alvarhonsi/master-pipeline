Start time: 2023-07-05 13:32:32.524661
torch.Size([1024, 10]) torch.Size([1024, 1])
Sequential(
  (0): Linear(in_features=10, out_features=512, bias=True)
  (1): ReLU()
  (2): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
  )
  (3): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
  )
  (4): Linear(in_features=512, out_features=1, bias=True)
)
Settings:
DEVICE: cuda:1 INFERENCE_TYPE: svi OBS_MODEL: homoskedastic PRIOR_LOC: 0.0 PRIOR_SCALE: 1.0 LIKELIHOOD_SCALE_LOC: 1.0 LIKELIHOOD_SCALE: 0.3 GUIDE_SCALE: 0.001 TRAIN_SIZE: 20000
Initial parameters:
net_guide.net.0.weight.loc torch.Size([512, 10]) Parameter containing:
tensor([[-0.0447,  0.0756, -0.2127,  ...,  0.2609,  0.4910,  0.2665],
        [-0.2647, -0.0771,  0.2573,  ..., -0.1631,  0.2988,  0.2101],
        [ 0.0411, -0.3286, -0.2541,  ..., -0.6626, -0.0275,  0.2559],
        ...,
        [-0.4244,  0.2789, -0.2359,  ...,  0.0649, -0.5205, -0.0421],
        [-0.4508, -0.1568,  0.2182,  ..., -0.4388, -0.3859, -0.0195],
        [-0.3507,  0.0489,  0.4109,  ..., -0.0855, -0.2056, -0.2932]],
       device='cuda:1', requires_grad=True)
net_guide.net.0.weight.scale torch.Size([512, 10]) tensor([[0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        ...,
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]],
       device='cuda:1', grad_fn=<AddBackward0>)
net_guide.net.0.bias.loc torch.Size([512]) Parameter containing:
tensor([-3.6166e-02, -1.3915e-01,  2.9564e-01,  2.9611e-01,  2.2214e-01,
        -9.7888e-02,  5.8897e-01, -1.8524e-01,  2.0443e-01,  5.8446e-02,
        -1.7745e-01, -1.9895e-01, -1.1682e-01, -5.3616e-01,  2.0789e-01,
        -6.4598e-02,  3.3362e-01,  1.3427e-01, -3.1360e-02, -3.8676e-01,
         5.7533e-01,  9.6737e-02, -3.1188e-01, -1.9318e-01, -3.3081e-01,
        -1.8537e-01,  3.6419e-01, -1.3505e-01,  3.0185e-01,  5.7582e-01,
        -3.7531e-01, -4.6969e-01, -6.4841e-02,  4.0309e-01, -4.3244e-01,
        -1.9433e-01,  1.6605e-01, -2.1830e-01,  2.8050e-01, -9.4567e-02,
         1.5417e-01,  1.7902e-01, -2.3644e-01, -2.4925e-01, -2.9956e-01,
        -3.7044e-02,  1.6814e-01, -1.9854e-01, -2.5638e-01,  2.6855e-01,
        -9.5205e-02,  3.6366e-01, -8.0318e-01, -1.6955e-01, -2.2713e-01,
        -2.0035e-02,  1.3097e-01,  2.3065e-01,  3.7070e-01, -1.3243e-01,
        -3.6160e-02, -4.8206e-03, -1.1376e-03,  2.0086e-01, -2.2492e-01,
         3.9010e-01, -2.8781e-01,  4.2783e-02, -3.1186e-01,  2.7993e-01,
         3.9311e-01,  7.0192e-02, -9.7189e-02,  8.0272e-01, -3.1546e-01,
        -5.5958e-01,  2.1423e-02, -1.2455e-01, -3.3646e-01,  2.7934e-01,
        -1.5209e-01,  2.7482e-01, -1.1987e-01,  4.2689e-01,  1.3793e-02,
         2.3633e-01, -3.1819e-01,  5.3045e-02,  1.5081e-01,  3.4590e-01,
        -3.7396e-01, -7.3865e-02, -9.2203e-02,  6.5114e-02,  3.8257e-01,
        -1.5689e-01,  1.7788e-01,  5.1722e-01, -4.2938e-01,  8.0669e-02,
        -6.2920e-03, -1.3110e-01, -2.6427e-02,  4.4446e-01, -5.4677e-01,
        -1.6423e-01,  3.0083e-02,  9.8959e-02, -1.1722e-01,  2.3326e-01,
         1.7362e-01, -4.6287e-01, -5.5670e-01, -9.9926e-02, -3.0622e-01,
         1.4751e-01, -6.1184e-01, -5.0763e-01, -1.6882e-02, -5.2880e-01,
        -7.5939e-01, -1.9816e-01, -1.5566e-01,  3.9489e-01,  3.2330e-01,
        -1.3048e-01,  2.4041e-01, -2.6492e-01, -1.5796e-01,  7.9179e-01,
         1.4048e-01,  5.2655e-01,  2.2442e-01, -9.1619e-02, -1.0366e+00,
         2.6553e-01,  2.0384e-01, -1.7155e-01, -1.6481e-03,  3.2141e-01,
        -5.8581e-01,  6.4256e-01, -3.9943e-01, -1.9391e-01, -2.6091e-01,
         1.1797e-01,  4.4223e-02,  1.6194e-01, -3.5289e-01, -3.2432e-01,
        -2.6665e-01,  3.0188e-01, -8.1698e-02, -1.5214e-01, -6.1498e-01,
        -3.0815e-02, -6.0532e-01,  4.0075e-01, -7.2847e-02,  2.7709e-01,
        -2.6974e-01,  2.5113e-01,  4.1658e-01,  3.3207e-01,  6.8874e-02,
        -5.5198e-02, -4.3679e-01,  5.4634e-01, -1.6460e-01, -1.7971e-01,
         3.5597e-01,  5.3952e-01, -2.0925e-01, -4.3910e-01, -3.2569e-01,
         7.6319e-01, -4.8673e-01,  2.1589e-02,  3.6273e-01, -3.1636e-01,
         9.0259e-02, -1.8414e-02, -2.3747e-01, -5.9817e-02, -1.9344e-01,
        -1.7293e-01, -9.0646e-02, -2.1341e-01, -4.3948e-01, -7.6056e-01,
        -2.0861e-01,  6.6792e-01, -1.3956e-01, -3.2485e-01,  1.1441e-01,
         1.7686e-01, -2.2298e-01,  4.3501e-01, -2.1019e-01, -1.8008e-02,
         3.9982e-01, -1.0706e-01,  3.2638e-01, -5.9527e-01,  1.1342e-01,
        -5.9372e-01, -9.7981e-02, -4.6723e-02,  1.7939e-01, -1.9921e-01,
         6.0286e-01, -5.7475e-01, -2.8755e-01, -2.1078e-02,  3.3662e-01,
        -5.4672e-01, -8.4574e-02,  7.0585e-01, -3.7891e-02, -2.0209e-01,
        -4.6297e-02, -1.0724e-01, -3.7633e-02,  3.6016e-01,  6.9463e-01,
         8.4260e-02,  4.2845e-01, -2.1915e-01,  2.0365e-01,  3.4857e-01,
         2.7607e-01, -4.2154e-01, -7.8276e-01,  3.9964e-02, -1.5784e-02,
        -6.7150e-02,  7.5284e-02,  2.0118e-01,  4.6005e-01,  1.2877e-01,
         1.7722e-01,  2.7403e-01, -4.4400e-01, -3.5898e-01,  3.2615e-01,
        -2.8858e-01,  1.9766e-01,  3.4877e-01,  3.3363e-01, -3.0321e-02,
        -1.4267e-01,  7.5654e-03, -4.5793e-01,  9.4683e-02, -7.8115e-01,
         3.5276e-01, -2.6607e-02, -1.3633e-01,  1.3946e-01, -1.6989e-01,
         9.7561e-02,  1.9092e-01,  1.1244e-01, -1.5142e-02, -2.4859e-01,
         2.6107e-01,  1.3460e-01, -1.9601e-01,  2.2171e-01, -1.1813e-01,
        -2.7271e-02,  2.2744e-01, -6.0848e-02,  1.0853e-01,  2.9351e-01,
         2.4204e-02, -1.1631e-01,  2.2765e-01,  3.5871e-01,  2.9450e-01,
        -5.8593e-01,  3.7996e-02, -4.5191e-01,  2.0098e-01,  1.1031e-01,
         2.5319e-01,  3.8350e-01,  4.1628e-01,  2.2083e-01, -5.2145e-01,
        -1.2084e-04, -2.9774e-01,  5.9605e-01, -1.4718e-01, -2.0328e-01,
        -2.7510e-01,  6.2981e-02,  2.8263e-01,  1.0762e-01, -3.1115e-02,
        -8.6717e-02,  1.2602e-01,  3.4481e-01, -3.1291e-01,  4.4573e-02,
        -5.4093e-02,  1.2785e-02,  5.9368e-01, -9.3458e-02, -3.0025e-02,
        -8.2114e-01,  3.5871e-02, -1.2330e-01, -2.9151e-02, -1.7028e-02,
        -6.4747e-01,  6.7500e-01, -9.3829e-02, -3.5783e-01, -1.1899e-01,
        -1.5495e-01,  1.4848e-01, -1.3111e-02, -4.6007e-01,  7.6984e-02,
        -3.0186e-02,  5.6222e-01, -2.4689e-01, -9.7050e-02, -1.6777e-01,
        -3.7750e-01, -2.4305e-01, -4.1383e-01,  3.1174e-01, -3.7243e-01,
        -7.9324e-02,  1.1726e-01,  6.9679e-01,  1.9514e-01, -5.7582e-02,
        -2.1583e-01,  1.9784e-02,  1.2355e-01,  2.7329e-01,  9.2189e-02,
         1.3324e-01,  1.3457e-01,  1.5220e-01,  5.6737e-01, -4.6108e-01,
        -1.4723e-01,  3.6228e-01,  3.5389e-01, -1.3471e-01, -4.3502e-01,
         5.7319e-02,  6.4020e-01, -3.4931e-01,  5.9252e-01, -3.7241e-01,
         4.8289e-01, -7.1217e-01, -1.7626e-01,  5.8545e-02, -4.4086e-01,
         4.1514e-01,  3.5856e-02,  2.0005e-01, -7.7625e-02,  4.2968e-01,
         4.4622e-01, -2.8619e-01, -5.0256e-01, -6.0599e-01, -1.0697e-01,
        -6.6589e-03, -1.3865e-01, -1.9513e-01, -1.1505e-01, -1.1677e-01,
         1.4042e-01,  1.0355e-01, -1.9033e-01,  2.3525e-02, -3.3168e-01,
         3.7288e-01,  3.2279e-01,  3.5255e-01, -1.1326e-01,  3.3135e-01,
        -1.7131e-01,  3.8987e-01, -1.6718e-01,  2.1797e-02, -6.6744e-01,
        -3.9690e-01, -6.4341e-01,  1.5612e-01,  1.4624e-01, -1.5568e-01,
         1.6977e-02, -1.1612e-01, -2.9578e-01,  3.9115e-01, -1.8719e-01,
         2.2748e-01,  1.3767e-01,  3.3728e-01,  1.0920e-01, -3.8483e-01,
         2.2107e-01,  2.1028e-01,  1.3182e-01,  1.1805e-01,  1.4939e-02,
         4.6891e-01, -3.7607e-01, -1.6891e-01, -1.7116e-01, -6.4544e-02,
        -3.4030e-01,  4.5838e-01,  3.0842e-01,  2.1312e-01, -5.4339e-02,
         2.4640e-01,  9.0786e-02, -6.6366e-01,  3.6862e-02,  3.8134e-01,
        -1.4490e-01, -5.9302e-02, -1.5054e-01,  3.4661e-02, -2.3997e-01,
        -2.0295e-01, -5.0164e-01, -2.1711e-02, -5.0930e-01, -2.2989e-01,
        -1.3395e-01, -7.2049e-02,  5.1076e-01, -1.9724e-01,  1.3791e-01,
         2.4521e-01,  4.4357e-02, -7.0624e-01, -1.9231e-01, -4.9890e-01,
        -3.3431e-01,  9.3956e-02,  3.9203e-02, -3.3491e-01, -7.7078e-01,
        -3.9517e-01, -7.0076e-03, -4.3714e-01, -5.3338e-01, -1.1568e-01,
        -7.7663e-01, -1.9353e-01,  1.6875e-01,  1.5197e-01,  3.1701e-01,
        -2.0656e-01,  2.4972e-01,  6.6190e-02, -2.9960e-02, -8.0230e-01,
        -4.1852e-02,  2.3524e-02,  3.8774e-01, -3.4516e-01,  2.3149e-01,
        -8.1876e-02, -7.5342e-04,  2.5952e-01,  1.2734e-01, -1.9654e-01,
        -2.9427e-02, -4.5514e-02,  5.0196e-01,  4.5032e-01,  4.2538e-01,
         2.0322e-01,  7.1951e-01, -5.9948e-01,  3.0338e-01, -2.7482e-02,
        -9.1157e-02, -2.4218e-01, -2.1302e-02,  2.9174e-01,  3.2023e-02,
         4.5233e-02, -1.0554e-01,  4.9416e-01,  1.0603e-01, -2.3242e-01,
        -1.0399e-01, -2.7018e-01,  2.0762e-01,  3.4917e-01, -7.6422e-02,
         1.4725e-01, -5.7476e-02, -7.6483e-02,  3.3816e-01, -5.8852e-01,
         1.6630e-02,  8.2448e-03], device='cuda:1', requires_grad=True)
net_guide.net.0.bias.scale torch.Size([512]) tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010],
       device='cuda:1', grad_fn=<AddBackward0>)
net_guide.net.2.0.weight.loc torch.Size([512, 512]) Parameter containing:
tensor([[-0.1347,  0.2989, -0.5339,  ..., -0.5265, -0.2761, -0.0241],
        [-0.4257,  0.3315,  0.2079,  ..., -0.1017,  0.1317,  0.5264],
        [-0.6097, -0.1783,  0.2613,  ...,  0.3783, -0.4814, -0.0344],
        ...,
        [ 0.0203, -0.2584, -0.2590,  ..., -0.4645, -0.5785, -0.1913],
        [-0.1921,  0.9825,  0.0440,  ...,  0.2357, -0.6674,  0.3438],
        [ 0.4051, -0.2642,  0.7370,  ...,  0.3095,  0.2294,  0.2429]],
       device='cuda:1', requires_grad=True)
net_guide.net.2.0.weight.scale torch.Size([512, 512]) tensor([[0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        ...,
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]],
       device='cuda:1', grad_fn=<AddBackward0>)
net_guide.net.2.0.bias.loc torch.Size([512]) Parameter containing:
tensor([ 5.1383e-01,  2.2676e-01, -1.8156e-01, -2.9724e-01, -1.5685e-01,
         6.0414e-01,  6.1232e-02,  2.7250e-02, -2.3418e-01, -4.5196e-02,
        -2.3660e-01, -6.8167e-01,  5.7750e-02,  3.6466e-01,  3.1874e-01,
         5.3432e-02,  1.8438e-01,  8.8736e-02,  3.0512e-01,  5.2947e-02,
         8.0293e-03,  6.4511e-02,  1.7163e-01,  7.7425e-02,  2.7578e-01,
        -2.7774e-01,  6.8803e-01,  4.6933e-01,  2.0090e-01, -4.3950e-01,
        -2.8161e-01,  3.8266e-01, -3.2890e-02, -6.4451e-01,  6.4740e-01,
        -2.4258e-01, -5.4273e-01, -2.0864e-01, -1.6346e-01,  4.2535e-01,
         6.1291e-02, -1.3541e-01,  3.5634e-01,  2.0267e-01, -3.8041e-01,
         4.7205e-01, -1.3605e-02,  3.2818e-01, -5.6446e-01, -2.6980e-01,
        -3.6690e-01,  1.6149e-01, -2.4639e-01, -4.7106e-02,  4.9669e-02,
        -1.6383e-01, -6.6454e-01, -2.0559e-01,  3.5866e-01, -6.5202e-01,
        -2.5192e-01, -1.2759e-01, -1.0010e-01,  5.5464e-01,  2.6002e-01,
         6.1209e-01,  4.5297e-02, -2.3984e-01,  2.4185e-01, -5.3261e-01,
        -1.5795e-03,  3.7480e-01,  2.2998e-01,  2.5373e-01,  6.2845e-01,
        -4.8846e-01, -2.6556e-01,  1.0543e-01, -1.7961e-01, -4.7442e-02,
         2.0987e-01,  1.4915e-01, -5.4043e-01,  6.3419e-01, -1.4536e-02,
        -1.3952e-01,  1.4541e-03, -1.5868e-01, -4.4381e-02, -7.2536e-03,
         3.0550e-01,  1.7987e-01,  2.4523e-01, -2.6376e-01, -5.4468e-01,
         8.4813e-02, -1.6345e-01, -9.2069e-02,  3.3448e-01,  8.8672e-02,
        -4.2712e-01, -7.8307e-02,  1.5671e-01, -1.4268e-01, -2.6539e-01,
         1.5692e-02, -1.4193e-01,  6.3396e-01, -1.6775e-01, -4.3899e-01,
        -2.9766e-01,  2.0886e-01,  6.2453e-02,  1.4515e-01, -1.7576e-01,
        -5.2782e-01,  2.8647e-01, -3.6118e-01, -1.1295e-01, -1.5333e-01,
         3.8649e-02, -2.3035e-01,  4.8449e-01, -6.5390e-01,  1.7446e-01,
        -2.0998e-01, -2.4014e-01,  3.8094e-01,  5.4638e-01, -9.2301e-02,
         7.2799e-01, -5.4894e-02, -2.6638e-01,  1.8212e-01,  6.3314e-02,
         4.4116e-02, -1.3119e-01,  7.7694e-01,  1.6987e-02, -1.0065e-01,
        -4.2424e-01,  5.3672e-01, -1.0983e-01,  1.8426e-01, -1.5716e-01,
         1.5363e-01,  9.4920e-02, -3.5707e-01, -3.0785e-02, -4.7559e-02,
        -6.1601e-01,  1.6270e-01,  1.1011e-01, -1.8307e-01,  2.0297e-01,
        -3.7307e-01,  1.1780e-01, -8.7353e-01, -6.3581e-01, -9.1177e-02,
         4.5015e-01,  5.8748e-01, -2.0362e-02,  5.2032e-01,  1.2865e-01,
        -2.7387e-01,  3.3855e-01, -8.1991e-02, -3.3930e-02, -2.2129e-01,
        -1.1106e-01,  2.9059e-01,  3.2387e-01, -3.3815e-02, -3.7728e-01,
         5.8272e-01,  6.2464e-01, -2.5074e-01, -4.3780e-01,  5.6216e-01,
         1.2451e-01, -1.2899e-01,  1.2758e-01, -9.5528e-02,  2.0078e-01,
        -2.1147e-01, -1.9996e-01,  2.1658e-01, -4.6028e-01,  1.7152e-01,
        -1.7944e-01,  2.5667e-02,  2.6994e-01, -3.3626e-01, -3.3286e-01,
         2.1351e-01,  3.3059e-01,  8.8407e-02,  1.1184e-01, -9.3410e-01,
        -3.5365e-01, -4.0851e-01,  1.9238e-01,  1.9179e-01,  6.0050e-01,
        -6.1300e-01, -7.7526e-02,  4.3369e-01,  1.9656e-01,  7.5422e-02,
         1.2600e-01,  1.8432e-01,  1.6680e-01,  9.4564e-02,  2.1989e-01,
         6.5338e-02,  3.0670e-01,  2.1004e-01, -3.4678e-02,  3.7545e-01,
        -7.9084e-02, -6.3368e-02,  5.0477e-01,  2.8279e-01, -6.6957e-02,
        -8.2414e-02, -4.5131e-01,  8.7372e-01, -1.2054e-01,  2.9910e-01,
        -7.9745e-04,  1.4130e-01,  2.4211e-01,  1.4722e-01,  2.2276e-02,
         6.4288e-01,  1.9376e-01,  2.3107e-01,  4.2620e-02, -1.0629e-01,
         4.9965e-01,  1.2873e-01, -5.4799e-02,  4.2276e-01, -2.7031e-01,
        -1.9287e-01, -2.8321e-01, -4.5494e-01, -1.1602e-01, -1.0290e-01,
        -1.4740e-01,  4.4534e-01,  5.1917e-01, -1.4431e-01, -7.7550e-01,
         1.6413e-01, -2.1547e-01,  3.4814e-01,  2.9550e-02,  1.2023e-01,
         2.7038e-01, -2.4514e-01, -2.5994e-01, -4.0943e-01,  6.1809e-01,
        -6.4172e-02,  1.4789e-01,  4.9981e-01,  5.8535e-01,  2.1067e-01,
        -7.5197e-02, -2.0989e-01, -6.3907e-02, -4.6315e-01,  2.4584e-01,
        -6.1935e-01,  1.9323e-02,  5.7194e-01, -2.9602e-01, -5.6871e-02,
        -4.8013e-01, -2.9334e-02,  4.9256e-02, -4.2844e-01,  1.4215e-01,
        -1.9628e-01, -5.6353e-01,  2.3770e-01, -1.9504e-01, -6.0946e-02,
         8.6788e-01,  1.5729e-01, -3.3453e-01,  4.2605e-02,  3.4771e-01,
         2.2894e-01,  8.9872e-02,  2.3474e-01,  3.7149e-01, -2.5347e-01,
         1.2892e-01, -3.7038e-01,  6.8718e-02, -2.8476e-01,  3.6732e-01,
        -1.4778e-01,  3.5754e-01,  5.1770e-02, -1.2465e-01,  1.4894e-02,
        -5.7676e-03, -4.7557e-01, -5.1856e-01,  1.0399e-01,  8.1136e-02,
         5.3078e-01, -4.8298e-01,  2.6217e-01,  1.1708e-01, -2.2655e-02,
         3.2414e-01,  3.2335e-01, -3.2487e-01, -3.6452e-01,  4.9279e-01,
         2.7096e-01, -2.5982e-01, -2.0117e-01, -2.4121e-01, -1.1426e-01,
        -7.0331e-02, -3.8127e-01, -3.8204e-01, -1.4516e-01, -3.1634e-01,
         2.4916e-01,  2.1327e-01, -2.6620e-01, -1.7288e-01,  2.1561e-02,
         2.7197e-01, -1.3148e-01,  8.5358e-02, -2.5469e-01,  1.9918e-01,
        -8.2631e-02, -3.2942e-01,  4.1063e-01, -2.2063e-01,  1.4496e-01,
         1.9767e-01, -1.2407e-01, -1.5407e-01, -5.4703e-01,  7.7805e-02,
        -4.6431e-01, -1.4431e-01,  9.7252e-02,  6.0515e-01, -5.5042e-01,
        -2.1915e-01, -2.3620e-01,  6.5295e-02,  8.8855e-01,  1.2050e-01,
        -2.8610e-01,  1.6722e-01,  4.6341e-01,  9.4008e-03, -9.6328e-02,
        -3.3636e-01,  4.1791e-01,  1.4727e-01,  4.5041e-01, -4.3296e-01,
        -3.3456e-02,  6.8088e-02, -1.9341e-01, -2.2595e-01,  1.5026e-01,
        -1.9233e-01, -2.3071e-02, -1.5759e-01,  2.4411e-01, -1.4933e-01,
        -7.8673e-02, -5.1893e-01, -1.8274e-01, -3.6652e-01,  3.9821e-01,
        -1.1308e-03,  1.1077e-01,  1.1272e-01,  1.4247e-01, -2.5590e-01,
        -2.6423e-01, -3.1982e-01,  5.4112e-01,  4.2725e-01,  4.2929e-02,
        -1.4493e-01,  4.0068e-01, -1.5884e-01, -4.5532e-01, -3.6434e-01,
        -2.6256e-01, -1.9314e-01, -3.0976e-01,  2.1947e-01,  1.2527e+00,
         4.6440e-02,  5.4746e-02, -4.3317e-02,  3.7618e-01, -3.7077e-01,
        -2.0447e-01, -1.2383e-01,  2.0692e-01,  1.3606e-01,  1.9516e-01,
         2.2275e-01,  1.7480e-01,  3.2938e-01, -5.1290e-02, -7.7177e-01,
        -2.7293e-01,  3.2536e-01, -1.2914e-01,  8.3979e-02,  3.6308e-02,
        -3.2365e-02, -2.9454e-01,  3.3357e-01, -1.0323e-01,  2.0189e-01,
         2.5102e-02,  4.2577e-01, -3.1884e-01,  4.0641e-01,  8.1616e-03,
         3.8972e-01, -1.5253e-01,  6.5812e-01, -3.0501e-01,  1.1704e-01,
        -3.4881e-01,  1.1053e-02, -3.0909e-01, -7.7253e-02,  3.6673e-01,
        -7.6565e-02,  9.1087e-03, -1.7329e-01,  2.6309e-01,  8.9734e-02,
        -4.5330e-01,  1.5570e-02, -4.8282e-01,  4.0811e-02, -3.2425e-02,
        -3.0552e-01,  9.6641e-02, -1.8799e-02,  1.7777e-02,  7.3005e-01,
         1.4098e-01,  1.0050e-01, -1.0706e-01, -1.7136e-01,  2.0919e-01,
         2.9493e-01, -8.6930e-01, -8.4521e-02, -4.6610e-01,  4.6881e-01,
         2.8357e-01,  2.9123e-01,  5.6292e-01, -7.6437e-01,  9.9124e-02,
        -1.5738e-01,  4.0906e-01,  1.5995e-01, -3.8363e-01,  1.4078e-02,
         2.1916e-01,  2.0725e-01, -1.0849e-01, -4.3832e-01, -4.3885e-01,
        -2.4597e-02,  3.0685e-01, -4.8883e-01, -4.4606e-02, -8.3244e-01,
        -3.0004e-01,  3.6187e-01, -1.8884e-01,  1.1498e-01, -2.2350e-01,
         1.8464e-01, -5.0595e-02,  3.7592e-01, -1.6456e-01,  9.8069e-02,
         2.6785e-01,  2.1655e-01,  2.4135e-01, -4.7972e-01,  1.9272e-01,
         1.7350e-01, -4.1612e-01], device='cuda:1', requires_grad=True)
net_guide.net.2.0.bias.scale torch.Size([512]) tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010],
       device='cuda:1', grad_fn=<AddBackward0>)
net_guide.net.3.0.weight.loc torch.Size([512, 512]) Parameter containing:
tensor([[-0.1730, -0.2277, -0.1308,  ..., -0.0064,  0.0714,  0.0089],
        [-0.3097, -0.3952,  0.1457,  ...,  0.1606, -0.3123,  0.2392],
        [-0.3884,  0.1280, -0.2651,  ..., -0.3274,  0.0380,  0.5866],
        ...,
        [-0.1138,  0.1471, -0.2607,  ..., -0.1059,  0.1240, -0.2748],
        [ 0.1022, -0.0441,  0.4888,  ...,  0.2420, -0.3309, -0.0214],
        [ 0.3723, -0.2546, -0.5360,  ...,  0.0103,  0.2929, -0.4245]],
       device='cuda:1', requires_grad=True)
net_guide.net.3.0.weight.scale torch.Size([512, 512]) tensor([[0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        ...,
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]],
       device='cuda:1', grad_fn=<AddBackward0>)
net_guide.net.3.0.bias.loc torch.Size([512]) Parameter containing:
tensor([ 1.4179e-01,  3.2210e-01, -5.6643e-01,  2.7856e-01,  4.0780e-01,
        -5.2465e-01, -4.4860e-01,  6.3692e-01,  1.2261e-01,  3.3203e-01,
         1.1851e-01,  3.5166e-01,  4.1000e-01, -6.7416e-02,  5.7536e-01,
         9.8060e-02,  4.7483e-02, -9.5358e-02,  5.6268e-02,  4.9899e-02,
         2.9323e-01,  5.6371e-01,  2.5355e-01, -7.4552e-02, -3.9356e-01,
         1.9312e-01, -4.2989e-03, -7.0626e-02, -1.7859e-01,  4.3795e-01,
        -3.8399e-01,  5.2805e-02, -1.2964e-01,  5.6573e-02, -1.4092e-01,
         1.6990e-01,  6.7457e-02, -3.0747e-01,  4.2022e-01,  3.0776e-01,
        -3.1603e-02,  1.7747e-01,  1.3542e-01, -2.8546e-01,  6.4476e-01,
         2.1349e-02, -7.8576e-01,  4.7399e-02, -1.9146e-02,  8.6159e-04,
         4.6737e-01,  3.0309e-01, -8.5541e-02, -2.5931e-02, -1.7506e-01,
        -3.3630e-01,  1.6496e-01, -2.1160e-01,  8.8874e-02,  9.7483e-02,
         1.7767e-01,  8.5455e-01,  3.7553e-01,  1.7289e-01,  3.1729e-01,
        -1.1959e-01,  6.3505e-01, -3.6701e-01, -3.2456e-01,  4.0400e-01,
         3.2255e-01, -6.0352e-01,  2.1656e-02, -3.1416e-01, -3.4468e-01,
        -3.2838e-01,  1.2244e-01,  2.3571e-01,  5.9361e-01,  2.3576e-01,
         2.9457e-01,  2.5872e-01,  5.8149e-01, -4.4340e-01, -5.3872e-01,
        -2.0802e-01,  4.6460e-01, -2.5942e-01, -1.6369e-01, -3.9992e-01,
        -4.5108e-01,  1.5733e-01,  1.2554e-03,  1.2605e-01,  1.7727e-01,
        -1.0899e-01,  4.6134e-01, -1.1725e-01, -1.8230e-01, -3.0823e-01,
         1.0486e-02,  6.9209e-04, -1.7649e-01,  2.0212e-01, -1.1128e-01,
        -2.9200e-01, -4.3355e-01, -2.6220e-02, -3.9349e-01,  7.9136e-02,
         1.3552e-01, -5.1725e-01, -1.9342e-01, -9.7791e-02,  7.8979e-03,
        -3.1055e-01, -3.4341e-01, -1.3593e-01,  1.9896e-01, -1.7927e-01,
        -5.4761e-01, -2.2198e-01,  4.2610e-01,  8.2436e-02, -2.0173e-01,
         2.4040e-02, -1.8343e-01, -2.1978e-01,  3.5884e-01, -7.7458e-01,
         2.3324e-01,  1.3607e-01, -3.9449e-01,  4.1063e-01, -5.3288e-01,
         1.1797e-01, -3.6661e-01,  5.9781e-01, -2.7411e-01,  8.7778e-02,
         1.4884e-01, -3.0281e-01, -6.3868e-01, -1.1967e-01,  2.4771e-01,
         5.4744e-01, -1.4941e-01,  2.3260e-02,  3.9616e-04, -4.2770e-01,
        -4.0471e-01, -2.0044e-01,  3.2872e-01,  4.6651e-02,  2.4371e-01,
         1.9984e-01,  1.5637e-01, -8.4627e-02,  8.0435e-02,  1.6755e-01,
         2.4172e-01, -5.1212e-01,  1.8761e-01, -2.4661e-01,  1.5017e-01,
        -4.1426e-01,  3.1818e-01, -2.4743e-02, -6.2680e-02,  1.5470e-01,
         1.4934e-01,  2.2034e-01,  1.2142e-01,  2.1281e-01,  5.2308e-01,
         1.7412e-01,  2.7777e-01,  1.9550e-01,  5.3673e-01,  1.1650e-01,
        -1.3916e-01, -6.9720e-01,  6.8880e-01,  2.5903e-01, -1.0851e-01,
         1.5277e-01,  3.2483e-01, -2.9587e-02, -2.5160e-01, -8.1416e-02,
         7.9530e-02, -2.6971e-01,  7.0683e-01, -9.2652e-02, -2.7599e-01,
        -2.8310e-01, -3.0244e-01,  2.5042e-01, -2.0662e-01, -1.3467e-01,
        -3.8732e-01, -3.3861e-01, -2.8108e-01, -3.0866e-01, -6.7359e-02,
         3.5845e-01, -1.1492e-01, -2.6174e-01,  7.9780e-01,  6.6983e-02,
        -3.5975e-01,  4.4830e-01,  2.3262e-01, -3.8860e-01,  3.2931e-01,
        -5.0148e-01,  3.9907e-01,  6.3266e-01,  1.0864e-01,  3.5626e-02,
         4.6151e-01, -4.1601e-01,  2.0126e-01,  2.8901e-01, -2.9050e-01,
         1.5636e-01,  1.5314e-01, -2.6690e-01,  2.0631e-01, -1.2344e-01,
         5.0111e-02, -2.8826e-01, -1.3203e-01, -1.0933e-01, -1.2740e-01,
        -1.6363e-01, -3.2539e-02, -4.1435e-02,  2.0555e-01,  2.7631e-01,
        -1.3128e-01,  1.9418e-01,  2.1531e-01,  3.0464e-01,  1.2553e-01,
        -4.3558e-03,  3.5148e-03,  4.5660e-02, -2.6346e-01, -1.2613e-01,
        -1.6006e-01,  2.5396e-01,  2.3544e-03,  2.7709e-01,  2.7365e-01,
         1.5975e-01, -2.0429e-01,  2.6308e-01,  1.1232e-01, -1.7520e-01,
        -2.9343e-02,  1.9986e-01,  3.7351e-01,  1.8321e-03,  2.8144e-01,
         1.6961e-01,  1.1166e-01, -4.7342e-01,  2.5215e-01,  1.2465e-01,
        -1.7574e-01, -2.3487e-01, -3.2847e-02, -3.3511e-01, -1.6397e-01,
         9.2866e-02,  6.8842e-01, -1.2720e-01,  3.8358e-03, -1.8727e-01,
         1.1597e-01,  1.0454e-01, -2.6154e-01,  2.1201e-01, -4.5223e-01,
         2.0397e-01, -6.3676e-01, -1.0293e-01, -2.7385e-01, -3.9719e-01,
         1.6923e-01,  8.8046e-02,  1.1130e-01, -3.8459e-01, -3.7879e-01,
         5.1172e-01,  4.1529e-01, -3.8174e-01, -1.2938e-01,  3.2678e-01,
         4.4141e-01,  5.7247e-01,  5.7335e-01,  2.2937e-01,  1.7478e-01,
         3.0146e-01,  2.0555e-01, -8.7688e-01,  2.6807e-01,  3.9275e-01,
         3.8590e-02, -3.1944e-01, -5.3004e-02,  1.4634e-02,  1.4402e-01,
        -2.0849e-01,  1.3237e-01,  1.5445e-01, -2.2459e-02,  2.4120e-01,
         1.2028e-01, -1.7279e-01,  4.2801e-01, -7.6152e-01, -2.1103e-01,
         6.2899e-01, -1.6014e-01,  5.1742e-02,  4.7674e-01,  5.3797e-02,
        -1.6155e-01,  1.0281e-01, -5.7464e-01,  2.1592e-01, -1.2658e-01,
         4.8350e-02,  3.5443e-02,  1.1428e-01, -4.5882e-01, -9.1370e-02,
        -8.0386e-02, -5.6888e-02,  7.8916e-02,  1.6889e-02,  9.4458e-02,
        -1.0846e-02,  1.4602e-01,  2.9974e-01, -1.2817e-01,  1.4236e-01,
        -5.1285e-01, -4.5173e-01,  3.7114e-01, -6.4035e-02,  3.9342e-01,
         3.0148e-01, -8.0483e-02, -7.5345e-02, -3.7438e-01, -1.1560e-01,
        -7.6414e-01,  1.1941e-01,  3.2946e-01,  1.6418e-01,  2.5149e-01,
         2.8158e-01, -3.1064e-01, -2.1117e-01, -3.6134e-01, -1.7946e-01,
        -3.8067e-01, -1.8442e-02,  5.4178e-01,  1.0826e-01, -4.2489e-01,
         9.8786e-02, -1.9886e-01, -1.9944e-01, -2.6189e-01,  3.2915e-01,
         2.7132e-01, -2.7107e-01,  1.9721e-01, -3.4363e-02, -3.4736e-01,
         7.6883e-01,  7.6609e-01,  1.3300e-01,  1.0317e-01, -9.9651e-02,
        -1.5886e-01,  3.3379e-01,  1.1817e-01,  6.1088e-01, -9.8981e-02,
         3.2033e-02, -3.2494e-01,  6.3448e-01, -1.8965e-02, -1.0558e-01,
         1.8887e-01,  2.4920e-02, -4.7867e-01,  1.6645e-03,  1.6404e-01,
        -2.1174e-01,  5.4358e-01, -1.9561e-01, -6.2061e-01, -5.3127e-01,
         1.8306e-01,  5.1041e-01,  2.6210e-01,  4.7968e-01,  4.0350e-01,
         1.7007e-01, -6.5120e-02,  3.2445e-02, -2.4497e-01,  3.8961e-02,
         3.3875e-01, -2.3760e-01,  4.1712e-01,  1.6046e-01, -2.4134e-01,
         1.4197e-01, -1.9834e-01,  4.0619e-01,  2.6777e-01,  2.4601e-01,
         9.6592e-02,  2.2297e-02,  4.6209e-01,  3.8926e-01,  1.6503e-01,
         1.6308e-01, -2.7902e-01, -1.7507e-01, -1.0870e-01,  4.1737e-02,
         1.2515e-01, -1.6289e-01,  2.8835e-01, -5.0282e-01,  2.9335e-01,
         5.7595e-01, -2.0366e-01,  4.6764e-02, -2.6312e-01,  4.7355e-01,
        -3.3565e-01,  2.4745e-01, -8.0281e-02,  3.2135e-02, -6.0093e-01,
         4.9367e-01, -3.1144e-01,  2.6010e-01,  6.3402e-02, -1.1066e-02,
        -2.8310e-01, -5.9138e-01,  1.9894e-02, -5.6878e-01,  4.3710e-01,
        -1.8511e-01,  1.4252e-01, -4.7774e-01, -1.0077e-01, -2.5265e-01,
         1.0201e-01, -2.4135e-01, -3.3036e-01,  4.7532e-02,  1.9244e-01,
        -1.9187e-01,  3.5796e-02,  2.8442e-01, -2.9295e-01,  2.3329e-02,
         2.8451e-01, -1.1799e-01,  2.6453e-01,  1.4019e-01, -7.1528e-02,
         1.0160e+00,  2.1072e-01,  1.9396e-01, -1.2166e-01, -6.4238e-02,
        -1.6593e-01,  2.4005e-01, -2.9599e-01, -1.6909e-01,  9.1479e-03,
        -5.0724e-02, -3.1212e-01,  4.8560e-01,  3.9701e-01,  1.2635e-01,
        -5.3069e-01, -8.0266e-02,  3.7003e-01, -3.5217e-01,  8.7458e-02,
         5.4936e-01, -4.9864e-01,  1.0496e-01,  1.4389e-01, -7.2095e-01,
         1.7354e-01, -1.0492e-01], device='cuda:1', requires_grad=True)
net_guide.net.3.0.bias.scale torch.Size([512]) tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010],
       device='cuda:1', grad_fn=<AddBackward0>)
net_guide.net.4.weight.loc torch.Size([1, 512]) Parameter containing:
tensor([[ 0.7570,  0.0071,  0.1389,  0.6667,  0.1712,  0.3561,  0.6226, -0.3891,
          0.5041, -0.1839, -0.3202, -0.1969,  0.1615,  0.0672,  0.6710, -0.3528,
         -0.3141, -0.2882, -0.8871,  0.1790, -0.3063,  0.4413, -1.0605, -0.2951,
         -0.3255, -0.0646,  0.2149, -0.5881, -0.2235, -0.0753,  0.5737, -0.5544,
         -0.0257, -0.1990, -0.4254, -0.1341,  0.0489, -0.3904, -0.2764, -0.3566,
          0.1979,  0.6079, -0.1551, -0.4622,  0.5872, -0.5354, -0.3222, -0.0805,
         -0.3098, -0.0448,  0.7059,  0.6188,  0.2833,  0.2381, -0.2853, -0.1509,
         -0.4050, -0.2043, -0.2229, -0.4423,  0.1936, -0.2756, -0.6272, -0.0563,
          0.0129,  0.0949,  0.0776,  0.0665,  0.0221, -0.1633, -0.2864,  0.3297,
          0.3653,  0.2385, -0.1601,  0.0213,  0.0414,  0.4344, -0.1426,  0.3209,
         -0.1330, -0.0715,  0.1667, -0.1738, -0.5722, -0.5953, -0.0185, -0.6191,
          0.4194,  0.3419,  0.0859,  0.2053,  0.2619, -0.2133, -0.4736,  0.0040,
         -0.3127, -0.3731, -0.2702,  0.1135,  0.2918,  0.2723, -0.2393, -0.0356,
          0.3593, -0.0179, -0.0283,  0.2146,  0.2183,  0.4363, -0.0966,  0.5011,
          0.4738, -0.2301,  0.3377,  0.5182,  0.2462, -0.2835, -0.2046, -0.0658,
          0.4032,  0.2224, -0.2755,  0.8335,  0.2519, -0.2333,  0.0282,  0.0173,
         -0.2267,  0.3252, -0.0499,  0.0456, -0.2739,  0.3119, -0.1075, -0.3342,
          0.2032, -0.3366, -0.2031,  0.1704, -0.1464, -0.3186,  0.1348, -0.2662,
         -0.4975,  0.1851,  0.2307,  0.0125, -0.1342,  0.5029, -0.3441, -0.0833,
         -0.5997,  0.1109,  0.1963,  0.0987, -0.6184,  0.0578,  0.1665,  0.3195,
          0.2226,  0.3615, -0.7867, -0.3353, -0.0744,  0.2562, -0.1247,  0.2649,
         -0.3539, -0.0216,  0.0795,  0.0297, -0.0140,  0.0654,  0.0853, -0.0177,
          0.1761, -0.1112,  0.1291, -0.4507, -0.3451, -0.2394,  0.4435,  0.4105,
         -0.4136, -0.0931, -0.5896,  0.0572, -0.3367, -0.3010,  0.0908, -0.1063,
         -0.5687,  0.1835, -0.1890, -0.0747,  0.2271,  0.1515, -0.0937,  0.0105,
         -0.5979,  0.5121,  0.2226,  0.2394, -0.1796, -0.5596, -0.1476, -0.3604,
          0.0613, -0.6463, -0.2884,  0.0498,  0.0476, -0.1238,  0.0033, -0.1810,
          0.2991, -0.7201, -0.0066,  0.6760,  0.0838, -0.2200,  0.5599, -0.4012,
          0.0079,  0.4337,  0.0768,  0.5233,  0.0051, -0.1023, -0.2747,  0.1599,
         -0.0071,  0.3136,  0.1999, -0.0581,  0.1474, -0.4202,  0.3128, -0.0721,
          0.1800, -0.6434,  0.2795,  0.0963,  0.1675, -0.2505,  0.5946,  0.0881,
         -0.3420, -0.4583,  0.2318, -0.1727,  0.3149, -0.2287, -0.0798, -0.1796,
          0.2559,  0.4442, -0.1899, -0.2371, -0.5489, -0.4815,  0.0435, -0.3169,
          0.4664,  0.0213,  0.0719, -0.0919,  0.0049,  0.0717, -0.2498, -0.1512,
          0.0769, -0.3439,  0.0776, -0.3771,  0.3978, -0.3865,  0.0013,  0.3145,
         -0.2653,  0.3279, -0.5856, -0.6437, -0.3371,  0.2609, -0.0104, -0.0156,
          0.1098,  0.2341,  0.1565,  0.2076,  0.0886, -0.3759, -0.1986,  0.2679,
          0.2184,  0.0187, -0.2609, -0.0485,  0.2321,  0.2120, -0.3796, -0.1598,
         -0.2731, -0.2402, -0.7589, -0.0833,  0.2278,  0.1961,  0.3413, -0.0987,
          0.4173, -0.0623, -0.5167, -0.5240, -0.3195, -0.2283,  0.4674, -0.0255,
         -0.5547,  0.4798, -0.4382, -0.0420, -0.1176,  0.0931, -0.0501,  0.4722,
          0.6665, -0.0861,  0.6480, -0.0445, -0.3785, -0.0294,  0.3172, -0.1142,
          0.0714, -0.1573,  0.0901, -0.3999,  0.2734,  0.3352,  0.1221,  0.1154,
         -0.2944,  0.4117, -0.2558, -0.0271, -0.0529, -0.1143, -0.3698,  0.3019,
         -0.3937, -0.0406,  0.4142, -0.0227,  0.1544,  0.1405,  0.6259, -0.3281,
         -0.1419,  0.6239,  0.0778, -0.2243, -0.2499,  0.0725, -0.4267, -0.4464,
          0.5441, -0.0022, -0.2501,  0.1621, -0.2522,  0.2555, -0.1617, -0.1284,
         -0.0315,  0.1421, -0.1258, -0.0346,  0.0374,  0.2211, -0.6120,  0.1248,
         -0.3892, -0.1977,  0.4000,  0.2652,  0.1389, -0.1081,  0.6099,  0.2467,
         -0.0990,  0.2355,  0.4636, -0.2268,  0.4451, -0.2121, -0.5002, -0.0408,
          0.2536,  0.3768, -0.6709,  0.2756, -0.2226, -0.4895, -0.5475,  0.0174,
          0.4232,  0.3590,  0.6767,  0.3510, -0.0845, -0.0845, -0.4329, -0.2155,
         -0.0831,  0.1408,  0.3465,  0.3161,  0.3256,  0.1817, -0.4837,  0.2695,
         -0.1407, -0.2695,  0.2053,  0.8556, -0.1175, -0.1025,  0.1077,  0.5011,
         -0.3269,  0.2269, -0.1758, -0.2570,  0.0990, -0.4238, -0.2143, -0.4339,
          0.5493,  0.0367, -0.0246,  0.2124,  0.3997, -0.2968, -0.6228,  0.4566,
          0.2689, -0.6811,  0.2121,  0.0886,  0.2624,  0.4336,  0.1599,  0.4324,
          0.5957, -0.5103,  0.8678, -0.3761, -0.3902, -0.2045, -0.1148,  0.1110,
         -0.3288, -0.1500,  0.7500, -0.5143,  0.4097, -0.2637,  0.2661, -0.3321,
          0.1945,  0.0906, -0.0694,  0.2230, -0.0518,  0.0263,  0.7312,  0.0204,
         -0.3837, -0.0236, -0.0973,  0.4279, -0.1067, -0.4604,  0.3151,  0.2388,
          0.0919,  0.3406, -0.2363, -0.3606,  0.5200,  0.1322, -0.2743,  0.1592,
         -0.4984,  0.0436, -0.2330, -0.0258,  0.0537, -0.4252,  0.3755, -0.1834,
         -0.2058, -0.5455,  0.1601, -0.1842, -0.2745, -0.3696, -0.3067,  0.3493]],
       device='cuda:1', requires_grad=True)
net_guide.net.4.weight.scale torch.Size([1, 512]) tensor([[0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010]],
       device='cuda:1', grad_fn=<AddBackward0>)
net_guide.net.4.bias.loc torch.Size([1]) Parameter containing:
tensor([-0.1671], device='cuda:1', requires_grad=True)
net_guide.net.4.bias.scale torch.Size([1]) tensor([0.0010], device='cuda:1', grad_fn=<AddBackward0>)
Using device: cuda:1
===== Training profile tensin-3x512-s03 - 1 =====
[0:00:03.346741] epoch: 0 | elbo: 626675618.5599997 | train_rmse: 54.5909 | val_rmse: 54.2327 | val_ll: -1514.5634
[0:02:52.684702] epoch: 50 | elbo: 22106835.279999997 | train_rmse: 12.9843 | val_rmse: 15.9317 | val_ll: -180.4273
[0:05:41.473935] epoch: 100 | elbo: 12071980.124999998 | train_rmse: 8.7815 | val_rmse: 13.3234 | val_ll: -140.0169
[0:08:31.638296] epoch: 150 | elbo: 8256491.45 | train_rmse: 6.5605 | val_rmse: 12.1048 | val_ll: -121.4597
[0:11:22.635057] epoch: 200 | elbo: 6177267.032500001 | train_rmse: 4.9855 | val_rmse: 11.4187 | val_ll: -113.4075
[0:14:10.249008] epoch: 250 | elbo: 5040528.467499999 | train_rmse: 3.8472 | val_rmse: 10.9335 | val_ll: -104.1629
[0:16:57.617978] epoch: 300 | elbo: 4299824.72 | train_rmse: 2.9609 | val_rmse: 10.599 | val_ll: -99.8022
[0:19:45.864440] epoch: 350 | elbo: 3834680.2787499996 | train_rmse: 2.2299 | val_rmse: 10.365 | val_ll: -94.4985
[0:22:34.571298] epoch: 400 | elbo: 3530059.472499999 | train_rmse: 1.6433 | val_rmse: 10.1901 | val_ll: -88.029
[0:25:25.134106] epoch: 450 | elbo: 3339797.85625 | train_rmse: 1.1918 | val_rmse: 10.0841 | val_ll: -82.2733
[0:28:18.282335] epoch: 500 | elbo: 3211326.19625 | train_rmse: 0.8726 | val_rmse: 10.0069 | val_ll: -75.6378
[0:31:08.457872] epoch: 550 | elbo: 3128844.1462499998 | train_rmse: 0.5902 | val_rmse: 9.9342 | val_ll: -69.6337
[0:33:57.312476] epoch: 600 | elbo: 3073192.23875 | train_rmse: 0.4212 | val_rmse: 9.8777 | val_ll: -62.1013
[0:36:49.391912] epoch: 650 | elbo: 3036244.32375 | train_rmse: 0.3795 | val_rmse: 9.8107 | val_ll: -56.1767
[0:39:39.842207] epoch: 700 | elbo: 2991708.7487500003 | train_rmse: 0.3439 | val_rmse: 9.741 | val_ll: -51.5576
[0:42:32.403716] epoch: 750 | elbo: 2961661.9625 | train_rmse: 0.283 | val_rmse: 9.657 | val_ll: -46.42
[0:45:23.515970] epoch: 800 | elbo: 2930724.55375 | train_rmse: 0.2626 | val_rmse: 9.5711 | val_ll: -42.0554
[0:48:14.113650] epoch: 850 | elbo: 2903036.29625 | train_rmse: 0.3531 | val_rmse: 9.4874 | val_ll: -39.5137
[0:51:02.273303] epoch: 900 | elbo: 2877609.2337499997 | train_rmse: 0.3049 | val_rmse: 9.3757 | val_ll: -36.151
[0:53:48.612618] epoch: 950 | elbo: 2851690.17625 | train_rmse: 0.2806 | val_rmse: 9.2708 | val_ll: -33.6806
[0:56:37.828546] epoch: 1000 | elbo: 2831934.1287499997 | train_rmse: 0.3436 | val_rmse: 9.1606 | val_ll: -31.1032
[0:59:26.800663] epoch: 1050 | elbo: 2808682.33125 | train_rmse: 0.2992 | val_rmse: 9.0417 | val_ll: -29.3606
[1:02:20.091784] epoch: 1100 | elbo: 2788324.4112499994 | train_rmse: 0.2945 | val_rmse: 8.9198 | val_ll: -28.0735
[1:05:13.380608] epoch: 1150 | elbo: 2767848.41875 | train_rmse: 0.3155 | val_rmse: 8.7907 | val_ll: -26.4626
[1:08:02.178520] epoch: 1200 | elbo: 2750123.16625 | train_rmse: 0.3743 | val_rmse: 8.6772 | val_ll: -25.2062
[1:10:54.412777] epoch: 1250 | elbo: 2730749.12 | train_rmse: 0.3232 | val_rmse: 8.5424 | val_ll: -23.8288
[1:13:45.067369] epoch: 1300 | elbo: 2712248.5337500004 | train_rmse: 0.3242 | val_rmse: 8.4196 | val_ll: -23.0324
[1:16:31.986792] epoch: 1350 | elbo: 2696666.63 | train_rmse: 0.4199 | val_rmse: 8.2956 | val_ll: -21.7962
[1:19:16.714887] epoch: 1400 | elbo: 2678711.4425 | train_rmse: 0.3889 | val_rmse: 8.1538 | val_ll: -20.9986
[1:22:09.259453] epoch: 1450 | elbo: 2660631.2337499997 | train_rmse: 0.3435 | val_rmse: 8.0243 | val_ll: -20.195
[1:24:59.331914] epoch: 1500 | elbo: 2642063.1475 | train_rmse: 0.3261 | val_rmse: 7.8813 | val_ll: -19.5772
[1:27:52.325406] epoch: 1550 | elbo: 2625117.0912499996 | train_rmse: 0.3754 | val_rmse: 7.7461 | val_ll: -18.826
[1:30:42.357131] epoch: 1600 | elbo: 2606809.10125 | train_rmse: 0.3271 | val_rmse: 7.6098 | val_ll: -18.0416
[1:33:26.732698] epoch: 1650 | elbo: 2587623.6112499996 | train_rmse: 0.3268 | val_rmse: 7.4639 | val_ll: -17.5592
[1:36:10.852450] epoch: 1700 | elbo: 2569362.4099999997 | train_rmse: 0.3085 | val_rmse: 7.3337 | val_ll: -16.7834
[1:38:56.793441] epoch: 1750 | elbo: 2552919.645 | train_rmse: 0.3418 | val_rmse: 7.1812 | val_ll: -16.2514
[1:41:42.583076] epoch: 1800 | elbo: 2533830.4625 | train_rmse: 0.3263 | val_rmse: 7.0515 | val_ll: -15.5167
[1:44:27.327722] epoch: 1850 | elbo: 2513579.24375 | train_rmse: 0.3303 | val_rmse: 6.9045 | val_ll: -15.3186
[1:47:12.584592] epoch: 1900 | elbo: 2494356.8062499994 | train_rmse: 0.3426 | val_rmse: 6.7661 | val_ll: -14.6003
[1:49:57.307804] epoch: 1950 | elbo: 2476301.66375 | train_rmse: 0.3415 | val_rmse: 6.6267 | val_ll: -14.3174
[1:52:42.290172] epoch: 2000 | elbo: 2452237.8587499997 | train_rmse: 0.3354 | val_rmse: 6.4865 | val_ll: -13.7271
[1:55:27.746836] epoch: 2050 | elbo: 2431482.45375 | train_rmse: 0.3297 | val_rmse: 6.3498 | val_ll: -13.4214
[1:58:17.878668] epoch: 2100 | elbo: 2409854.8012500005 | train_rmse: 0.3705 | val_rmse: 6.2103 | val_ll: -12.8726
[2:01:09.540772] epoch: 2150 | elbo: 2385048.46125 | train_rmse: 0.3052 | val_rmse: 6.0732 | val_ll: -12.5263
[2:03:54.794239] epoch: 2200 | elbo: 2364693.785 | train_rmse: 0.3445 | val_rmse: 5.9419 | val_ll: -11.9939
[2:06:40.816779] epoch: 2250 | elbo: 2341534.7599999993 | train_rmse: 0.3144 | val_rmse: 5.8064 | val_ll: -11.8833
[2:09:28.371736] epoch: 2300 | elbo: 2316171.3500000006 | train_rmse: 0.3076 | val_rmse: 5.6821 | val_ll: -11.3954
[2:12:13.621427] epoch: 2350 | elbo: 2294950.035 | train_rmse: 0.3193 | val_rmse: 5.5465 | val_ll: -11.0727
[2:14:59.101205] epoch: 2400 | elbo: 2268198.81 | train_rmse: 0.3605 | val_rmse: 5.4253 | val_ll: -10.5862
[2:17:44.966564] epoch: 2450 | elbo: 2244921.605 | train_rmse: 0.3158 | val_rmse: 5.2963 | val_ll: -10.408
[2:20:39.393556] epoch: 2500 | elbo: 2218510.0675 | train_rmse: 0.3153 | val_rmse: 5.175 | val_ll: -10.1439
[2:23:24.586857] epoch: 2550 | elbo: 2191521.60125 | train_rmse: 0.3084 | val_rmse: 5.0581 | val_ll: -9.8108
[2:26:09.715604] epoch: 2600 | elbo: 2167628.62 | train_rmse: 0.3252 | val_rmse: 4.9497 | val_ll: -9.5627
[2:28:56.925698] epoch: 2650 | elbo: 2141128.9 | train_rmse: 0.3146 | val_rmse: 4.8285 | val_ll: -9.0107
[2:31:45.461100] epoch: 2700 | elbo: 2112808.8274999997 | train_rmse: 0.3102 | val_rmse: 4.7181 | val_ll: -8.9491
[2:34:37.902766] epoch: 2750 | elbo: 2085627.591875 | train_rmse: 0.3294 | val_rmse: 4.6017 | val_ll: -8.6421
[2:37:26.399653] epoch: 2800 | elbo: 2056419.5 | train_rmse: 0.3235 | val_rmse: 4.4954 | val_ll: -8.3969
[2:40:16.229469] epoch: 2850 | elbo: 2028480.845625 | train_rmse: 0.3519 | val_rmse: 4.399 | val_ll: -8.1726
[2:43:05.570764] epoch: 2900 | elbo: 2001139.028125 | train_rmse: 0.3419 | val_rmse: 4.2845 | val_ll: -7.9179
[2:45:53.861839] epoch: 2950 | elbo: 1971108.2731249998 | train_rmse: 0.3572 | val_rmse: 4.1795 | val_ll: -7.6565
[2:48:44.383625] epoch: 3000 | elbo: 1940816.8656250003 | train_rmse: 0.3387 | val_rmse: 4.0753 | val_ll: -7.3702
[2:51:33.213938] epoch: 3050 | elbo: 1910319.140625 | train_rmse: 0.3342 | val_rmse: 3.978 | val_ll: -7.2903
[2:54:22.876765] epoch: 3100 | elbo: 1880885.590625 | train_rmse: 0.3183 | val_rmse: 3.8786 | val_ll: -7.021
[2:57:11.543311] epoch: 3150 | elbo: 1849952.0831249994 | train_rmse: 0.3447 | val_rmse: 3.7833 | val_ll: -6.8141
[3:00:03.617152] epoch: 3200 | elbo: 1820101.1575000002 | train_rmse: 0.3278 | val_rmse: 3.6909 | val_ll: -6.5962
[3:02:55.046683] epoch: 3250 | elbo: 1789413.2806250001 | train_rmse: 0.3527 | val_rmse: 3.6006 | val_ll: -6.4173
[3:05:46.839714] epoch: 3300 | elbo: 1758072.0931250001 | train_rmse: 0.3513 | val_rmse: 3.5115 | val_ll: -6.125
[3:08:36.840836] epoch: 3350 | elbo: 1729058.1337499998 | train_rmse: 0.3474 | val_rmse: 3.427 | val_ll: -5.9543
[3:11:28.748359] epoch: 3400 | elbo: 1699701.88875 | train_rmse: 0.3692 | val_rmse: 3.3452 | val_ll: -5.6839
[3:14:17.181416] epoch: 3450 | elbo: 1669875.7493750001 | train_rmse: 0.3491 | val_rmse: 3.2704 | val_ll: -5.5508
[3:17:06.757971] epoch: 3500 | elbo: 1639640.5343750003 | train_rmse: 0.3481 | val_rmse: 3.1967 | val_ll: -5.4093
[3:19:54.529929] epoch: 3550 | elbo: 1611232.8168750003 | train_rmse: 0.364 | val_rmse: 3.126 | val_ll: -5.204
[3:22:43.963571] epoch: 3600 | elbo: 1582805.9837500001 | train_rmse: 0.3594 | val_rmse: 3.0492 | val_ll: -5.0783
[3:25:33.016520] epoch: 3650 | elbo: 1554213.8987499997 | train_rmse: 0.3751 | val_rmse: 2.9808 | val_ll: -4.9743
[3:28:22.837571] epoch: 3700 | elbo: 1526752.8606250002 | train_rmse: 0.3738 | val_rmse: 2.9106 | val_ll: -4.8008
[3:31:13.300298] epoch: 3750 | elbo: 1498546.0818750004 | train_rmse: 0.3704 | val_rmse: 2.8414 | val_ll: -4.6973
[3:33:59.608054] epoch: 3800 | elbo: 1469983.9056250001 | train_rmse: 0.3856 | val_rmse: 2.7803 | val_ll: -4.5277
[3:36:42.887708] epoch: 3850 | elbo: 1443248.4968750002 | train_rmse: 0.3829 | val_rmse: 2.7055 | val_ll: -4.3767
[3:39:26.964077] epoch: 3900 | elbo: 1416126.8418750002 | train_rmse: 0.3774 | val_rmse: 2.637 | val_ll: -4.2278
[3:42:11.209489] epoch: 3950 | elbo: 1387720.2650000001 | train_rmse: 0.3817 | val_rmse: 2.5726 | val_ll: -4.144
[3:44:54.647885] epoch: 4000 | elbo: 1361397.8493750002 | train_rmse: 0.3852 | val_rmse: 2.5073 | val_ll: -4.0032
[3:47:39.318155] epoch: 4050 | elbo: 1333976.0624999995 | train_rmse: 0.3889 | val_rmse: 2.4354 | val_ll: -3.8741
[3:50:24.602043] epoch: 4100 | elbo: 1306997.9781250001 | train_rmse: 0.397 | val_rmse: 2.3679 | val_ll: -3.7328
[3:53:13.957078] epoch: 4150 | elbo: 1278941.2924999997 | train_rmse: 0.3965 | val_rmse: 2.3018 | val_ll: -3.6349
[3:56:05.313051] epoch: 4200 | elbo: 1252855.58125 | train_rmse: 0.4036 | val_rmse: 2.2335 | val_ll: -3.502
[3:58:56.509861] epoch: 4250 | elbo: 1225380.6387500002 | train_rmse: 0.3982 | val_rmse: 2.1611 | val_ll: -3.3193
[4:01:47.512088] epoch: 4300 | elbo: 1198779.90375 | train_rmse: 0.4047 | val_rmse: 2.0891 | val_ll: -3.1725
[4:04:39.086255] epoch: 4350 | elbo: 1171544.1637499998 | train_rmse: 0.4039 | val_rmse: 2.0128 | val_ll: -3.0564
[4:07:29.154744] epoch: 4400 | elbo: 1145415.7443749998 | train_rmse: 0.4116 | val_rmse: 1.9476 | val_ll: -2.889
[4:10:19.471583] epoch: 4450 | elbo: 1118338.2293749999 | train_rmse: 0.4086 | val_rmse: 1.8685 | val_ll: -2.7792
[4:13:11.556983] epoch: 4500 | elbo: 1091655.69125 | train_rmse: 0.4063 | val_rmse: 1.8023 | val_ll: -2.6896
[4:16:03.696060] epoch: 4550 | elbo: 1063606.5837499998 | train_rmse: 0.4157 | val_rmse: 1.7311 | val_ll: -2.5936
[4:18:55.962768] epoch: 4600 | elbo: 1037858.4390625 | train_rmse: 0.4216 | val_rmse: 1.6666 | val_ll: -2.4755
[4:21:47.485038] epoch: 4650 | elbo: 1008948.6474999997 | train_rmse: 0.4243 | val_rmse: 1.5977 | val_ll: -2.4003
[4:24:38.478260] epoch: 4700 | elbo: 982316.5331249998 | train_rmse: 0.4237 | val_rmse: 1.5338 | val_ll: -2.3088
[4:27:29.039007] epoch: 4750 | elbo: 955201.4168749999 | train_rmse: 0.4299 | val_rmse: 1.4712 | val_ll: -2.2085
[4:30:21.372840] epoch: 4800 | elbo: 927775.3200000001 | train_rmse: 0.4306 | val_rmse: 1.408 | val_ll: -2.1243
[4:33:13.089916] epoch: 4850 | elbo: 900501.713125 | train_rmse: 0.4332 | val_rmse: 1.3531 | val_ll: -2.0365
[4:36:02.845304] epoch: 4900 | elbo: 873170.3134375 | train_rmse: 0.4339 | val_rmse: 1.2965 | val_ll: -1.9577
[4:38:52.865386] epoch: 4950 | elbo: 845879.2306249999 | train_rmse: 0.438 | val_rmse: 1.2428 | val_ll: -1.895
[4:41:42.626123] epoch: 5000 | elbo: 818635.7862499999 | train_rmse: 0.4356 | val_rmse: 1.1949 | val_ll: -1.8096
[4:44:33.678806] epoch: 5050 | elbo: 791536.7318750002 | train_rmse: 0.4354 | val_rmse: 1.1467 | val_ll: -1.7489
[4:47:25.496215] epoch: 5100 | elbo: 765142.5543750001 | train_rmse: 0.4398 | val_rmse: 1.0967 | val_ll: -1.681
[4:50:17.609447] epoch: 5150 | elbo: 738133.8212499999 | train_rmse: 0.4403 | val_rmse: 1.052 | val_ll: -1.6126
[4:53:09.102312] epoch: 5200 | elbo: 711459.2606249999 | train_rmse: 0.4422 | val_rmse: 1.0109 | val_ll: -1.5743
[4:56:01.152905] epoch: 5250 | elbo: 684611.3609375 | train_rmse: 0.4398 | val_rmse: 0.9704 | val_ll: -1.5054
[4:58:52.689346] epoch: 5300 | elbo: 657986.3403124999 | train_rmse: 0.4418 | val_rmse: 0.9322 | val_ll: -1.4683
[5:01:42.879061] epoch: 5350 | elbo: 632204.9453125 | train_rmse: 0.4441 | val_rmse: 0.8978 | val_ll: -1.4232
[5:04:33.551790] epoch: 5400 | elbo: 606405.6609375 | train_rmse: 0.4413 | val_rmse: 0.8627 | val_ll: -1.3979
[5:07:25.355430] epoch: 5450 | elbo: 580815.4615624999 | train_rmse: 0.4442 | val_rmse: 0.8299 | val_ll: -1.3654
[5:10:15.589834] epoch: 5500 | elbo: 556195.3553124999 | train_rmse: 0.4462 | val_rmse: 0.8001 | val_ll: -1.311
[5:13:08.109081] epoch: 5550 | elbo: 531482.46640625 | train_rmse: 0.4433 | val_rmse: 0.773 | val_ll: -1.2647
[5:15:58.968551] epoch: 5600 | elbo: 507041.28421874996 | train_rmse: 0.4429 | val_rmse: 0.7461 | val_ll: -1.234
[5:18:48.968213] epoch: 5650 | elbo: 483421.7290625001 | train_rmse: 0.4431 | val_rmse: 0.7219 | val_ll: -1.2005
[5:21:37.979970] epoch: 5700 | elbo: 460293.335625 | train_rmse: 0.4412 | val_rmse: 0.7004 | val_ll: -1.1642
[5:24:28.472134] epoch: 5750 | elbo: 437816.19953125 | train_rmse: 0.4445 | val_rmse: 0.6842 | val_ll: -1.136
[5:27:17.595174] epoch: 5800 | elbo: 415470.77156250004 | train_rmse: 0.4366 | val_rmse: 0.6682 | val_ll: -1.1109
[5:30:09.391133] epoch: 5850 | elbo: 393841.9 | train_rmse: 0.4335 | val_rmse: 0.6463 | val_ll: -1.0643
[5:33:02.533218] epoch: 5900 | elbo: 373592.68187499995 | train_rmse: 0.4284 | val_rmse: 0.6304 | val_ll: -1.0449
[5:35:54.392170] epoch: 5950 | elbo: 353871.9828125 | train_rmse: 0.4325 | val_rmse: 0.618 | val_ll: -1.0339
[5:38:45.937953] epoch: 6000 | elbo: 334788.53953124996 | train_rmse: 0.4243 | val_rmse: 0.6027 | val_ll: -1.0104
[5:41:36.956638] epoch: 6050 | elbo: 316161.82125 | train_rmse: 0.4205 | val_rmse: 0.5937 | val_ll: -0.9937
[5:44:29.824913] epoch: 6100 | elbo: 298913.48765625 | train_rmse: 0.4175 | val_rmse: 0.5839 | val_ll: -0.9771
[5:47:22.341076] epoch: 6150 | elbo: 282216.86 | train_rmse: 0.4127 | val_rmse: 0.5756 | val_ll: -0.9585
[5:50:10.207067] epoch: 6200 | elbo: 266620.32687499997 | train_rmse: 0.4101 | val_rmse: 0.5664 | val_ll: -0.9527
[5:52:54.047408] epoch: 6250 | elbo: 251791.171328125 | train_rmse: 0.4052 | val_rmse: 0.5592 | val_ll: -0.9383
[5:55:37.593742] epoch: 6300 | elbo: 237506.301015625 | train_rmse: 0.401 | val_rmse: 0.5489 | val_ll: -0.9245
[5:58:22.417977] epoch: 6350 | elbo: 224585.3884375 | train_rmse: 0.3996 | val_rmse: 0.5421 | val_ll: -0.9128
[6:01:05.937813] epoch: 6400 | elbo: 212157.670078125 | train_rmse: 0.3947 | val_rmse: 0.5311 | val_ll: -0.8775
[6:03:49.395994] epoch: 6450 | elbo: 200678.04398437502 | train_rmse: 0.3904 | val_rmse: 0.5234 | val_ll: -0.8617
[6:06:32.966436] epoch: 6500 | elbo: 190017.79140625003 | train_rmse: 0.3872 | val_rmse: 0.5152 | val_ll: -0.843
[6:09:16.569699] epoch: 6550 | elbo: 180654.19789062496 | train_rmse: 0.384 | val_rmse: 0.5108 | val_ll: -0.8292
[6:12:00.451406] epoch: 6600 | elbo: 171093.685 | train_rmse: 0.3815 | val_rmse: 0.5065 | val_ll: -0.8335
[6:14:43.481266] epoch: 6650 | elbo: 163006.11109375 | train_rmse: 0.3787 | val_rmse: 0.5026 | val_ll: -0.827
[6:17:30.586869] epoch: 6700 | elbo: 155106.82351562503 | train_rmse: 0.3775 | val_rmse: 0.4966 | val_ll: -0.8155
[6:20:17.824889] epoch: 6750 | elbo: 147994.37859375 | train_rmse: 0.372 | val_rmse: 0.492 | val_ll: -0.8016
[6:23:05.305657] epoch: 6800 | elbo: 141641.438984375 | train_rmse: 0.3693 | val_rmse: 0.4868 | val_ll: -0.78
[6:25:56.735872] epoch: 6850 | elbo: 135779.146796875 | train_rmse: 0.3685 | val_rmse: 0.4863 | val_ll: -0.779
[6:28:48.961012] epoch: 6900 | elbo: 130480.98667968751 | train_rmse: 0.363 | val_rmse: 0.4798 | val_ll: -0.7725
[6:31:40.019515] epoch: 6950 | elbo: 125548.34074218749 | train_rmse: 0.3626 | val_rmse: 0.4761 | val_ll: -0.766
[6:34:31.329509] epoch: 7000 | elbo: 121441.535 | train_rmse: 0.3624 | val_rmse: 0.4751 | val_ll: -0.7614
[6:37:20.681727] epoch: 7050 | elbo: 116989.38343749999 | train_rmse: 0.359 | val_rmse: 0.47 | val_ll: -0.7516
[6:40:15.014702] epoch: 7100 | elbo: 113225.418125 | train_rmse: 0.3571 | val_rmse: 0.4678 | val_ll: -0.7406
[6:43:09.791288] epoch: 7150 | elbo: 109575.99515625 | train_rmse: 0.3548 | val_rmse: 0.4631 | val_ll: -0.734
[6:45:55.945517] epoch: 7200 | elbo: 106221.60054687501 | train_rmse: 0.3519 | val_rmse: 0.4584 | val_ll: -0.7142
[6:48:39.762895] epoch: 7250 | elbo: 103340.68632812501 | train_rmse: 0.3507 | val_rmse: 0.4565 | val_ll: -0.7048
[6:51:22.057566] epoch: 7300 | elbo: 100288.49015624999 | train_rmse: 0.348 | val_rmse: 0.4521 | val_ll: -0.7154
[6:54:05.524051] epoch: 7350 | elbo: 97792.2969140625 | train_rmse: 0.3484 | val_rmse: 0.4517 | val_ll: -0.6994
[6:56:50.643630] epoch: 7400 | elbo: 95305.31023437499 | train_rmse: 0.3474 | val_rmse: 0.4498 | val_ll: -0.6969
[6:59:35.831702] epoch: 7450 | elbo: 92974.762421875 | train_rmse: 0.346 | val_rmse: 0.4442 | val_ll: -0.6966
[7:02:21.201667] epoch: 7500 | elbo: 90805.83656250002 | train_rmse: 0.3449 | val_rmse: 0.4424 | val_ll: -0.6893
[7:05:07.112656] epoch: 7550 | elbo: 88819.017734375 | train_rmse: 0.344 | val_rmse: 0.4414 | val_ll: -0.6725
[7:07:51.410438] epoch: 7600 | elbo: 86721.0441796875 | train_rmse: 0.3436 | val_rmse: 0.4376 | val_ll: -0.6653
[7:10:37.727776] epoch: 7650 | elbo: 84988.02964843748 | train_rmse: 0.342 | val_rmse: 0.4344 | val_ll: -0.6686
[7:13:23.033805] epoch: 7700 | elbo: 83234.448515625 | train_rmse: 0.3414 | val_rmse: 0.4328 | val_ll: -0.6586
[7:16:09.678698] epoch: 7750 | elbo: 81602.75511718748 | train_rmse: 0.3414 | val_rmse: 0.4301 | val_ll: -0.6419
[7:18:56.004427] epoch: 7800 | elbo: 79935.7933984375 | train_rmse: 0.3395 | val_rmse: 0.4257 | val_ll: -0.6331
[7:21:42.401553] epoch: 7850 | elbo: 78397.4780078125 | train_rmse: 0.3397 | val_rmse: 0.4258 | val_ll: -0.6477
[7:24:28.119906] epoch: 7900 | elbo: 77068.0982421875 | train_rmse: 0.3375 | val_rmse: 0.4229 | val_ll: -0.6276
[7:27:13.939656] epoch: 7950 | elbo: 75834.9413671875 | train_rmse: 0.339 | val_rmse: 0.4214 | val_ll: -0.6116
[7:30:00.729461] epoch: 8000 | elbo: 74471.949765625 | train_rmse: 0.3371 | val_rmse: 0.4194 | val_ll: -0.6203
[7:32:54.360445] epoch: 8050 | elbo: 73111.26546875 | train_rmse: 0.3351 | val_rmse: 0.4161 | val_ll: -0.6085
[7:35:40.102964] epoch: 8100 | elbo: 72042.27441406249 | train_rmse: 0.3363 | val_rmse: 0.415 | val_ll: -0.6135
[7:38:25.260520] epoch: 8150 | elbo: 70869.0921875 | train_rmse: 0.3352 | val_rmse: 0.4146 | val_ll: -0.6045
[7:41:15.460642] epoch: 8200 | elbo: 69649.2549609375 | train_rmse: 0.3346 | val_rmse: 0.4121 | val_ll: -0.5946
[7:44:03.719281] epoch: 8250 | elbo: 68762.02734375001 | train_rmse: 0.3338 | val_rmse: 0.4104 | val_ll: -0.5897
[7:46:52.391735] epoch: 8300 | elbo: 67707.45765624999 | train_rmse: 0.3339 | val_rmse: 0.4106 | val_ll: -0.597
[7:49:40.686472] epoch: 8350 | elbo: 66935.4256640625 | train_rmse: 0.3348 | val_rmse: 0.4104 | val_ll: -0.5886
[7:52:33.543893] epoch: 8400 | elbo: 65947.76189453126 | train_rmse: 0.3327 | val_rmse: 0.4077 | val_ll: -0.5887
[7:55:25.890297] epoch: 8450 | elbo: 65272.408828125 | train_rmse: 0.3332 | val_rmse: 0.4065 | val_ll: -0.5857
[7:58:14.830597] epoch: 8500 | elbo: 64272.99021484375 | train_rmse: 0.3326 | val_rmse: 0.4057 | val_ll: -0.5757
[8:01:01.409347] epoch: 8550 | elbo: 63385.06669921875 | train_rmse: 0.3333 | val_rmse: 0.4056 | val_ll: -0.5974
[8:03:50.119644] epoch: 8600 | elbo: 62830.556679687485 | train_rmse: 0.3326 | val_rmse: 0.406 | val_ll: -0.5856
[8:06:39.545904] epoch: 8650 | elbo: 62034.94087890625 | train_rmse: 0.3332 | val_rmse: 0.4063 | val_ll: -0.5821
[8:09:27.762089] epoch: 8700 | elbo: 61299.8046875 | train_rmse: 0.3333 | val_rmse: 0.4033 | val_ll: -0.5855
[8:12:18.381501] epoch: 8750 | elbo: 60435.6899609375 | train_rmse: 0.3302 | val_rmse: 0.4012 | val_ll: -0.5713
[8:15:07.432544] epoch: 8800 | elbo: 59955.899335937494 | train_rmse: 0.3301 | val_rmse: 0.4015 | val_ll: -0.5744
[8:17:56.870811] epoch: 8850 | elbo: 59344.27619140624 | train_rmse: 0.3301 | val_rmse: 0.399 | val_ll: -0.5689
[8:20:46.545632] epoch: 8900 | elbo: 58934.29425781251 | train_rmse: 0.33 | val_rmse: 0.3989 | val_ll: -0.5635
[8:23:31.527345] epoch: 8950 | elbo: 58278.77988281249 | train_rmse: 0.3274 | val_rmse: 0.3969 | val_ll: -0.5718
[8:26:21.146817] epoch: 9000 | elbo: 57573.9400390625 | train_rmse: 0.3289 | val_rmse: 0.3957 | val_ll: -0.5647
[8:29:13.626748] epoch: 9050 | elbo: 56987.33185546874 | train_rmse: 0.3292 | val_rmse: 0.3959 | val_ll: -0.5602
[8:32:02.214204] epoch: 9100 | elbo: 56495.182851562495 | train_rmse: 0.3268 | val_rmse: 0.3949 | val_ll: -0.5658
[8:34:46.966621] epoch: 9150 | elbo: 56279.33843749999 | train_rmse: 0.3276 | val_rmse: 0.3948 | val_ll: -0.5669
[8:37:30.782435] epoch: 9200 | elbo: 55395.66658203125 | train_rmse: 0.3271 | val_rmse: 0.3937 | val_ll: -0.5695
[8:40:15.652987] epoch: 9250 | elbo: 55154.48517578126 | train_rmse: 0.3262 | val_rmse: 0.3935 | val_ll: -0.5658
[8:42:59.812152] epoch: 9300 | elbo: 54508.14052734375 | train_rmse: 0.325 | val_rmse: 0.3925 | val_ll: -0.5518
[8:45:44.606493] epoch: 9350 | elbo: 54217.93701171875 | train_rmse: 0.3251 | val_rmse: 0.3924 | val_ll: -0.5611
[8:48:29.429854] epoch: 9400 | elbo: 53698.44841796874 | train_rmse: 0.3262 | val_rmse: 0.392 | val_ll: -0.5704
[8:51:14.558044] epoch: 9450 | elbo: 53327.68349609374 | train_rmse: 0.3252 | val_rmse: 0.3919 | val_ll: -0.5554
[8:54:00.594804] epoch: 9500 | elbo: 52853.11400390626 | train_rmse: 0.3248 | val_rmse: 0.3908 | val_ll: -0.5563
[8:56:51.092834] epoch: 9550 | elbo: 52505.762226562496 | train_rmse: 0.3242 | val_rmse: 0.3899 | val_ll: -0.5572
[8:59:41.408893] epoch: 9600 | elbo: 52177.61533203124 | train_rmse: 0.3235 | val_rmse: 0.3903 | val_ll: -0.5516
[9:02:32.214915] epoch: 9650 | elbo: 51702.9753515625 | train_rmse: 0.3237 | val_rmse: 0.3913 | val_ll: -0.5526
[9:05:22.645197] epoch: 9700 | elbo: 51594.72359375001 | train_rmse: 0.3231 | val_rmse: 0.3889 | val_ll: -0.5472
[9:08:11.372985] epoch: 9750 | elbo: 51223.1955859375 | train_rmse: 0.3233 | val_rmse: 0.3899 | val_ll: -0.568
[9:10:55.530954] epoch: 9800 | elbo: 50729.7084765625 | train_rmse: 0.3219 | val_rmse: 0.3882 | val_ll: -0.5603
[9:13:38.500165] epoch: 9850 | elbo: 50448.638671874985 | train_rmse: 0.3232 | val_rmse: 0.3899 | val_ll: -0.5617
[9:16:21.973865] epoch: 9900 | elbo: 50124.0766796875 | train_rmse: 0.3228 | val_rmse: 0.3892 | val_ll: -0.5614
[9:19:04.464741] epoch: 9950 | elbo: 49736.48384765624 | train_rmse: 0.3223 | val_rmse: 0.3879 | val_ll: -0.5662
Training finished in 9:21:46.680564 seconds
Saved SVI model to tests/sigma-over-underfit-test/models/tensin-3x512-s03/checkpoint_1.pt
File Size is 4.0595598220825195 MB
data samples:  (1000, 1000)
Sequential(
  (0): Linear(in_features=10, out_features=512, bias=True)
  (1): ReLU()
  (2): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
  )
  (3): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
  )
  (4): Linear(in_features=512, out_features=1, bias=True)
)
Settings:
DEVICE: cuda:1 INFERENCE_TYPE: svi OBS_MODEL: homoskedastic PRIOR_LOC: 0.0 PRIOR_SCALE: 1.0 LIKELIHOOD_SCALE_LOC: 1.0 LIKELIHOOD_SCALE: 0.3 GUIDE_SCALE: 0.001 TRAIN_SIZE: 20000
Loaded SVI model from tests/sigma-over-underfit-test/models/tensin-3x512-s03/checkpoint_1.pt
using device: cuda:1
====== evaluating profile tensin-3x512-s03 - 1 ======
pred samples:  (1000, 1000)
Evaluating train...
tensor([7.0376], device='cuda:1')
tensor([[ 7.0228],
        [19.6836],
        [ 7.0256],
        ...,
        [12.7172],
        [-4.7706],
        [ 3.7075]], device='cuda:1')
tensor(-0.1837, device='cuda:1')
tensor([5.1967], device='cuda:1')
tensor([[  5.1966],
        [ 14.4655],
        [  8.6312],
        ...,
        [-12.4129],
        [-13.1987],
        [ 10.6690]], device='cuda:1')
tensor(-0.3829, device='cuda:1')
tensor([23.8366], device='cuda:1')
tensor([[ 23.8444],
        [-10.7489],
        [  8.2620],
        ...,
        [ -4.5143],
        [  5.8086],
        [ 17.2859]], device='cuda:1')
tensor(0.3200, device='cuda:1')
tensor([-3.6326], device='cuda:1')
tensor([[ -3.6262],
        [-11.5585],
        [ 10.7517],
        ...,
        [ 11.1476],
        [  6.1793],
        [ -8.4186]], device='cuda:1')
tensor(-0.1116, device='cuda:1')
tensor([-11.8207], device='cuda:1')
tensor([[-11.8212],
        [-15.2047],
        [ 10.2622],
        ...,
        [ -4.8218],
        [ -7.7641],
        [ -9.6890]], device='cuda:1')
tensor(-0.0131, device='cuda:1')
tensor([8.7884], device='cuda:1')
tensor([[  8.7879],
        [ -2.4143],
        [-18.9634],
        ...,
        [  7.1881],
        [ -7.3754],
        [ -8.0604]], device='cuda:1')
tensor(-0.7061, device='cuda:1')
tensor([11.7989], device='cuda:1')
tensor([[11.7906],
        [ 4.0569],
        [ 4.3632],
        ...,
        [-1.9944],
        [23.4667],
        [ 4.2646]], device='cuda:1')
tensor(0.1792, device='cuda:1')
tensor([-1.2077], device='cuda:1')
tensor([[-1.2106],
        [-4.4623],
        [ 6.8434],
        ...,
        [11.3424],
        [-2.5224],
        [21.8957]], device='cuda:1')
tensor(-0.3306, device='cuda:1')
tensor([6.1886], device='cuda:1')
tensor([[ 6.1864],
        [ 6.4488],
        [12.0242],
        ...,
        [-1.0735],
        [11.0646],
        [ 7.5807]], device='cuda:1')
tensor(0.0505, device='cuda:1')
tensor([-10.8415], device='cuda:1')
tensor([[-10.8445],
        [ -3.8285],
        [  8.4130],
        ...,
        [ -4.5387],
        [  6.8906],
        [ -4.3442]], device='cuda:1')
tensor(-0.0385, device='cuda:1')
tensor([-14.7105], device='cuda:1')
tensor([[-14.7116],
        [  3.6056],
        [ -6.8153],
        ...,
        [ -2.4579],
        [ -1.5690],
        [  9.1689]], device='cuda:1')
tensor(-0.3466, device='cuda:1')
tensor([-14.3516], device='cuda:1')
tensor([[-14.3517],
        [ -5.8886],
        [ -1.6717],
        ...,
        [  3.2298],
        [ -4.1801],
        [-21.2587]], device='cuda:1')
tensor(-0.1134, device='cuda:1')
tensor([-4.3470], device='cuda:1')
tensor([[ -4.3434],
        [ 15.5197],
        [ -2.3244],
        ...,
        [  3.1773],
        [ -5.7660],
        [-11.4940]], device='cuda:1')
tensor(0.4646, device='cuda:1')
tensor([-11.1364], device='cuda:1')
tensor([[-11.1356],
        [  4.4675],
        [ 11.4765],
        ...,
        [-26.7980],
        [-19.2498],
        [ 16.2226]], device='cuda:1')
tensor(0.1148, device='cuda:1')
tensor([-7.1665], device='cuda:1')
tensor([[ -7.1662],
        [  6.3433],
        [  2.2206],
        ...,
        [-19.9589],
        [ -3.3415],
        [-13.8988]], device='cuda:1')
tensor(-0.0258, device='cuda:1')
tensor([15.9931], device='cuda:1')
tensor([[ 15.9880],
        [  1.0561],
        [ 11.7466],
        ...,
        [ 11.7595],
        [  5.1260],
        [-16.8468]], device='cuda:1')
tensor(0.3601, device='cuda:1')
tensor([7.4023], device='cuda:1')
tensor([[ 7.4033],
        [-5.8871],
        [-9.7489],
        ...,
        [-1.9681],
        [ 7.2599],
        [ 2.6571]], device='cuda:1')
tensor(-0.1015, device='cuda:1')
tensor([6.6630], device='cuda:1')
tensor([[ 6.6691],
        [-3.1500],
        [10.0410],
        ...,
        [ 6.8995],
        [-9.0700],
        [-3.5976]], device='cuda:1')
tensor(0.0753, device='cuda:1')
tensor([-20.1561], device='cuda:1')
tensor([[-20.1586],
        [  9.1444],
        [  0.0778],
        ...,
        [  3.7817],
        [  1.0253],
        [ -2.4180]], device='cuda:1')
tensor(-0.0017, device='cuda:1')
tensor([-9.1158], device='cuda:1')
tensor([[ -9.1178],
        [  9.0431],
        [ -0.1171],
        [ -0.0977],
        [-14.9987],
        [-10.5091],
        [ -2.8115],
        [  0.4742],
        [ -0.4577],
        [ -2.7805],
        [-10.9712],
        [  8.1340],
        [  2.7671],
        [ 10.4400],
        [  7.7950],
        [ 18.7598],
        [ -7.6152],
        [ 20.8731],
        [  6.6004],
        [  3.4741],
        [  9.0159],
        [  7.3035],
        [-12.1270],
        [  0.9122],
        [  6.4032],
        [  4.7647],
        [ 14.5471],
        [-13.3565],
        [ -7.7441],
        [ 11.5855],
        [ 12.0524],
        [-13.4628],
        [ 15.9461],
        [ -0.8312],
        [ 12.7632],
        [ 10.3005],
        [-13.7501],
        [ -1.7480],
        [-11.8650],
        [  5.9973],
        [-11.8686],
        [  4.8185],
        [  6.4326],
        [ 14.8740],
        [ -4.2799],
        [  1.2029],
        [ -5.3449],
        [ -3.1949],
        [ -7.3407],
        [-14.6229],
        [ -7.4612],
        [  3.0628],
        [ 12.4174],
        [  8.9444],
        [  9.9150],
        [  3.6576],
        [  7.1748],
        [  5.0228],
        [-15.0326],
        [ -4.6129],
        [ -6.4913],
        [ -2.6608],
        [  2.8845],
        [  4.9627],
        [-12.9051],
        [  3.2906],
        [  2.5982],
        [ -4.6030],
        [ -4.3831],
        [ 18.1929],
        [-13.9359],
        [  5.6338],
        [ -3.6539],
        [ -3.1987],
        [  5.9191],
        [ -0.0288],
        [ -8.3372],
        [  4.8500],
        [  1.2185],
        [  1.2396],
        [ -1.4048],
        [ -2.2799],
        [  7.1852],
        [ 15.3175],
        [ -3.8058],
        [-10.1757],
        [ -3.8803],
        [-16.6377],
        [  4.7898],
        [ -3.1267],
        [ -2.8295],
        [ -1.3683],
        [ -5.6968],
        [  3.6023],
        [ -3.1034],
        [ -9.0107],
        [ -7.1826],
        [ -0.0587],
        [-21.2868],
        [  8.4803],
        [ 17.3355],
        [ -1.7155],
        [ -5.9938],
        [  8.2290],
        [ -2.9652],
        [  6.3307],
        [  2.8902],
        [ 13.1688],
        [-15.3347],
        [ -0.8851],
        [  2.8063],
        [ -2.2109],
        [ 18.8629],
        [ -0.9700],
        [  3.9821],
        [ -8.5968],
        [ -3.5299],
        [ -1.7461],
        [ 17.0164],
        [ 19.7773],
        [ -7.2361],
        [ -1.5032],
        [  8.8693],
        [ -1.6975],
        [  3.7314],
        [ -7.8716],
        [-14.1865],
        [ -2.3098],
        [ -2.1024],
        [-19.0108],
        [-15.5710],
        [  8.6484],
        [  2.7131],
        [  6.9840],
        [  0.6822],
        [  3.3156],
        [ 17.5357],
        [ -6.1755],
        [  9.1510],
        [ 10.3199],
        [  1.5764],
        [ 13.7012],
        [  2.5484],
        [ -2.7040],
        [  1.1438],
        [ -4.3382],
        [  3.6089],
        [ -1.6551],
        [ 14.2511],
        [  2.0485],
        [ -9.8442],
        [  9.2184],
        [ -2.0496],
        [ -7.7034],
        [ -3.5187],
        [ 25.3826],
        [ -1.3316],
        [ -4.8294],
        [ -5.5616],
        [ 11.2634],
        [ -8.1832],
        [  4.7825],
        [ -0.4885],
        [  9.3289],
        [ -0.5219],
        [ -1.7728],
        [  5.7950],
        [ -7.7210],
        [  2.3947],
        [-11.4585],
        [ -1.6028],
        [  2.5630],
        [  1.2079],
        [  4.7466],
        [ -1.5760],
        [  8.4842],
        [ -1.9978],
        [ -5.0731],
        [ -7.4813],
        [ -4.6223],
        [ -0.4681],
        [  9.4534],
        [  9.6487],
        [ -9.9422],
        [ -1.4766],
        [  6.4395],
        [  0.5641],
        [ -1.2470],
        [-16.5530],
        [ 16.0470],
        [ -3.5054],
        [ 12.6921],
        [ 12.9469],
        [  2.7384],
        [ 10.8749],
        [ 13.5175],
        [  5.5553],
        [ 11.8606],
        [ -9.5348],
        [-14.1232],
        [  0.6527],
        [ 10.8172],
        [  2.9349],
        [  2.1110],
        [ -8.7247],
        [  0.8552],
        [-10.8619],
        [ 14.8705],
        [ -8.4679],
        [  8.7202],
        [ -4.0396],
        [  8.3496],
        [ -4.9883],
        [-20.6168],
        [ 13.8020],
        [-10.0334],
        [ 11.6902],
        [-13.2050],
        [ 14.5414],
        [-14.3977],
        [-19.7224],
        [ -4.8576],
        [  8.9028],
        [ 11.3168],
        [ 11.7659],
        [ -0.6205],
        [ -2.2408],
        [  2.5975],
        [ -9.6970],
        [ -8.8014],
        [ 11.5165],
        [-15.8999],
        [ -2.4456],
        [-18.8746],
        [ 14.0192],
        [  5.5841],
        [ -9.5953],
        [ -7.1695],
        [ -3.6804],
        [ 11.6050],
        [ 12.1225],
        [ -7.7934],
        [ 18.0203],
        [ -7.4428],
        [  1.3073],
        [ -1.9440],
        [ 20.0898],
        [  0.6664],
        [ 15.3085],
        [ 14.6795],
        [  0.1151],
        [  7.7168],
        [ -0.1560],
        [ -1.6966],
        [-16.2758],
        [  6.4574],
        [ 10.5416],
        [-15.2449],
        [ -0.2205],
        [ 16.5296],
        [  5.1844],
        [ -0.2863],
        [ 13.5371],
        [ -8.8489],
        [ 13.2876],
        [ -2.2463],
        [  9.4997],
        [  1.9836],
        [-19.1261],
        [  1.2395],
        [  8.7846],
        [ -0.9452],
        [ -6.9840],
        [  0.8141],
        [ 11.6401],
        [  4.5718],
        [  0.8439],
        [  8.0907],
        [  6.4615],
        [  7.9454],
        [ 12.1650],
        [  5.1511],
        [ 11.3294],
        [ -0.2151],
        [ -5.7306],
        [ -4.1880],
        [  1.7601],
        [ -2.6330],
        [ -6.6752],
        [  1.7975],
        [ 14.1125],
        [  2.5800],
        [  0.1090],
        [  9.7777],
        [  4.1600],
        [-19.4936],
        [  9.2331],
        [  6.6618],
        [ 10.5408],
        [  9.7828],
        [ -3.5419],
        [ 17.8798],
        [ -3.2750],
        [ -4.6989],
        [-10.5223],
        [  4.1241],
        [  0.6890],
        [ -9.4045],
        [  0.9233],
        [ -2.6422],
        [  3.2945],
        [  0.0698],
        [ 14.5279],
        [  6.1073],
        [  8.7471],
        [  0.2314],
        [-12.7192],
        [  8.7756],
        [  7.2017],
        [ 13.7782],
        [-11.5844],
        [ 12.2510],
        [  7.9898],
        [  1.0770],
        [ 10.4307],
        [-15.7021],
        [ -8.4726],
        [-14.0674],
        [-11.8542],
        [  5.7547],
        [-18.1654],
        [ -0.7162],
        [ -5.8604],
        [-19.8876],
        [  0.9743],
        [ -2.8180],
        [-14.1349],
        [ -2.1772],
        [  6.5759],
        [  9.0047],
        [-12.1790],
        [ -2.6653],
        [-10.9094],
        [-10.0059],
        [ -6.5117],
        [ -9.0618],
        [  0.6176],
        [  0.2426],
        [  3.3348],
        [-10.4127],
        [-11.0200],
        [ -2.8474],
        [  3.0213],
        [ -7.0866],
        [  4.6431],
        [  1.2410],
        [ -7.5721],
        [  1.1836],
        [  2.1672],
        [ -5.1205],
        [ -5.6941],
        [  0.8042],
        [  5.3054],
        [  1.6724],
        [ 15.7955],
        [  4.2654],
        [ -7.7214],
        [  2.9122],
        [-10.8515],
        [ 15.5938],
        [  1.6990],
        [ 11.8445],
        [-10.4263],
        [  5.6376],
        [ -4.2634],
        [ -7.6127],
        [  7.0727],
        [  4.0668],
        [ -1.2459],
        [  3.0087],
        [-11.6301],
        [  0.6976],
        [-22.8327],
        [  6.6748],
        [  1.4998],
        [  8.2992],
        [ -8.3313],
        [-14.5276],
        [ -0.5421],
        [  3.6801],
        [  6.1265],
        [  1.3086],
        [  8.2218],
        [ 11.3970],
        [  9.0638],
        [ -1.0354],
        [-11.6171],
        [ 15.6167],
        [ -4.6726],
        [  5.0699],
        [ 16.4123],
        [-20.1964],
        [ -2.9169],
        [ -7.1746],
        [ 11.7039],
        [ 13.6166],
        [ -3.2415],
        [ -8.5911],
        [  6.9270],
        [ -2.6813],
        [  6.0360],
        [ -5.8019],
        [ -1.4397],
        [ -2.1832],
        [-18.0876],
        [  8.5794],
        [ -7.2450],
        [  9.0772],
        [  5.6304],
        [ 15.7546],
        [ 12.2738],
        [ -4.9930],
        [ -4.0011],
        [ 18.6006],
        [  7.1572],
        [ -5.8493],
        [  1.0230],
        [-14.7633],
        [  3.3037],
        [  2.9815],
        [ -0.8637],
        [ 10.2514],
        [-16.5194],
        [ -6.3668],
        [  2.1804],
        [-11.4907],
        [ -8.5369],
        [  3.3862],
        [ 10.6257],
        [ -9.6508],
        [  3.2304],
        [ -1.0630],
        [ -1.8655],
        [ -2.1092],
        [ -0.8882],
        [ -1.8503],
        [ -4.7822],
        [  6.2492],
        [-16.4669],
        [  6.4060],
        [  8.1700],
        [ 19.4305],
        [ 18.7371],
        [ 19.1973],
        [ -9.5006],
        [ -6.0011],
        [ -4.9048],
        [  2.4077],
        [-18.1951],
        [ 11.7607],
        [ -6.8516],
        [  5.0942],
        [  6.9736],
        [ -7.2736],
        [ -1.7945],
        [  7.0928],
        [ -5.7147],
        [  4.8634],
        [ 25.6308],
        [ -0.1953],
        [ -1.6230],
        [ -0.4107],
        [-10.0576],
        [ -0.3806],
        [  2.2270],
        [ 15.6176],
        [  6.2376],
        [-12.4481],
        [ -3.7079],
        [ 10.3666],
        [ -3.2532],
        [ -1.0774],
        [ 19.5066],
        [  9.2870],
        [ -5.2828],
        [ -5.3265],
        [  1.1198],
        [ 13.0961],
        [ -5.9717],
        [ -6.0107],
        [-22.9558],
        [  2.3958],
        [-21.1493],
        [  3.2069],
        [ 16.3005],
        [ 10.7530],
        [ -2.0230],
        [ 10.3806],
        [  7.6218],
        [  5.0457],
        [  7.0094],
        [  3.7568],
        [ -2.8855],
        [ -5.5901],
        [ -2.4612],
        [ 11.1449],
        [ -5.0302],
        [ -2.9455],
        [-20.3752],
        [  6.9393],
        [ -5.9074],
        [ -6.2548],
        [-14.9088],
        [  2.8532],
        [  7.4848],
        [  2.2479],
        [  6.7749],
        [-13.0179],
        [ 15.9958],
        [-22.4578],
        [ -5.1879],
        [  0.9764],
        [ 16.9690],
        [  4.4733],
        [ 23.6221],
        [ 13.6855],
        [ -6.3914],
        [  8.4630],
        [  9.3492],
        [-15.0183],
        [-16.5685],
        [ 17.4843],
        [ -3.1612],
        [ -9.1789],
        [  5.9173],
        [ 11.6467],
        [ -8.7863],
        [  8.5252],
        [  8.3073],
        [ -2.8131],
        [ -7.0717],
        [  5.5320],
        [ -2.3148],
        [  2.5484]], device='cuda:1')
tensor(0.6342, device='cuda:1')
Evaluating test...
tensor([9.3829], device='cuda:1')
tensor([[  9.3895],
        [ 38.6693],
        [ 33.9899],
        ...,
        [-19.8060],
        [ 32.6539],
        [-10.4388]], device='cuda:1')
tensor(-0.0667, device='cuda:1')
tensor([-6.6793], device='cuda:1')
tensor([[ -6.6866],
        [ 37.2621],
        [ -3.8030],
        ...,
        [ 20.6859],
        [-55.0764],
        [-14.6450]], device='cuda:1')
tensor(-0.3840, device='cuda:1')
tensor([-2.3346], device='cuda:1')
tensor([[ -2.3379],
        [ -4.9747],
        [ -3.1075],
        ...,
        [-11.4552],
        [ 14.9079],
        [  9.3653]], device='cuda:1')
tensor(-0.7952, device='cuda:1')
tensor([5.8398], device='cuda:1')
tensor([[  5.8374],
        [-13.8213],
        [ -8.3393],
        ...,
        [ 86.2122],
        [ -3.1127],
        [  5.7650]], device='cuda:1')
tensor(2.1192, device='cuda:1')
tensor([6.6067], device='cuda:1')
tensor([[  6.6012],
        [-18.9262],
        [ -4.1934],
        ...,
        [-70.3176],
        [ 41.3540],
        [-45.7697]], device='cuda:1')
tensor(-0.3630, device='cuda:1')
tensor([3.5918], device='cuda:1')
tensor([[  3.5881],
        [-49.7796],
        [  9.8102],
        ...,
        [ 12.1648],
        [ 39.8289],
        [-44.7996]], device='cuda:1')
tensor(-0.7031, device='cuda:1')
tensor([-26.9353], device='cuda:1')
tensor([[-26.5781],
        [  3.7777],
        [ -4.7342],
        ...,
        [ 53.2861],
        [-21.2184],
        [ 20.4683]], device='cuda:1')
tensor(0.7015, device='cuda:1')
tensor([5.2234], device='cuda:1')
tensor([[  5.2225],
        [  4.4789],
        [ -0.6580],
        ...,
        [-33.4280],
        [ -7.0773],
        [ 70.8411]], device='cuda:1')
tensor(1.4327, device='cuda:1')
tensor([-9.7748], device='cuda:1')
tensor([[-9.7995],
        [ 5.5770],
        [10.1570],
        ...,
        [27.0089],
        [26.4548],
        [ 0.0773]], device='cuda:1')
tensor(0.7266, device='cuda:1')
tensor([-10.6253], device='cuda:1')
tensor([[-1.0830e+01],
        [ 4.4332e+00],
        [ 8.7630e+00],
        [-3.6915e+00],
        [ 1.3625e+00],
        [ 9.6151e+00],
        [ 1.3935e+00],
        [ 1.7530e-01],
        [ 2.4244e+01],
        [ 3.5633e+01],
        [-1.1217e+01],
        [-5.0753e+00],
        [ 1.1445e+01],
        [-7.6653e+00],
        [ 3.1471e+01],
        [-1.3943e+01],
        [-3.4711e+01],
        [-1.2006e+01],
        [ 1.6629e+01],
        [-3.2813e+00],
        [-1.5373e+01],
        [-4.1944e+00],
        [-6.4784e+00],
        [-3.9874e+00],
        [ 1.9010e+01],
        [ 1.9744e+00],
        [ 2.8892e+01],
        [ 3.6042e+01],
        [ 5.4746e+01],
        [-2.3525e+00],
        [ 2.8116e+01],
        [-1.5608e+01],
        [-3.3810e+01],
        [ 9.4491e+00],
        [-1.7110e+01],
        [-1.9893e+01],
        [ 5.6828e+00],
        [-5.6361e+00],
        [ 1.1831e+01],
        [ 6.8468e+01],
        [ 2.0964e+01],
        [-3.5872e+01],
        [-2.6026e+01],
        [ 1.5345e+01],
        [ 2.2110e+01],
        [-8.4926e+00],
        [ 8.3014e+00],
        [ 2.9455e+01],
        [-1.6981e+01],
        [ 3.5230e+01],
        [-4.2251e+01],
        [ 1.8407e+00],
        [ 4.5269e+00],
        [-4.2019e+00],
        [ 9.8857e+00],
        [-5.2720e+01],
        [ 1.1458e+01],
        [-7.3143e+00],
        [-1.6485e+01],
        [ 2.7570e+01],
        [-2.2036e+01],
        [-1.6757e+00],
        [ 3.5964e+01],
        [ 7.6096e+00],
        [ 2.5050e+01],
        [ 2.1788e+01],
        [-5.3494e+01],
        [-1.3430e+01],
        [-5.1570e+00],
        [ 3.2430e+01],
        [ 9.2680e+00],
        [-1.5521e+01],
        [-7.5008e+00],
        [-1.5797e+01],
        [-3.4440e+00],
        [ 6.3340e+01],
        [-2.5784e+01],
        [-7.9154e-02],
        [ 5.4630e+01],
        [ 3.8409e+01],
        [-1.1298e+01],
        [ 2.6823e+01],
        [-1.5461e+01],
        [-6.5698e+00],
        [-1.0899e+01],
        [ 4.3155e+00],
        [ 5.8422e+01],
        [-4.1286e+00],
        [-1.6826e+01],
        [ 5.9892e+01],
        [ 9.0683e+00],
        [-4.1695e+00],
        [ 5.6510e+01],
        [ 5.0404e+01],
        [-2.0333e+01],
        [ 1.5637e+01],
        [ 3.4840e+01],
        [-1.4490e+01],
        [-2.7540e+00],
        [ 4.1219e+00],
        [-1.6654e+01],
        [-3.7614e+01],
        [-1.9810e+00],
        [-1.9012e+01],
        [ 6.9431e+01],
        [ 4.3256e+00],
        [ 3.7206e+01],
        [-5.1058e+01],
        [-9.6868e+00],
        [-1.6114e+01],
        [-1.1872e+01],
        [-5.9653e+00],
        [ 7.0876e+00],
        [ 1.5959e+01],
        [-2.4905e+01],
        [-4.8913e+00],
        [-3.8230e+01],
        [-2.9760e+01],
        [ 5.9119e+01],
        [-1.1019e+01],
        [ 1.5015e+01],
        [-2.8459e+01],
        [-1.1502e+01],
        [ 1.0589e+01],
        [-1.7900e+00],
        [ 3.6618e+01],
        [-6.1845e+01],
        [-6.1080e+01],
        [-8.5068e+00],
        [-2.0550e+01],
        [-7.4523e+00],
        [-2.1341e+01],
        [-9.0795e+00],
        [-2.5236e-01],
        [-5.0597e+00],
        [ 4.6091e-02],
        [ 1.0566e+01],
        [-8.7793e+00],
        [-3.0706e+01],
        [ 7.8181e+00],
        [-6.6194e+00],
        [-1.6434e+00],
        [-7.5466e-01],
        [-8.4656e+00],
        [ 7.0166e+00],
        [ 2.3203e+01],
        [ 2.2259e-01],
        [ 2.2222e+01],
        [ 1.3773e+01],
        [-1.8530e+01],
        [ 4.8896e-01],
        [-1.5421e+00],
        [ 3.9017e+01],
        [ 5.3968e+01],
        [-6.8036e+00],
        [ 2.1489e+01],
        [-9.2400e-01],
        [ 8.6397e+00],
        [-4.2749e+00],
        [-5.4863e+00],
        [-3.0865e+01],
        [-6.6290e+00],
        [-4.1828e+01],
        [ 2.2329e+01],
        [ 1.6809e+01],
        [ 1.2757e+01],
        [ 3.7209e+01],
        [ 1.3095e+01],
        [-2.1002e+00],
        [-2.4225e+01],
        [ 6.5966e+00],
        [ 4.2494e+00],
        [ 3.3023e-01],
        [ 8.5386e+00],
        [-2.2012e+00],
        [ 1.7678e-01],
        [-4.4418e+00],
        [-5.1215e+01],
        [-1.3810e+01],
        [ 2.5779e+00],
        [ 5.4310e+01],
        [ 1.1866e+01],
        [-1.0382e+01],
        [ 4.5128e+00],
        [-3.6655e+00],
        [ 5.0557e+00],
        [ 5.2505e+01],
        [ 3.8912e+00],
        [-5.7200e+00],
        [ 9.8230e-01],
        [-3.3817e+00],
        [ 2.2859e+01],
        [ 6.6506e+01],
        [-6.4020e+01],
        [-1.1566e+01],
        [ 4.1811e+01],
        [-9.5778e+00],
        [-1.6128e+01],
        [-2.5701e+01],
        [ 2.2077e+01],
        [ 2.2125e+00],
        [ 3.7201e+01],
        [ 2.5433e-01],
        [-6.9684e+01],
        [ 1.4560e+01],
        [-6.7099e+00],
        [ 5.2576e+01],
        [-3.9493e+00],
        [-2.5123e+01],
        [ 1.1596e+01],
        [ 1.9746e+01],
        [-1.1030e+00],
        [-1.1935e+01],
        [-2.7706e+00],
        [-5.7898e+01],
        [-5.5274e+00],
        [-5.6700e-01],
        [-2.5182e+00],
        [-2.6729e+00],
        [ 3.6219e+01],
        [-9.0104e+00],
        [ 6.1719e+00],
        [-4.5184e+00],
        [-3.1459e+00],
        [ 1.4683e+01],
        [ 3.6811e+01],
        [ 8.3937e+00],
        [-5.3638e+00],
        [ 2.7555e-01],
        [ 2.0512e+00],
        [ 7.1327e+00],
        [ 6.3799e+01],
        [ 1.1278e+01],
        [ 9.2279e+00],
        [-5.3386e+01],
        [ 1.7476e+00],
        [ 2.3318e+01],
        [ 3.7662e+00],
        [ 1.2224e+01],
        [-3.9720e+01],
        [ 3.0566e+01],
        [-4.0261e+01],
        [ 6.4851e+01],
        [ 4.7776e+00],
        [-1.6843e+01],
        [ 9.0601e+01],
        [-7.1460e+01],
        [-7.2664e+00],
        [ 2.8451e+00],
        [-4.6908e+00],
        [-1.6929e+00],
        [-3.0296e+01],
        [ 1.5745e+00],
        [ 7.6725e+00],
        [ 9.8008e-01],
        [ 3.5185e-01],
        [-2.8133e+01],
        [-1.1771e+01],
        [-9.6900e-01],
        [-6.8015e+00],
        [ 4.0320e+00],
        [-5.8893e+01],
        [ 4.0526e+00],
        [ 2.9605e+01],
        [-2.0314e+01],
        [-2.7133e+01],
        [-2.7644e+01],
        [-5.2842e+01],
        [-2.5532e+01],
        [-6.2130e+00],
        [ 2.8131e+01],
        [ 5.5975e+00],
        [ 1.5831e+01],
        [ 9.5136e+00],
        [-5.5393e+00],
        [ 6.0465e+01],
        [ 6.8315e+01],
        [ 3.8885e+01],
        [-1.0135e+01],
        [-2.2158e+00],
        [-2.0647e+01],
        [-1.1526e+01],
        [-9.1189e+00],
        [ 1.3628e+00],
        [-1.6045e+01],
        [ 4.9712e+01],
        [ 7.5703e+00],
        [-2.1708e+01],
        [-2.6204e-01],
        [-2.5236e+01],
        [-5.3377e-02],
        [ 3.2306e+01],
        [-5.8319e+01],
        [ 7.0205e+01],
        [-1.2024e+01],
        [-8.7892e+00],
        [ 1.4291e+01],
        [ 2.2546e+00],
        [-5.9305e+00],
        [ 8.2001e+00],
        [ 1.4696e+01],
        [-1.2848e+01],
        [ 5.9927e+00],
        [-2.3236e+01],
        [ 2.6158e+01],
        [-2.1759e+01],
        [-3.8729e+00],
        [ 1.9584e+01],
        [-5.9269e+01],
        [ 1.4653e+01],
        [ 1.1266e+01],
        [-5.7768e+01],
        [ 3.7999e+01],
        [-2.0453e+00],
        [-1.8456e+01],
        [-8.2820e-01],
        [ 6.8260e+01],
        [ 3.0511e+01],
        [ 2.2329e+01],
        [ 1.0731e+01],
        [ 4.6476e+01],
        [ 8.4736e+00],
        [-2.1519e+01],
        [-3.2257e+01],
        [ 1.1236e+01],
        [-3.8472e+01],
        [ 5.5177e+01],
        [-2.5513e+00],
        [-5.8102e+01],
        [ 4.3472e+00],
        [ 2.8775e+00],
        [ 5.8362e+01],
        [-7.0219e+01],
        [-2.4539e+00],
        [-1.1996e+01],
        [ 6.8682e+00],
        [ 5.5056e+00],
        [-1.2180e+01],
        [-1.0549e+01],
        [-6.3590e+01],
        [ 6.0664e+01],
        [ 8.0237e+00],
        [-4.7089e+01],
        [-9.7272e+00],
        [-1.1220e+01],
        [ 5.1675e+01],
        [-1.9950e+00],
        [ 6.0695e+00],
        [-9.8225e+00],
        [ 3.2161e+01],
        [ 1.4454e+01],
        [ 5.2230e+00],
        [-2.4829e+01],
        [ 5.7189e+01],
        [ 8.0465e+00],
        [-2.5757e+01],
        [ 9.2971e+00],
        [-2.1224e-01],
        [ 6.9075e+00],
        [ 1.6696e+01],
        [-2.1203e+01],
        [ 9.7526e-01],
        [ 1.5777e+01],
        [-1.5204e+01],
        [-3.6403e+01],
        [-1.1542e+01],
        [ 6.2696e+00],
        [ 5.5544e+00],
        [-5.5371e+00],
        [-3.9773e+01],
        [ 9.9960e+00],
        [ 5.8962e+01],
        [ 7.1268e+01],
        [ 1.4708e+00],
        [ 2.1614e+01],
        [-6.2267e+01],
        [-9.2525e+00],
        [ 1.5977e+01],
        [ 1.8600e+01],
        [ 3.1929e+01],
        [-8.1920e+00],
        [-7.0433e+00],
        [ 5.6947e+00],
        [ 1.3006e+00],
        [ 5.6976e+00],
        [-5.6838e+00],
        [-1.8331e+00],
        [-4.0675e+01],
        [-4.2890e+00],
        [-5.7444e+00],
        [ 7.6058e+00],
        [-2.1322e+01],
        [-5.8853e+01],
        [ 1.8797e+00],
        [ 7.4257e+01],
        [-2.7359e+01],
        [-6.7546e+01],
        [-6.2498e+00],
        [ 7.6000e+00],
        [ 1.2086e+01],
        [-4.8837e+01],
        [ 3.7508e+00],
        [ 4.0402e+01],
        [ 6.4644e+01],
        [-9.5601e+00],
        [ 7.4468e+01],
        [-1.2773e+01],
        [ 1.6560e+01],
        [-1.0572e+00],
        [ 6.0073e+00],
        [-1.8724e+01],
        [-2.2303e+01],
        [-3.4511e+00],
        [-2.4362e+01],
        [-6.3714e+00],
        [ 4.7157e+00],
        [ 5.7690e+01],
        [-1.2721e+01],
        [ 1.3392e+01],
        [ 3.8600e+01],
        [-6.1831e+01],
        [-6.3072e+00],
        [ 1.5242e+01],
        [ 7.2709e+00],
        [-8.5216e+00],
        [ 7.0121e-01],
        [-3.0673e+01],
        [ 7.8752e+00],
        [ 5.7467e-01],
        [-4.8206e+01],
        [ 3.5706e+00],
        [ 1.2788e+01],
        [ 1.0189e+01],
        [ 1.5067e+01],
        [ 6.9739e+00],
        [-1.7270e+01],
        [ 3.0677e+00],
        [ 8.1107e+00],
        [ 1.2062e+01],
        [ 8.5786e+00],
        [ 2.1343e+01],
        [-1.4764e+01],
        [-2.1087e+00],
        [ 2.9860e-01],
        [ 2.2423e+00],
        [-1.4757e+01],
        [ 7.3269e+00],
        [-2.3084e+01],
        [-1.5283e+01],
        [ 5.0924e+00],
        [-2.6034e+00],
        [ 5.6284e+01],
        [ 2.3864e+01],
        [ 5.1088e+01],
        [ 1.7559e+01],
        [-4.7162e-01],
        [ 1.7574e+01],
        [-1.3135e+01],
        [ 3.3816e+00],
        [-2.0206e+01],
        [-4.0159e+01],
        [ 4.7706e+00],
        [ 1.9134e+01],
        [-5.9731e+00],
        [-5.2782e+00],
        [-9.6588e+00],
        [-3.7493e+01],
        [ 3.4523e+01],
        [ 9.4673e+00],
        [-3.3717e+00],
        [ 1.2248e+01],
        [-1.3829e+01],
        [-3.7751e+01],
        [-1.0214e+01],
        [-1.3208e+00],
        [ 3.0717e+00],
        [ 1.1725e+01],
        [ 2.1109e+00],
        [-4.4965e+01],
        [ 2.5061e+01],
        [-2.6629e+00],
        [ 1.4502e+01],
        [ 5.8685e+01],
        [-2.8074e+01],
        [ 1.0281e+01],
        [-6.1821e+01],
        [ 2.0316e+01],
        [ 5.6510e-01],
        [-2.2929e-01],
        [ 3.9588e+01],
        [-1.2248e+01],
        [-1.3176e+01],
        [-1.6323e+01],
        [-6.7421e+01],
        [ 1.2066e+01],
        [-2.4657e+01],
        [-4.7735e+00],
        [-1.8114e+01],
        [ 2.7095e+01],
        [-4.3557e+01],
        [ 9.4313e+00],
        [ 1.0889e+01],
        [ 2.9888e+00],
        [-5.9803e+00],
        [ 2.9413e+01],
        [ 1.8305e+01],
        [ 1.5293e+01],
        [ 2.6001e+01],
        [ 8.6888e+00],
        [ 3.3526e+01],
        [-4.2878e+01],
        [ 2.7197e+00],
        [ 3.9474e+01],
        [-1.2033e+01],
        [ 5.6305e+00],
        [-3.1811e+01],
        [ 2.2961e+01],
        [ 1.7774e+01],
        [-5.9282e+01],
        [-3.6751e+01],
        [ 2.4900e-02],
        [ 1.7158e+01],
        [-4.7527e+01],
        [-5.9836e+01],
        [-6.0954e+01],
        [-6.0861e+01],
        [-1.3400e+01],
        [-3.5058e+01],
        [ 1.0170e+01],
        [ 8.9312e+00],
        [ 1.8623e+01],
        [ 1.9395e+00],
        [ 1.5784e+01],
        [-2.1594e+00],
        [-2.2103e+00],
        [-1.1157e+01],
        [ 3.4514e+00],
        [ 1.9015e+01],
        [-1.0127e+01],
        [ 2.5594e+01],
        [ 9.3594e-01],
        [-8.9990e+00],
        [-1.9877e+01],
        [ 1.2478e+01],
        [-1.3763e+00],
        [ 1.3295e+01],
        [-5.1208e+00],
        [-9.2309e+00],
        [-4.0040e+00],
        [ 7.7408e+01],
        [-2.5888e+00],
        [ 1.2339e+01],
        [-9.0630e+00],
        [-2.6490e+01],
        [-6.4106e+00],
        [-1.5971e+00],
        [-3.6052e+00],
        [ 6.5127e+00],
        [ 3.2635e+01],
        [-1.7120e+01],
        [-2.2456e+01],
        [-3.8403e+01],
        [-1.5992e+01],
        [ 4.0050e+00],
        [ 1.1758e+01],
        [-5.9626e+01],
        [ 4.1623e-01],
        [-1.7688e+00],
        [-4.0850e+00],
        [-1.7926e+01],
        [ 1.4041e+01],
        [-1.1149e+01],
        [ 2.1436e+01],
        [ 3.0227e+01],
        [ 3.6437e+01],
        [-6.4519e+00],
        [-6.4668e+01],
        [-6.0636e+01],
        [-1.7384e+01],
        [-4.5909e-01],
        [ 1.8322e+01],
        [-3.5637e+01],
        [ 1.2347e+01],
        [-1.6804e+01],
        [ 1.7128e+01],
        [ 1.9669e+01],
        [-9.2308e+00],
        [ 6.7934e+00],
        [-1.4365e+01],
        [-4.9356e+01],
        [-7.0829e+00],
        [-3.5417e+01],
        [ 5.4597e+00],
        [-2.4877e+01],
        [-5.3215e+01],
        [-3.9670e+01],
        [-4.6569e+00],
        [-1.0824e+01],
        [-2.2991e+01],
        [ 2.3287e+00],
        [ 6.5513e-01],
        [ 3.6720e+00],
        [-1.5260e+01],
        [ 6.6683e+01],
        [ 2.3013e+01],
        [-5.6262e+00],
        [ 7.0351e+01],
        [ 4.6267e+00],
        [ 1.9158e+01],
        [ 3.0416e+01],
        [ 7.3144e+00],
        [-1.3855e+01],
        [ 3.2020e+01],
        [-1.4303e+01],
        [-5.9581e+01],
        [ 4.5735e+01],
        [ 4.0677e+00],
        [ 3.1147e+00],
        [ 7.4244e+01],
        [ 6.6080e+00],
        [ 2.5957e+01],
        [ 3.3379e+01],
        [-3.2639e+01],
        [-5.4011e+01],
        [-5.6325e+01],
        [ 4.3438e+01],
        [ 5.7969e+00],
        [ 3.0861e+00],
        [-2.4586e+01],
        [ 3.9424e+01],
        [-2.1445e+00],
        [-1.2012e+01],
        [ 4.8107e+00],
        [ 2.5970e+01],
        [ 4.5197e+01],
        [-1.6732e+01],
        [-1.5755e+00],
        [ 1.4456e+00],
        [ 3.4244e+01],
        [ 6.8053e+00],
        [-3.2620e+00],
        [ 4.8294e+00],
        [-4.7787e+01],
        [-5.7182e+00],
        [-5.9055e+01],
        [-6.4895e+01],
        [-1.9813e+01],
        [ 2.1412e+01],
        [ 3.6921e+00],
        [ 4.9540e+01],
        [ 5.6092e-01],
        [ 1.9457e+01],
        [-9.1185e+00],
        [-9.6485e+00],
        [-7.3687e+00],
        [-1.6723e-01],
        [ 1.2557e+01],
        [-5.4607e-01],
        [-2.6286e+01],
        [ 2.6265e+01],
        [-1.9544e+01],
        [ 2.2013e+00],
        [ 5.9850e+00],
        [ 7.3526e+00],
        [-2.5007e+01],
        [ 2.4780e+00],
        [-8.9103e+00],
        [-1.3835e+01],
        [-4.9278e+01],
        [ 9.9080e+00],
        [-2.6675e+00],
        [ 1.9217e+01],
        [-1.7842e+00],
        [ 4.0255e+00],
        [-1.8420e+00],
        [-1.1146e+01],
        [ 1.2682e+01],
        [-3.7795e+01],
        [ 4.7581e+00],
        [ 2.4769e+01],
        [-3.7917e+01],
        [-6.2411e+00],
        [ 7.9332e+00],
        [ 5.9084e+01],
        [ 1.3619e+01],
        [ 5.9477e+01],
        [ 3.1011e+00],
        [-4.8622e+01],
        [-7.1736e+00],
        [-9.4865e+00],
        [ 7.5357e+00],
        [-8.0527e+00],
        [ 4.9450e+00],
        [-3.1375e+01],
        [-6.6713e+01],
        [-9.3194e+00],
        [-9.6723e+00],
        [ 2.6972e+01],
        [ 4.7244e-02],
        [ 6.6182e+00],
        [-1.0048e+00],
        [-1.4192e+01],
        [ 4.1559e+00],
        [ 3.4600e+00],
        [ 4.1687e+01],
        [ 3.8238e+00],
        [-1.8451e+01],
        [ 1.2492e+01],
        [-5.0003e+01],
        [-8.8773e-01],
        [-1.1276e+00],
        [-2.0285e+01],
        [ 7.4120e+00],
        [ 3.1243e+01],
        [ 1.1367e+01],
        [-6.7570e+01],
        [ 9.7826e-01],
        [-1.5314e+01],
        [-2.0148e+00],
        [ 4.5698e+01],
        [ 1.9738e+00],
        [ 3.5826e+01],
        [ 8.2337e+00],
        [ 4.6390e+01],
        [ 3.2147e+01],
        [ 4.7464e+01],
        [ 9.0745e+00],
        [ 8.5643e+00],
        [-2.6502e-02],
        [ 6.4264e+01],
        [-5.3716e+01],
        [-5.0699e+01],
        [-4.2425e+01],
        [-1.6994e+01],
        [ 3.0958e+00],
        [ 1.0151e+01],
        [-2.0189e+01],
        [-3.4682e+01],
        [-6.0460e+00],
        [-1.2070e+01],
        [ 1.5987e+01],
        [ 2.4843e+00],
        [-6.3294e+00],
        [ 9.4085e+00],
        [ 6.8732e+00],
        [-3.4799e+01],
        [ 1.4301e+01],
        [-5.4148e+01],
        [-5.8902e+01],
        [ 1.0416e+01],
        [ 1.6121e+01],
        [ 9.0493e-01],
        [-1.8921e+00],
        [-5.8034e+00],
        [-1.6393e+01],
        [ 3.2312e+01],
        [ 6.2546e+00],
        [-1.0363e+00],
        [ 1.7728e+01],
        [ 1.6309e+01],
        [ 3.2916e+00],
        [ 5.1366e+00],
        [ 1.2437e+01],
        [ 1.5255e+01],
        [ 3.5535e+00],
        [-4.8081e+01],
        [ 1.5117e+01],
        [ 1.4263e+01],
        [ 3.0943e+00],
        [-9.0211e+00],
        [ 2.3051e+01],
        [-3.6772e+01],
        [ 1.3601e+01],
        [ 1.2096e+01],
        [ 1.9045e+01],
        [ 3.9649e+01],
        [ 3.0025e+01],
        [-6.0160e+00],
        [-5.1669e+00],
        [-7.2989e-01],
        [ 3.5854e+01],
        [-5.8999e+00],
        [ 5.3742e+00],
        [-6.2966e+00]], device='cuda:1')
tensor(0.2547, device='cuda:1')
Evaluating in_domain...
tensor([-1.6375], device='cuda:1')
tensor([[ -1.6414],
        [-15.5661],
        [ -6.9123],
        ...,
        [-22.5218],
        [-15.8961],
        [-16.4160]], device='cuda:1')
tensor(0.0661, device='cuda:1')
tensor([-0.9977], device='cuda:1')
tensor([[-1.0020],
        [ 3.2608],
        [10.9490],
        ...,
        [ 2.7015],
        [ 0.4504],
        [ 7.7459]], device='cuda:1')
tensor(-0.3057, device='cuda:1')
tensor([3.8496], device='cuda:1')
tensor([[  3.8316],
        [ 11.6562],
        [-12.6082],
        ...,
        [  7.4159],
        [ -8.0943],
        [ -2.9833]], device='cuda:1')
tensor(0.0150, device='cuda:1')
tensor([12.2491], device='cuda:1')
tensor([[ 12.2490],
        [-16.8881],
        [ -3.6324],
        ...,
        [ -1.1119],
        [  3.7148],
        [ -8.3950]], device='cuda:1')
tensor(-0.0044, device='cuda:1')
tensor([-3.4618], device='cuda:1')
tensor([[-3.4587e+00],
        [ 2.1832e+00],
        [ 3.2046e-01],
        [-1.5032e+00],
        [-1.0473e+00],
        [ 2.1876e+00],
        [-1.7776e+01],
        [ 1.5460e+00],
        [-6.5550e+00],
        [ 3.8256e+00],
        [ 9.4356e+00],
        [ 2.4921e+01],
        [ 1.2452e+01],
        [ 3.4893e+00],
        [ 7.5735e+00],
        [-4.1349e+00],
        [ 2.2488e+00],
        [ 1.8244e+01],
        [-1.0144e+01],
        [ 6.9540e+00],
        [ 3.9132e+00],
        [ 5.3371e+00],
        [-1.9779e+01],
        [-1.4906e+01],
        [ 8.8217e+00],
        [ 9.2892e-01],
        [ 1.4625e+01],
        [ 7.7267e+00],
        [-4.7128e+00],
        [ 5.4659e-01],
        [-4.3652e+00],
        [-5.6284e+00],
        [-2.2315e-01],
        [ 5.4291e+00],
        [ 4.3885e+00],
        [-7.8795e+00],
        [ 1.1826e+01],
        [ 2.9778e+00],
        [-7.4872e-01],
        [ 7.7915e+00],
        [-5.5647e-01],
        [-6.7317e+00],
        [-6.2219e+00],
        [ 1.9464e+00],
        [ 2.1972e-01],
        [ 8.7590e+00],
        [-2.5832e+00],
        [ 1.6749e+01],
        [-8.3977e+00],
        [-2.3711e+00],
        [ 3.2778e+00],
        [-5.5185e+00],
        [-8.7090e+00],
        [-2.5531e+00],
        [ 2.5765e+00],
        [ 4.7648e+00],
        [-6.9952e+00],
        [ 5.5604e+00],
        [ 9.8344e+00],
        [ 7.6821e+00],
        [-1.6483e+00],
        [ 9.3576e+00],
        [-6.1088e+00],
        [-1.0627e+01],
        [ 4.8128e+00],
        [ 9.4930e+00],
        [ 5.2903e+00],
        [ 1.3074e+00],
        [ 1.2065e+01],
        [-2.4478e+00],
        [-2.4953e+00],
        [ 8.1857e+00],
        [ 1.3374e+01],
        [-2.1127e+01],
        [-1.1366e+01],
        [-1.0799e+01],
        [-7.5379e+00],
        [-4.1473e+00],
        [-5.5642e+00],
        [ 7.9695e+00],
        [-1.6618e+01],
        [-4.5280e+00],
        [-6.1923e+00],
        [ 1.3537e+00],
        [-1.3199e+00],
        [-6.7849e+00],
        [-7.8768e+00],
        [-9.6506e+00],
        [ 1.5541e+00],
        [ 4.8812e-01],
        [-2.5054e+00],
        [ 1.8824e+01],
        [ 1.4386e+01],
        [ 8.5873e+00],
        [ 1.4460e+01],
        [ 7.2214e+00],
        [-3.2956e+00],
        [-3.2345e+00],
        [ 1.5893e+01],
        [-4.2982e+00],
        [ 9.8124e+00],
        [ 5.8636e+00],
        [ 7.4266e+00],
        [ 4.7360e+00],
        [ 8.6355e+00],
        [-3.5263e-01],
        [-3.5722e+00],
        [-1.4258e+00],
        [-3.1005e+00],
        [ 1.0906e-01],
        [-5.1538e+00],
        [-1.2309e+00],
        [ 4.2561e-01],
        [-6.2171e+00],
        [-4.7529e+00],
        [-1.9771e+00],
        [ 7.2346e+00],
        [-4.4536e+00],
        [-4.7516e+00],
        [-7.9898e+00],
        [ 8.4886e+00],
        [ 5.6591e+00],
        [ 1.3578e+00],
        [-8.3684e+00],
        [ 4.6036e+00],
        [-1.1767e+01],
        [ 6.7274e+00],
        [-5.5010e+00],
        [-2.3889e+00],
        [ 4.7969e+00],
        [-6.4304e+00],
        [ 4.9185e+00],
        [ 3.8567e+00],
        [-2.5838e+00],
        [-9.6134e+00],
        [-1.4964e+01],
        [-6.1853e+00],
        [-8.0409e-01],
        [-2.8604e+00],
        [ 2.5022e+00],
        [ 1.5053e+01],
        [-1.5810e+01],
        [ 9.1423e+00],
        [ 2.2479e+00],
        [-9.5670e+00],
        [ 3.4326e+00],
        [-4.2246e+00],
        [ 2.6880e+00],
        [ 2.3409e+00],
        [-1.9723e+01],
        [ 1.3725e+01],
        [-6.8518e+00],
        [-7.6602e+00],
        [-1.3532e+01],
        [ 1.5086e+01],
        [-1.1173e+00],
        [-8.5092e-01],
        [-5.9572e+00],
        [ 8.2281e+00],
        [ 1.2554e+00],
        [ 8.0294e+00],
        [-4.3579e+00],
        [-1.4488e+00],
        [-2.1680e+01],
        [ 3.2198e+00],
        [ 5.7083e-01],
        [ 3.6510e+00],
        [-9.0879e+00],
        [-1.0637e+01],
        [ 9.0631e+00],
        [-4.4642e+00],
        [ 7.7515e+00],
        [-1.2968e+01],
        [-1.6596e-01],
        [ 8.7856e+00],
        [-1.5460e+01],
        [ 5.6245e+00],
        [-1.2747e+00],
        [ 6.5249e+00],
        [-2.3501e+01],
        [ 1.6960e+00],
        [-1.3804e+01],
        [ 6.5363e-02],
        [ 1.0662e+00],
        [ 6.6915e+00],
        [ 2.2303e+01],
        [ 8.1552e+00],
        [ 2.9353e+00],
        [-8.7015e+00],
        [-6.5455e+00],
        [ 1.1096e+01],
        [-9.0876e+00],
        [ 6.9561e+00],
        [ 4.7465e+00],
        [ 1.7557e+01],
        [ 1.1689e+01],
        [-1.4472e+01],
        [ 8.2434e+00],
        [-7.4987e+00],
        [-6.0723e+00],
        [ 1.1337e+01],
        [ 5.2237e+00],
        [ 5.6904e+00],
        [-7.7767e+00],
        [-2.4050e+01],
        [-7.0952e-01],
        [-6.1704e+00],
        [ 8.3902e+00],
        [ 6.3428e+00],
        [ 4.9200e+00],
        [ 2.8833e+00],
        [-2.0733e+00],
        [-8.2814e+00],
        [-2.2345e+00],
        [ 2.6625e+00],
        [ 1.1504e+01],
        [-5.5686e+00],
        [-1.8774e+00],
        [ 5.7015e+00],
        [-1.3486e+00],
        [-3.1227e+00],
        [-2.4032e+00],
        [ 1.4173e+01],
        [ 3.7579e+00],
        [ 1.6351e+00],
        [-2.3930e+00],
        [-1.9294e+00],
        [-2.2798e+01],
        [ 1.1367e+01],
        [-1.7914e+01],
        [-4.1274e+00],
        [-6.0805e+00],
        [ 2.8430e+00],
        [-2.4103e+01],
        [-4.3024e+00],
        [ 2.6471e+00],
        [-1.7060e+01],
        [ 2.0358e+01],
        [-4.6740e+00],
        [ 5.8944e+00],
        [-7.4218e+00],
        [-1.6641e+00],
        [-1.4032e+00],
        [ 3.7997e+00],
        [ 9.3571e+00],
        [-1.5852e+00],
        [-2.0455e+00],
        [-1.4216e+00],
        [ 4.3523e+00],
        [ 2.4780e+01],
        [ 2.9095e+00],
        [ 1.1489e+01],
        [-3.0384e+00],
        [ 1.7379e+01],
        [-1.1983e+01],
        [ 9.4598e+00],
        [-1.0784e+01],
        [-1.4130e+01],
        [ 1.3669e+01],
        [ 6.5188e+00],
        [-8.0747e+00],
        [ 1.9786e+01],
        [ 1.3206e+01],
        [ 2.7557e+01],
        [ 3.0815e+00],
        [-2.0205e+00],
        [-2.0605e+01],
        [-8.5494e+00],
        [ 4.7903e+00],
        [ 1.1487e+01],
        [ 1.1594e+01],
        [-5.3732e+00],
        [-1.9455e+01],
        [-1.1178e+00],
        [ 1.2627e+01],
        [-6.6981e+00],
        [-7.8605e-01],
        [ 8.5461e+00],
        [-2.4178e+00],
        [ 4.3262e+00],
        [ 1.3028e+00],
        [ 8.1208e+00],
        [-1.7924e+01],
        [-5.0578e+00],
        [-2.1084e-01],
        [-5.6220e+00],
        [-1.6136e+01],
        [-1.0784e+01],
        [ 6.9502e+00],
        [-1.5288e+01],
        [ 1.5025e+01],
        [-2.1972e+00],
        [ 1.1467e+01],
        [-8.7266e-01],
        [-1.4306e+00],
        [ 1.7431e+01],
        [ 5.3244e+00],
        [-4.0498e+00],
        [ 1.8838e+00],
        [ 1.6667e+01],
        [-4.6826e+00],
        [ 1.7874e+01],
        [ 4.0026e+00],
        [ 4.5720e+00],
        [-1.2044e+01],
        [-1.2623e+01],
        [ 5.1393e+00],
        [ 2.6819e+00],
        [-5.4750e+00],
        [ 1.1202e+01],
        [ 3.8905e+00],
        [-4.5581e+00],
        [-3.2600e+00],
        [ 3.6714e+00],
        [ 5.3689e+00],
        [-9.5837e+00],
        [ 3.1869e+00],
        [ 5.9627e-01],
        [ 2.4230e+00],
        [ 5.5551e+00],
        [ 9.0766e+00],
        [ 1.0988e+01],
        [ 4.2885e+00],
        [-1.6818e+01],
        [-7.8772e+00],
        [-4.1539e+00],
        [-8.9554e-01],
        [ 7.1915e+00],
        [ 3.2761e+00],
        [-5.7907e+00],
        [-1.8573e+00],
        [ 1.7160e+01],
        [ 1.3554e+01],
        [ 1.6178e+01],
        [-3.5269e+00],
        [-9.6960e+00],
        [ 3.7690e+00],
        [ 2.2641e+00],
        [-5.0958e-01],
        [ 2.9407e+00],
        [ 3.8234e+00],
        [-1.0145e+01],
        [ 5.4235e+00],
        [ 9.4533e+00],
        [ 6.7432e+00],
        [-3.8801e+00],
        [-1.0554e+00],
        [ 7.0317e+00],
        [-1.4958e+01],
        [-8.5559e+00],
        [-3.1603e+00],
        [-6.9255e+00],
        [ 2.2713e+01],
        [-2.8761e+00],
        [ 1.2754e+01],
        [ 6.8708e+00],
        [ 1.0746e+01],
        [-1.6486e+01],
        [ 1.5388e+01],
        [ 2.2326e+01],
        [-1.0273e+01],
        [ 1.5587e+00],
        [-1.0789e+01],
        [ 5.2611e-01],
        [ 1.6329e+01],
        [-6.0354e-01],
        [-1.8271e+00],
        [-1.5782e+01],
        [ 9.2197e+00],
        [ 1.1578e+00],
        [ 1.7894e+01],
        [-1.5503e+01],
        [-9.3087e+00],
        [-4.3471e+00],
        [ 8.0997e+00],
        [ 3.6255e+00],
        [ 3.8660e+00],
        [ 1.1965e+00],
        [ 2.5522e-01],
        [-3.8319e+00],
        [-1.4275e+01],
        [ 8.2541e-02],
        [ 9.4288e+00],
        [ 1.6345e+01],
        [ 3.9220e+00],
        [-6.9467e+00],
        [-5.8849e+00],
        [ 6.1136e+00],
        [ 1.3535e+01],
        [-1.6813e+01],
        [-4.5555e+00],
        [ 1.1522e+00],
        [-4.6617e+00],
        [-8.8988e+00],
        [-1.0370e+00],
        [ 3.0792e+00],
        [ 6.1821e+00],
        [ 1.6708e+01],
        [ 1.9058e+01],
        [ 8.0220e+00],
        [ 9.5400e-02],
        [-9.3251e+00],
        [-5.8022e+00],
        [ 7.8550e+00],
        [-1.3265e+01],
        [-7.8494e+00],
        [ 1.1426e+01],
        [-5.4308e+00],
        [-5.6641e+00],
        [ 1.0678e+01],
        [ 4.5215e+00],
        [-5.1097e+00],
        [-3.8691e+00],
        [ 2.4182e+00],
        [ 5.2217e+00],
        [-1.7756e+00],
        [-7.6923e+00],
        [-1.6360e+00],
        [-1.3164e+00],
        [-5.7089e+00],
        [ 9.7840e+00],
        [ 2.2315e+01],
        [ 1.5178e+01],
        [-5.9711e+00],
        [ 8.9128e+00],
        [ 4.3597e+00],
        [-1.0346e+01],
        [ 1.1705e+01],
        [-3.3540e+00],
        [-5.3673e-01],
        [ 8.4695e+00],
        [-6.0508e+00],
        [-1.8910e+00],
        [-1.0455e+00],
        [-8.5739e+00],
        [ 3.8197e+00],
        [-6.6116e+00],
        [ 1.0789e+00],
        [ 8.9198e+00],
        [-1.6065e+00],
        [-3.3332e+00],
        [-8.7360e+00],
        [ 9.4247e+00],
        [-4.8249e+00],
        [ 1.2577e+01],
        [-1.1112e+01],
        [-1.4791e+00],
        [ 4.3955e+00],
        [ 2.3452e-01],
        [ 1.1087e+01],
        [-2.1163e+01],
        [-1.0415e+00],
        [-1.7496e+01],
        [-1.0873e+01],
        [-8.9006e+00],
        [ 2.0463e+00],
        [ 4.4523e+00],
        [-8.8545e+00],
        [ 5.1986e+00],
        [-5.1152e+00],
        [-5.1640e+00],
        [-3.1590e+00],
        [-4.7860e+00],
        [ 3.1248e+00],
        [ 7.4784e-01],
        [-1.5630e+01],
        [ 5.5032e+00],
        [ 5.3759e+00],
        [ 9.5219e+00],
        [-1.7058e+01],
        [ 7.3640e+00],
        [ 7.7803e+00],
        [ 2.4378e+00],
        [-1.6286e+01],
        [-1.2049e+01],
        [-1.0294e+01],
        [ 2.1038e+00],
        [ 6.6232e+00],
        [-2.5714e+00],
        [ 7.9361e+00],
        [-5.7454e+00],
        [-3.1157e+00],
        [-7.5024e+00],
        [-7.5300e-01],
        [-2.9291e+00],
        [-2.8095e+00],
        [-7.1585e+00],
        [ 9.3393e+00],
        [-1.6651e+00],
        [-6.6159e+00],
        [ 1.6263e+01],
        [ 4.1033e+00],
        [ 3.1551e+00],
        [ 1.4439e+01],
        [ 6.6094e+00],
        [ 1.4212e+01],
        [ 1.9677e+00],
        [ 3.6701e+00],
        [-6.5956e+00],
        [-1.5389e+01],
        [ 1.0764e+01],
        [-1.7099e+01],
        [ 1.1986e+01],
        [-3.4202e+00],
        [ 7.8211e+00],
        [ 1.8427e+01],
        [-3.3788e+00],
        [ 2.6333e+01],
        [ 4.1018e-02],
        [-1.3382e+01],
        [-1.0414e+00],
        [-5.9897e+00],
        [-1.5315e+01],
        [ 6.1298e-01],
        [ 2.8076e+00],
        [-7.6802e+00],
        [-2.3718e+00],
        [ 7.1240e+00],
        [-2.5943e+00],
        [ 1.1720e+00],
        [-9.3614e+00],
        [-7.0262e-01],
        [ 5.7947e+00],
        [ 1.5823e+01],
        [-1.6545e+01],
        [-1.3300e+01],
        [-6.5497e+00],
        [ 2.3450e+01],
        [ 4.0606e+00],
        [ 1.1659e+01],
        [ 4.0231e+00],
        [-4.0293e+00],
        [-1.3050e+01],
        [ 3.8019e+00],
        [ 1.5583e+01],
        [ 4.6475e+00],
        [-1.0944e+01],
        [ 7.8274e+00],
        [ 1.5462e+00],
        [-1.3279e+01],
        [-7.2370e+00],
        [-2.0421e-01],
        [-1.4326e+01],
        [-5.3828e+00],
        [ 2.3781e+00],
        [ 1.1524e+00],
        [ 6.0502e+00],
        [-3.8046e+00],
        [-6.9444e-01],
        [-2.3763e+00],
        [-1.7258e-01],
        [-9.2203e+00],
        [ 1.1137e+00],
        [-1.0297e+00],
        [ 2.1662e+01],
        [ 1.1103e-01],
        [-2.5606e+00],
        [-1.0130e+01],
        [-8.9641e+00],
        [-1.3578e+01],
        [ 4.0078e+00],
        [-1.8247e+01],
        [-7.9860e+00],
        [ 1.4038e+00],
        [-3.8171e+00],
        [-1.6403e+01],
        [ 6.7899e+00],
        [-8.7919e+00],
        [ 1.3070e+01],
        [-3.3216e+00],
        [ 9.3580e-01],
        [-3.8850e+00],
        [ 1.3622e+01],
        [ 4.8319e+00],
        [ 9.8200e+00],
        [ 7.3860e+00],
        [ 6.2309e-01],
        [ 6.2568e+00],
        [ 3.7315e+00],
        [ 2.3774e+00],
        [-4.0296e+00],
        [-9.1124e+00],
        [-1.0743e-01],
        [-1.1802e+01],
        [ 1.7017e+00],
        [ 1.2513e+01],
        [-1.6403e+00],
        [ 1.4720e+01],
        [ 3.9322e+00],
        [-3.2319e+00],
        [-7.3124e+00],
        [ 1.0335e+01],
        [ 1.2674e+01],
        [-3.4764e+00],
        [ 6.7938e+00],
        [ 7.6835e+00],
        [-8.8332e+00],
        [ 6.1106e-01],
        [-2.4384e+00],
        [ 4.0648e+00],
        [-3.9672e+00],
        [ 6.8879e+00],
        [-6.0390e+00],
        [-5.3024e+00],
        [ 5.6554e-01],
        [-9.7571e+00],
        [ 3.3397e+00],
        [-2.0654e+00],
        [-1.5909e+01],
        [ 1.2637e+01],
        [ 1.0226e+01],
        [-5.5348e+00],
        [-6.0141e+00],
        [ 7.9674e+00],
        [ 5.8875e+00],
        [-7.1679e+00],
        [-1.6550e+01],
        [-1.0839e+00],
        [-2.3396e+00],
        [ 1.2622e+00],
        [-4.7899e+00],
        [ 1.4466e+01],
        [ 1.5726e+01],
        [ 9.1676e+00],
        [ 4.9845e+00],
        [ 1.2665e+01],
        [-6.7842e+00],
        [-3.9936e+00],
        [-4.5813e-01],
        [ 1.2865e+01],
        [ 5.7392e-01],
        [-1.2138e+00],
        [-1.6276e+00],
        [-7.3023e+00],
        [ 7.2966e+00],
        [-5.0655e+00],
        [ 6.6571e+00],
        [-6.2894e+00],
        [-6.2528e+00],
        [-2.7409e-01],
        [ 3.6076e+00],
        [ 8.2770e+00],
        [ 6.9826e+00],
        [ 9.8638e+00],
        [-9.8242e+00],
        [-7.1123e+00],
        [ 2.2055e+00],
        [-2.4453e-02],
        [-1.2624e+01],
        [ 1.6324e+01],
        [-9.1179e+00],
        [ 1.0534e+01],
        [-1.0111e+01],
        [ 8.8649e+00],
        [-6.8159e+00],
        [-4.6394e+00],
        [-6.3249e+00],
        [-6.6737e+00],
        [ 4.5508e+00],
        [ 2.9619e+00],
        [ 7.1363e+00],
        [ 2.0163e+01],
        [-2.7173e-01],
        [-1.5341e+00],
        [ 6.0637e+00],
        [ 1.3082e+01],
        [-1.3342e+01],
        [ 1.2355e+01],
        [ 1.2037e+00],
        [ 5.8349e+00],
        [-3.1424e+00],
        [-1.4305e+01],
        [-1.3144e+01],
        [-6.3137e+00],
        [ 2.0801e+00],
        [ 3.0160e+00],
        [-1.1206e+01],
        [ 1.5415e+01],
        [ 1.4258e+01],
        [ 1.4462e+01],
        [ 4.4143e+00],
        [-2.0364e+01],
        [ 8.0359e+00],
        [-7.3207e+00],
        [-1.0058e+01],
        [ 1.0665e+01],
        [ 1.7138e+01],
        [ 1.7801e+00],
        [ 6.1789e+00],
        [-1.3780e-01],
        [-5.4351e+00],
        [-6.0151e+00],
        [ 1.4705e+00],
        [ 1.2788e+01],
        [-2.5124e+00],
        [-1.2240e+01],
        [ 4.3345e-01],
        [-1.7753e+01],
        [-1.9896e+01],
        [ 5.5533e+00],
        [ 5.9608e+00],
        [ 1.5460e+00],
        [-3.9369e+00],
        [-1.9016e+01],
        [ 6.3280e-01],
        [ 6.9499e+00],
        [ 5.9574e+00],
        [-8.2392e+00],
        [ 1.2694e+00],
        [ 5.6866e+00],
        [-1.0117e+01],
        [-4.6038e+00],
        [-7.4957e+00],
        [-7.6207e+00],
        [ 3.1470e+00],
        [-8.2484e+00],
        [-1.8288e+01],
        [ 1.2056e+01],
        [-1.7958e-01],
        [ 1.4818e+01],
        [ 1.4768e+01],
        [-1.0451e+01],
        [-1.7406e+01],
        [-5.4885e+00],
        [-2.6316e+00],
        [ 9.1704e+00],
        [-2.9556e+00],
        [-3.2273e-01],
        [-2.9045e+00],
        [-1.4561e+01],
        [-4.4046e+00],
        [-5.3042e+00],
        [-8.9562e+00],
        [-8.1144e+00],
        [-7.0933e+00],
        [ 1.0444e+01],
        [ 1.1275e+00],
        [-1.4127e+00],
        [-1.0676e+01],
        [ 6.2949e+00],
        [-1.4385e+01],
        [ 5.5193e+00],
        [-1.3526e+00],
        [-2.0032e+00],
        [ 5.0815e+00],
        [-6.2622e+00],
        [-8.8523e+00],
        [ 3.7703e+00],
        [-9.4363e+00],
        [ 1.2861e+01],
        [-1.3774e+00],
        [ 2.3736e+00],
        [ 1.4879e+01],
        [-1.5852e+01],
        [-1.7112e+01],
        [ 1.8210e+01],
        [-6.7163e+00],
        [-1.4115e+00],
        [-7.3057e+00],
        [-1.0433e+01],
        [ 5.9520e+00],
        [-2.5395e-01],
        [-6.5805e+00],
        [-1.3395e+01],
        [ 7.6093e+00],
        [ 4.2859e+00],
        [-9.8802e+00],
        [-1.3578e+01],
        [ 8.2680e+00],
        [ 7.0140e-01],
        [-2.0447e+01],
        [ 2.5868e+00],
        [-3.9373e+00],
        [-4.9498e+00],
        [-6.6028e-01],
        [-4.5801e+00],
        [ 3.9203e+00],
        [ 2.7717e+00],
        [ 4.5711e+00],
        [ 1.3680e+00],
        [ 1.3146e+01],
        [ 3.2233e+00],
        [-9.2227e-01],
        [ 1.8701e+01],
        [ 2.6100e+00],
        [-2.4140e+00],
        [-1.0373e+01],
        [ 4.3691e-01],
        [-2.5290e+00],
        [ 1.1237e+01],
        [-6.4672e-01],
        [ 1.4641e+00],
        [-1.1349e+01],
        [-5.0994e+00],
        [ 1.2534e+01],
        [ 5.6983e+00],
        [ 1.1055e+01],
        [-7.0925e+00],
        [ 1.2283e+01],
        [-3.3914e+00],
        [ 4.6003e+00],
        [ 1.1488e+00],
        [-3.1999e+00],
        [-2.8806e+00],
        [-9.9585e+00],
        [ 7.4373e+00],
        [ 8.3182e+00],
        [ 1.8660e+00],
        [-2.9213e+00],
        [ 4.0631e+00],
        [ 1.1787e+00],
        [-1.1796e+01],
        [ 1.6210e+01],
        [ 3.4187e+00],
        [ 7.7510e+00],
        [-8.0691e+00],
        [ 7.3551e+00],
        [-2.2371e+00],
        [ 1.8183e+01],
        [-2.9689e+00],
        [-1.4115e+00],
        [ 1.3646e+01],
        [-8.5182e+00],
        [-9.8893e-01],
        [-2.1480e+00],
        [ 1.0651e+01],
        [ 3.4559e-02],
        [-8.6596e+00],
        [-2.7413e+00],
        [ 1.6889e+00],
        [-9.1526e+00],
        [ 1.7806e+01],
        [ 2.3717e+00],
        [-5.8722e+00],
        [-6.4052e+00],
        [-9.0790e+00],
        [-9.7144e+00],
        [-7.3080e+00],
        [-8.9922e+00],
        [-2.2279e+00],
        [-2.3571e+00],
        [ 5.2246e+00],
        [ 3.8254e+00],
        [-5.2909e+00],
        [ 2.2534e+00],
        [-5.9210e-01],
        [ 2.2568e+00],
        [-3.7052e+00],
        [ 8.3536e+00],
        [ 3.4417e+00],
        [-1.7387e+01],
        [ 1.2048e+01],
        [ 9.7529e-01],
        [ 2.4789e+00],
        [-6.1201e-01],
        [ 2.2536e+00],
        [ 6.2048e-01],
        [ 3.4180e-01],
        [ 9.7910e+00],
        [-4.6170e+00],
        [-5.8161e+00],
        [ 1.5846e+00],
        [ 4.8338e+00],
        [ 1.8128e+01],
        [ 8.4109e+00],
        [ 1.6111e+01],
        [ 5.6840e+00],
        [ 1.7564e+01],
        [-9.7985e+00],
        [ 4.8988e+00],
        [-1.0808e+01],
        [ 1.5325e+01],
        [ 1.1393e+01],
        [ 1.4031e+01],
        [-1.2831e+00],
        [-2.1170e+01],
        [ 5.6114e-01],
        [-2.7366e+00],
        [-1.1045e+00],
        [-3.9873e+00],
        [ 7.9144e+00],
        [-1.0021e+01],
        [ 1.0567e+01],
        [-2.4909e+00],
        [-5.6724e+00],
        [ 1.0822e+01],
        [ 9.7707e+00],
        [-3.4221e+00],
        [-4.4354e+00],
        [ 3.2076e-01],
        [ 6.8778e+00],
        [-9.4474e+00],
        [-5.1380e+00],
        [-4.0399e+00],
        [ 2.1507e+00],
        [ 2.3051e+00],
        [-1.4842e-01],
        [-6.2472e+00],
        [-6.5243e+00],
        [-1.7825e+00],
        [-3.7574e+00],
        [-1.6185e+01],
        [ 1.4498e+00],
        [-1.0787e+01]], device='cuda:1')
tensor(0.1498, device='cuda:1')
Evaluating out_domain...
tensor([4.9046], device='cuda:1')
tensor([[ 4.1970],
        [66.5863],
        [ 5.9417],
        ...,
        [18.3631],
        [-7.6235],
        [40.2201]], device='cuda:1')
tensor(1.0707, device='cuda:1')
tensor([-20.8558], device='cuda:1')
tensor([[-21.1324],
        [ 32.3027],
        [ 60.1015],
        ...,
        [ 19.5729],
        [ 13.9637],
        [-58.7721]], device='cuda:1')
tensor(0.3688, device='cuda:1')
tensor([-34.8456], device='cuda:1')
tensor([[-34.4709],
        [-43.2303],
        [ 28.9625],
        ...,
        [-39.7270],
        [ 28.0072],
        [ 22.4419]], device='cuda:1')
tensor(2.2126, device='cuda:1')
tensor([27.3472], device='cuda:1')
tensor([[ 27.2177],
        [ 16.7127],
        [ 30.5604],
        ...,
        [-34.7290],
        [ 22.8423],
        [-68.4702]], device='cuda:1')
tensor(0.4763, device='cuda:1')
tensor([10.3079], device='cuda:1')
tensor([[ 10.6109],
        [ 76.0107],
        [ -8.4057],
        [-19.0266],
        [-38.6811],
        [ 45.0725],
        [ -3.2018],
        [ 32.8504],
        [-39.2934],
        [-18.3510],
        [-57.3060],
        [ 42.4290],
        [ 18.0305],
        [-42.1133],
        [  8.2818],
        [-45.1314],
        [-52.0576],
        [-16.5542],
        [-24.5177],
        [-21.2538],
        [-33.2812],
        [ 42.9064],
        [-28.4755],
        [  1.7422],
        [ 26.8601],
        [ 38.8437],
        [-19.9510],
        [-12.9894],
        [ 26.8290],
        [ 58.0455],
        [ 14.5447],
        [-66.0250],
        [ 34.2825],
        [ 31.2418],
        [-34.3889],
        [  9.0486],
        [ 29.6878],
        [-51.5960],
        [ 36.8551],
        [  6.3232],
        [-34.9686],
        [ 44.3305],
        [-64.0756],
        [ 49.6549],
        [ 28.6175],
        [-51.0089],
        [-59.1894],
        [ -6.9372],
        [  7.5907],
        [ 21.4383],
        [-53.7278],
        [-62.8471],
        [ 20.2984],
        [ 19.3980],
        [-32.3697],
        [ 79.6797],
        [-44.4326],
        [-43.5560],
        [ 33.4626],
        [ 11.7595],
        [ 43.9347],
        [ 47.3348],
        [ 15.4690],
        [ 31.0568],
        [ 47.0483],
        [ 11.5914],
        [-45.1266],
        [ 54.7339],
        [-31.4135],
        [ -9.1033],
        [-16.2907],
        [ 45.6516],
        [ -5.2543],
        [ 38.3284],
        [-50.1049],
        [ 51.3527],
        [  8.8561],
        [ 73.1878],
        [-36.0487],
        [-31.8761],
        [-56.7713],
        [-15.7497],
        [-15.3981],
        [-51.4415],
        [-58.6928],
        [-61.7982],
        [ 26.5760],
        [-22.4899],
        [ 17.1618],
        [-15.4371],
        [-33.9790],
        [-13.5005],
        [ 27.0198],
        [ 20.9571],
        [ 28.4391],
        [ 29.9417],
        [ 57.1214],
        [ 29.2739],
        [ 46.1647],
        [-56.5640],
        [-11.9257],
        [-11.1893],
        [-20.9690],
        [ 66.5798],
        [-74.3695],
        [-33.6457],
        [-68.2713],
        [ 11.0509],
        [ -1.5889],
        [-12.3745],
        [-22.5637],
        [ 24.9445],
        [ 32.3277],
        [ 22.8381],
        [-61.2954],
        [ -4.1912],
        [ 26.2865],
        [-17.7014],
        [ 27.1067],
        [ 22.7937],
        [ 24.1534],
        [ -0.8746],
        [ 45.8934],
        [-10.3610],
        [-17.2821],
        [ 25.2356],
        [  6.1596],
        [ 42.1339],
        [ 16.4744],
        [ 54.4602],
        [-21.7453],
        [-25.6377],
        [-70.8839],
        [-12.6634],
        [-13.2811],
        [-31.3066],
        [-20.1063],
        [ 28.2204],
        [-25.5661],
        [ 52.3659],
        [ 56.9295],
        [ -0.6917],
        [ -5.9056],
        [-56.0081],
        [  5.5904],
        [-43.4691],
        [ -5.6049],
        [-23.0335],
        [-45.4118],
        [ 17.1069],
        [-14.0787],
        [ 67.4864],
        [-33.1565],
        [-59.6396],
        [-33.3463],
        [-34.2271],
        [ 69.3969],
        [-12.1913],
        [-49.8453],
        [  4.9761],
        [  4.6021],
        [ 36.0002],
        [-34.8037],
        [ 13.2941],
        [ 15.2425],
        [-15.6362],
        [-40.3142],
        [ 33.7221],
        [-30.5361],
        [-52.9713],
        [ 59.0373],
        [ 38.5460],
        [ -8.7330],
        [ 25.0672],
        [ 31.1250],
        [ 61.1391],
        [-34.6137],
        [ 63.3815],
        [ -3.9226],
        [-22.2546],
        [-49.1602],
        [ -2.2584],
        [ 13.0535],
        [-22.5613],
        [-22.5751],
        [-46.0705],
        [-16.8948],
        [-13.9208],
        [-34.5066],
        [  8.2569],
        [ 60.1410],
        [ 69.7445],
        [ 20.4476],
        [ 64.5084],
        [-61.0145],
        [-55.6538],
        [-19.3742],
        [-38.2154],
        [-38.9411],
        [-17.8330],
        [ 23.0068],
        [ 79.6889],
        [-47.9842],
        [ -4.3732],
        [ 33.7622],
        [-22.8109],
        [ 32.4789],
        [ 28.8732],
        [ 68.6079],
        [-11.5675],
        [ 34.5371],
        [-52.1037],
        [ 58.0461],
        [ 33.7393],
        [-47.1763],
        [-21.1022],
        [ 22.6068],
        [  9.6570],
        [ 25.8332],
        [ 16.5654],
        [-18.4044],
        [-24.2326],
        [-24.4941],
        [-15.7102],
        [-59.1222],
        [ 59.6154],
        [-22.5649],
        [ 13.8659],
        [ 24.0194],
        [ 71.0307],
        [ 12.5369],
        [-16.8567],
        [ 65.4953],
        [ 40.6018],
        [-29.3101],
        [ 31.5520],
        [ 29.9874],
        [ 37.0312],
        [ -2.5533],
        [-39.6238],
        [-23.5016],
        [ 44.2987],
        [-33.2734],
        [ -4.5155],
        [ 37.2539],
        [-28.9074],
        [ 57.3204],
        [ 30.0702],
        [ 57.8289],
        [-18.5909],
        [-22.4787],
        [ 13.2416],
        [ 36.0998],
        [-64.1358],
        [ 22.2093],
        [ 15.3410],
        [ 28.6979],
        [-27.1155],
        [-21.5347],
        [ 75.6982],
        [ 25.9124],
        [-54.2472],
        [-20.5999],
        [ 30.9952],
        [-29.7560],
        [ 25.3534],
        [ 29.2858],
        [ 86.7353],
        [-35.0255],
        [  1.4613],
        [-17.6478],
        [-23.7341],
        [ 11.7902],
        [ 68.8787],
        [-41.4821],
        [-23.1487],
        [ 27.8482],
        [ -0.8505],
        [-26.4673],
        [-23.3158],
        [ 21.6109],
        [-21.0557],
        [ 36.7634],
        [-38.8062],
        [ -6.2282],
        [  5.7074],
        [ 65.8074],
        [ -7.0144],
        [ -5.8396],
        [-25.6431],
        [-38.8711],
        [  8.3490],
        [ 19.5670],
        [  7.8444],
        [-42.0693],
        [-20.4387],
        [ 12.7508],
        [ 26.7691],
        [-17.2967],
        [ 42.3017],
        [-47.4370],
        [-24.5550],
        [ 62.0295],
        [ 70.6521],
        [-31.9934],
        [-63.2833],
        [-61.9725],
        [-53.4933],
        [-13.0350],
        [  4.3549],
        [ 59.8248],
        [ 25.7222],
        [ 18.6719],
        [-57.7537],
        [-42.2819],
        [-59.5660],
        [-35.4141],
        [-54.6477],
        [  7.2419],
        [ 46.7981],
        [-23.1149],
        [ 38.5667],
        [ 37.1783],
        [ -6.2710],
        [ 54.2973],
        [ 57.1163],
        [-11.2031],
        [-19.8770],
        [-42.1302],
        [ 42.5309],
        [ 49.0854],
        [ 20.9559],
        [ 15.1799],
        [ 22.6015],
        [-26.5374],
        [-19.9767],
        [ 47.0682],
        [ 66.2973],
        [-20.7128],
        [ 16.9741],
        [ 41.4698],
        [ -2.1441],
        [ 21.4138],
        [  9.9696],
        [-44.8716],
        [-48.3229],
        [ 67.1404],
        [ 11.1297],
        [ 43.3279],
        [ 77.9998],
        [-18.9976],
        [  3.7453],
        [-53.4348],
        [ 22.8136],
        [ 30.5824],
        [-22.0109],
        [  9.0962],
        [-38.3720],
        [ -7.8753],
        [-21.3189],
        [ -8.6520],
        [ 27.5772],
        [ 36.1295],
        [ 35.0961],
        [-18.4782],
        [-13.5866],
        [ 13.3990],
        [ 67.9816],
        [ 34.2849],
        [-41.0677],
        [ 23.7921],
        [  0.2487],
        [ -0.9453],
        [  6.6022],
        [ 60.8123],
        [-19.3810],
        [ 15.2057],
        [-30.8822],
        [-34.5287],
        [-34.3246],
        [ 13.4776],
        [ 56.6419],
        [ 53.4198],
        [-19.1983],
        [-61.9080],
        [ 43.9507],
        [-44.0218],
        [ 63.5816],
        [ 28.9534],
        [ 25.2778],
        [ 24.1997],
        [ -6.4205],
        [-54.2396],
        [ 30.4589],
        [-19.4289],
        [ 46.7107],
        [ -8.3485],
        [-50.9549],
        [-11.3772],
        [-20.5200],
        [ 16.3573],
        [-19.9805],
        [-10.9827],
        [ 29.7774],
        [ 39.8225],
        [ 17.2695],
        [ 16.1646],
        [ 32.8838],
        [ 40.1209],
        [-43.3587],
        [  3.2729],
        [-25.9935],
        [-34.8397],
        [ -7.9243],
        [ 15.7429],
        [-31.0306],
        [-19.8517],
        [-30.2757],
        [-16.5777],
        [  6.3020],
        [ 66.5819],
        [-29.5361],
        [-22.9962],
        [ 37.5534],
        [-28.4820],
        [ 34.8350],
        [ 73.9543],
        [-42.2930],
        [ 14.0323],
        [-29.3341],
        [ 14.0315],
        [ 16.2605],
        [-25.3501],
        [-38.9191],
        [-45.0883],
        [ 29.9084],
        [ 13.1687],
        [  2.1709],
        [  0.6196],
        [-35.5887],
        [-50.8189],
        [ 35.3608],
        [-45.1991],
        [-60.0958],
        [ 12.9128],
        [ -8.9493],
        [ 36.9315],
        [ 29.9795],
        [ 20.2522],
        [-49.2585],
        [ -7.5331],
        [ 17.7466],
        [ 30.4258],
        [ -8.2360],
        [-31.4987],
        [-22.9628],
        [-52.2443],
        [ 49.5371],
        [-36.2788],
        [-11.4101],
        [ 11.2413],
        [ 16.8135],
        [-48.7067],
        [-21.4009],
        [ 41.4536],
        [ -6.2640],
        [-17.9638],
        [ -5.9446],
        [-20.4426],
        [-54.5821],
        [-41.5850],
        [-30.0412],
        [-22.0697],
        [ 31.4297],
        [-45.0020],
        [-48.1181],
        [ -2.7353],
        [ 74.0663],
        [ 10.6580],
        [-40.6529],
        [ 16.2624],
        [ 15.1938],
        [ 26.2928],
        [-39.1919],
        [-11.1865],
        [ 11.8022],
        [ 28.7661],
        [-10.3733],
        [-37.7484],
        [ 25.6806],
        [ 10.9483],
        [ 23.1395],
        [-46.6368],
        [-60.7813],
        [-34.4319],
        [ -5.3474],
        [-58.5206],
        [-38.3683],
        [-10.4034],
        [-23.6623],
        [ 15.2470],
        [ 29.1359],
        [-31.5870],
        [ 33.4873],
        [-38.7384],
        [ 33.6570],
        [ 26.5640],
        [-57.4686],
        [ 31.0898],
        [-26.0654],
        [ 55.4539],
        [ -1.3892],
        [-32.5646],
        [ 22.5980],
        [ -9.8789],
        [ 35.6159],
        [ 13.6267],
        [-15.6256],
        [-11.1675],
        [-15.0763],
        [-24.3827],
        [ 16.8606],
        [ 30.1704],
        [  8.1244],
        [ 24.8173],
        [ -7.9008],
        [ 13.2452],
        [ -7.9150],
        [ 15.3141],
        [ 60.1172],
        [-25.2759],
        [-27.1746],
        [ 24.0599],
        [ 42.7908],
        [-18.7762],
        [ 18.3733],
        [ 23.4213],
        [ 35.4500],
        [ 30.4874],
        [-31.7707],
        [ -5.3452],
        [ -0.8602],
        [ 46.3518],
        [-59.3430],
        [-53.5093],
        [ -5.4632],
        [-37.4966],
        [-28.0687],
        [ 32.6864],
        [ -1.8165],
        [-61.5447],
        [-41.4189],
        [ 13.2524],
        [ 43.6947],
        [ 26.7985],
        [ 72.4851],
        [-50.8307],
        [ 60.2615],
        [-35.4226],
        [ 42.5841],
        [ 24.5017],
        [ 52.2630],
        [-10.0671],
        [-46.5256],
        [ 46.9974],
        [-33.9627],
        [-39.0249],
        [ 17.7150],
        [ 36.1878],
        [-54.4772],
        [ 21.4096],
        [-38.4393],
        [ -3.8383],
        [-13.4223],
        [ 22.9568],
        [-16.8348],
        [ 18.9773],
        [-48.4818],
        [-22.3489],
        [-39.8282],
        [ 45.9388],
        [-40.3083],
        [ 27.1791],
        [-36.1987],
        [-35.5202],
        [ 43.7915],
        [ 50.4105],
        [ 34.5890],
        [-56.1198],
        [ 50.7332],
        [  9.4404],
        [-50.2269],
        [ 37.1890],
        [-57.4852],
        [  9.2292],
        [ 37.0746],
        [ 20.7072],
        [ 38.1833],
        [-13.1561],
        [-22.4248],
        [ 39.6037],
        [-57.8140],
        [  6.1806],
        [ 22.5404],
        [ -8.7794],
        [-50.1079],
        [ 22.4602],
        [ 13.1985],
        [-12.7569],
        [-52.0543],
        [-51.4936],
        [-38.9359],
        [-36.0903],
        [  7.9981],
        [-22.2466],
        [-15.1515],
        [ 30.1540],
        [  7.6734],
        [ 35.3750],
        [-25.0191],
        [-32.4380],
        [ 59.2936],
        [-27.4810],
        [-16.1857],
        [-13.1843],
        [ 44.8624],
        [  4.3853],
        [ -6.7983],
        [-21.4046],
        [ 23.9295],
        [ 18.0410],
        [-22.7905],
        [  2.2066],
        [-48.0405],
        [ -9.4494],
        [ 67.3769],
        [ 16.7649],
        [-28.1660],
        [ 17.3100],
        [ 26.9292],
        [ 12.2241],
        [ 10.6705],
        [ -0.4961],
        [ 11.0070],
        [-12.9889],
        [ 31.5829],
        [-24.9614],
        [  5.6607],
        [ 22.5706],
        [ 38.7792],
        [-71.1023],
        [-25.4729],
        [ 59.0526],
        [-33.0479],
        [ 51.8065],
        [-25.5784],
        [ 35.4985],
        [-62.4376],
        [-25.3666],
        [ 66.9647],
        [ 68.8364],
        [ 23.8308],
        [ 18.0080],
        [-39.7134],
        [  2.3245],
        [ 24.3512],
        [ 24.0866],
        [-15.7775],
        [ 16.0828],
        [ -6.8854],
        [-62.1122],
        [  2.8427],
        [-43.1079],
        [-17.2962],
        [-33.3235],
        [  0.8341],
        [ 22.9466],
        [ 25.6190],
        [-46.3531],
        [-55.1386],
        [ 42.3122],
        [-27.5122],
        [-29.0543],
        [-34.9572],
        [-60.2640],
        [-41.1609],
        [ 28.4632],
        [ 28.3608],
        [ 30.8909],
        [-32.3542],
        [ 49.1915],
        [  5.3969],
        [ 22.9851],
        [-46.4585],
        [-39.6765],
        [ 18.5870],
        [ -8.7366],
        [ 41.2715],
        [ 39.8882],
        [ 58.7511],
        [-44.8814],
        [-12.7725],
        [ 18.3389],
        [-12.4816],
        [-64.6562],
        [ 41.8835],
        [ 56.5103],
        [-52.0861],
        [ 15.3364],
        [ 20.9823],
        [ -5.4237],
        [ 42.2170],
        [-52.7704],
        [-49.3973],
        [ 54.4399],
        [ -7.2764],
        [  4.7867],
        [-56.1473],
        [-12.1600],
        [-24.4212],
        [-10.8868],
        [ 24.5027],
        [-40.3798],
        [ 26.5932],
        [-61.7797],
        [-57.4457],
        [-43.7290],
        [ 28.9759],
        [-30.2435],
        [-60.7642],
        [ 27.1215],
        [-57.3522],
        [-40.8045],
        [ 16.3189],
        [-41.6269],
        [ -6.4649],
        [-56.5220],
        [-27.7356],
        [ 23.7380],
        [-16.0974],
        [-48.8457],
        [ -2.0518],
        [-17.5268],
        [ 60.6157],
        [-52.6265],
        [-58.5440],
        [-57.8472],
        [ 57.9716],
        [ 32.3428],
        [-57.3918],
        [ 19.1681],
        [ 31.1413],
        [ 39.0540],
        [-42.7128],
        [-45.5914],
        [ 27.4640],
        [-26.1495],
        [-19.2682],
        [-28.8790],
        [-32.6242],
        [-10.6099],
        [ 66.9110],
        [-13.5447],
        [ 35.4400],
        [ 56.8401],
        [-37.6688],
        [-22.7858],
        [-32.9934],
        [-62.5923],
        [ 19.5677],
        [ 47.6318],
        [-49.6317],
        [ -2.9204],
        [ 50.9671],
        [ 37.9857],
        [-33.9264],
        [ 32.7464],
        [ 32.1134],
        [-65.8976],
        [  4.1810],
        [ 61.7765],
        [ 21.5527],
        [-17.0829],
        [-16.3388],
        [-14.1921],
        [-33.4445],
        [  7.3140],
        [ -3.8862],
        [  3.0526],
        [ 46.7118],
        [ 51.4898],
        [-29.9138],
        [-19.4066],
        [-14.7430],
        [ 10.9154],
        [-63.7261],
        [-61.1095],
        [  1.6984],
        [ -8.2897],
        [ 20.4525],
        [-16.8368],
        [ -8.1330],
        [  8.4456],
        [ 18.2530],
        [ 67.1013],
        [-14.9860],
        [ -2.9635],
        [-20.3021],
        [ 27.1099],
        [ 31.9367],
        [  4.6694],
        [-26.1069],
        [-14.3324],
        [ 21.9733],
        [ 21.6087],
        [-51.2251],
        [  8.0244],
        [-74.7815],
        [-54.5238],
        [-11.5810],
        [-27.1499],
        [-44.6942],
        [ 26.3641],
        [ 32.4640],
        [-46.9389],
        [ 60.4277],
        [ 23.1790],
        [ 22.8087],
        [-32.2136],
        [ 10.0300],
        [-21.0222],
        [-23.8053],
        [-45.6110],
        [-10.0653],
        [-48.3477],
        [ 19.5334],
        [-22.7688],
        [ -1.9380],
        [-59.0890],
        [  6.4314],
        [ 40.2374],
        [ 44.6944],
        [-14.0795],
        [-13.5156],
        [-60.9553],
        [ 10.2970],
        [ 23.3161],
        [-61.3708],
        [-19.1327],
        [ 18.8469],
        [-35.1864],
        [ 36.7249],
        [-51.1820],
        [-50.4006],
        [-25.7805],
        [ 31.1087],
        [-35.2551],
        [-35.6850],
        [ 30.7560],
        [-14.5221],
        [  0.8802],
        [-62.9590],
        [ 14.6830],
        [ 37.2126],
        [ 41.6744],
        [-21.4198],
        [ 66.4295],
        [-58.5968],
        [ 21.3365],
        [ 70.5699],
        [ 29.7831],
        [ 19.4873],
        [-43.4380],
        [ 47.0827],
        [-44.7515],
        [-62.2110],
        [ 25.2669],
        [-10.2868],
        [-54.5614],
        [-31.7919],
        [ 27.0599],
        [ -6.3948],
        [  6.5543],
        [-19.6093],
        [-37.2635],
        [-24.7263],
        [  7.8742],
        [-39.7627],
        [-12.3789],
        [-33.9168],
        [ 34.9606],
        [-28.9827],
        [ -4.8876],
        [-16.7666],
        [ 50.4729],
        [ 36.9341],
        [-47.2408],
        [-60.9313],
        [ 56.0796],
        [ 60.2845],
        [  5.6200],
        [-47.4153],
        [  3.8947],
        [-48.8834]], device='cuda:1')
tensor(-1.4909, device='cuda:1')
Eval done in 0:03:30.556024
End time: 2023-07-05 22:57:53.707815
Total time: 9:25:21.183150
