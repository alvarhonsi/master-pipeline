Start time: 2023-07-04 15:12:07.178684
torch.Size([512, 10]) torch.Size([512, 1])
Sequential(
  (0): Linear(in_features=10, out_features=512, bias=True)
  (1): ReLU()
  (2): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
  )
  (3): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
  )
  (4): Linear(in_features=512, out_features=1, bias=True)
)
Settings:
DEVICE: cuda:3 INFERENCE_TYPE: svi OBS_MODEL: homoskedastic_gamma PRIOR_LOC: 0.0 PRIOR_SCALE: 2.0 LIKELIHOOD_SCALE_LOC: 2.0 LIKELIHOOD_SCALE: 1.0 GUIDE_SCALE: 0.001 TRAIN_SIZE: 20000
Initial parameters:
net_guide.net.0.weight.loc torch.Size([512, 10]) Parameter containing:
tensor([[-0.0893,  0.1511, -0.4253,  ...,  0.5217,  0.9820,  0.5329],
        [-0.5293, -0.1542,  0.5146,  ..., -0.3262,  0.5976,  0.4203],
        [ 0.0822, -0.6572, -0.5082,  ..., -1.3251, -0.0549,  0.5119],
        ...,
        [-0.8487,  0.5577, -0.4718,  ...,  0.1299, -1.0409, -0.0842],
        [-0.9015, -0.3136,  0.4363,  ..., -0.8776, -0.7717, -0.0389],
        [-0.7014,  0.0978,  0.8217,  ..., -0.1711, -0.4112, -0.5864]],
       device='cuda:3', requires_grad=True)
net_guide.net.0.weight.scale torch.Size([512, 10]) tensor([[0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        ...,
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]],
       device='cuda:3', grad_fn=<AddBackward0>)
net_guide.net.0.bias.loc torch.Size([512]) Parameter containing:
tensor([-7.2333e-02, -2.7830e-01,  5.9128e-01,  5.9223e-01,  4.4427e-01,
        -1.9578e-01,  1.1779e+00, -3.7048e-01,  4.0886e-01,  1.1689e-01,
        -3.5489e-01, -3.9790e-01, -2.3363e-01, -1.0723e+00,  4.1578e-01,
        -1.2920e-01,  6.6724e-01,  2.6853e-01, -6.2721e-02, -7.7352e-01,
         1.1507e+00,  1.9347e-01, -6.2377e-01, -3.8636e-01, -6.6163e-01,
        -3.7073e-01,  7.2838e-01, -2.7010e-01,  6.0369e-01,  1.1516e+00,
        -7.5062e-01, -9.3938e-01, -1.2968e-01,  8.0618e-01, -8.6488e-01,
        -3.8865e-01,  3.3210e-01, -4.3660e-01,  5.6100e-01, -1.8913e-01,
         3.0834e-01,  3.5804e-01, -4.7287e-01, -4.9849e-01, -5.9912e-01,
        -7.4089e-02,  3.3627e-01, -3.9708e-01, -5.1275e-01,  5.3710e-01,
        -1.9041e-01,  7.2732e-01, -1.6064e+00, -3.3911e-01, -4.5425e-01,
        -4.0070e-02,  2.6195e-01,  4.6130e-01,  7.4140e-01, -2.6487e-01,
        -7.2321e-02, -9.6412e-03, -2.2751e-03,  4.0172e-01, -4.4983e-01,
         7.8020e-01, -5.7563e-01,  8.5567e-02, -6.2372e-01,  5.5986e-01,
         7.8621e-01,  1.4038e-01, -1.9438e-01,  1.6054e+00, -6.3092e-01,
        -1.1192e+00,  4.2847e-02, -2.4911e-01, -6.7292e-01,  5.5868e-01,
        -3.0418e-01,  5.4963e-01, -2.3974e-01,  8.5378e-01,  2.7585e-02,
         4.7267e-01, -6.3637e-01,  1.0609e-01,  3.0161e-01,  6.9179e-01,
        -7.4791e-01, -1.4773e-01, -1.8441e-01,  1.3023e-01,  7.6514e-01,
        -3.1377e-01,  3.5576e-01,  1.0344e+00, -8.5877e-01,  1.6134e-01,
        -1.2584e-02, -2.6220e-01, -5.2854e-02,  8.8892e-01, -1.0935e+00,
        -3.2845e-01,  6.0166e-02,  1.9792e-01, -2.3444e-01,  4.6652e-01,
         3.4724e-01, -9.2573e-01, -1.1134e+00, -1.9985e-01, -6.1244e-01,
         2.9501e-01, -1.2237e+00, -1.0153e+00, -3.3764e-02, -1.0576e+00,
        -1.5188e+00, -3.9633e-01, -3.1133e-01,  7.8978e-01,  6.4659e-01,
        -2.6097e-01,  4.8083e-01, -5.2984e-01, -3.1591e-01,  1.5836e+00,
         2.8096e-01,  1.0531e+00,  4.4885e-01, -1.8324e-01, -2.0732e+00,
         5.3105e-01,  4.0767e-01, -3.4310e-01, -3.2961e-03,  6.4281e-01,
        -1.1716e+00,  1.2851e+00, -7.9885e-01, -3.8781e-01, -5.2183e-01,
         2.3594e-01,  8.8447e-02,  3.2388e-01, -7.0577e-01, -6.4864e-01,
        -5.3330e-01,  6.0376e-01, -1.6340e-01, -3.0429e-01, -1.2300e+00,
        -6.1631e-02, -1.2106e+00,  8.0151e-01, -1.4569e-01,  5.5418e-01,
        -5.3949e-01,  5.0226e-01,  8.3316e-01,  6.6414e-01,  1.3775e-01,
        -1.1040e-01, -8.7359e-01,  1.0927e+00, -3.2920e-01, -3.5941e-01,
         7.1193e-01,  1.0790e+00, -4.1849e-01, -8.7821e-01, -6.5139e-01,
         1.5264e+00, -9.7347e-01,  4.3178e-02,  7.2546e-01, -6.3273e-01,
         1.8052e-01, -3.6828e-02, -4.7494e-01, -1.1963e-01, -3.8688e-01,
        -3.4586e-01, -1.8129e-01, -4.2682e-01, -8.7895e-01, -1.5211e+00,
        -4.1722e-01,  1.3358e+00, -2.7913e-01, -6.4971e-01,  2.2883e-01,
         3.5372e-01, -4.4597e-01,  8.7001e-01, -4.2037e-01, -3.6016e-02,
         7.9964e-01, -2.1412e-01,  6.5276e-01, -1.1905e+00,  2.2685e-01,
        -1.1874e+00, -1.9596e-01, -9.3445e-02,  3.5878e-01, -3.9843e-01,
         1.2057e+00, -1.1495e+00, -5.7509e-01, -4.2157e-02,  6.7324e-01,
        -1.0934e+00, -1.6915e-01,  1.4117e+00, -7.5782e-02, -4.0418e-01,
        -9.2594e-02, -2.1449e-01, -7.5267e-02,  7.2032e-01,  1.3893e+00,
         1.6852e-01,  8.5690e-01, -4.3831e-01,  4.0729e-01,  6.9714e-01,
         5.5214e-01, -8.4307e-01, -1.5655e+00,  7.9929e-02, -3.1569e-02,
        -1.3430e-01,  1.5057e-01,  4.0235e-01,  9.2011e-01,  2.5753e-01,
         3.5445e-01,  5.4806e-01, -8.8800e-01, -7.1795e-01,  6.5229e-01,
        -5.7715e-01,  3.9531e-01,  6.9754e-01,  6.6727e-01, -6.0642e-02,
        -2.8534e-01,  1.5131e-02, -9.1586e-01,  1.8937e-01, -1.5623e+00,
         7.0553e-01, -5.3214e-02, -2.7266e-01,  2.7893e-01, -3.3978e-01,
         1.9512e-01,  3.8184e-01,  2.2488e-01, -3.0283e-02, -4.9717e-01,
         5.2214e-01,  2.6920e-01, -3.9202e-01,  4.4343e-01, -2.3627e-01,
        -5.4543e-02,  4.5488e-01, -1.2170e-01,  2.1705e-01,  5.8701e-01,
         4.8407e-02, -2.3263e-01,  4.5530e-01,  7.1742e-01,  5.8899e-01,
        -1.1719e+00,  7.5991e-02, -9.0382e-01,  4.0196e-01,  2.2063e-01,
         5.0637e-01,  7.6701e-01,  8.3257e-01,  4.4166e-01, -1.0429e+00,
        -2.4168e-04, -5.9548e-01,  1.1921e+00, -2.9437e-01, -4.0655e-01,
        -5.5019e-01,  1.2596e-01,  5.6526e-01,  2.1524e-01, -6.2229e-02,
        -1.7343e-01,  2.5203e-01,  6.8963e-01, -6.2582e-01,  8.9147e-02,
        -1.0819e-01,  2.5569e-02,  1.1874e+00, -1.8692e-01, -6.0051e-02,
        -1.6423e+00,  7.1743e-02, -2.4660e-01, -5.8303e-02, -3.4057e-02,
        -1.2949e+00,  1.3500e+00, -1.8766e-01, -7.1565e-01, -2.3798e-01,
        -3.0990e-01,  2.9696e-01, -2.6223e-02, -9.2013e-01,  1.5397e-01,
        -6.0372e-02,  1.1244e+00, -4.9378e-01, -1.9410e-01, -3.3554e-01,
        -7.5501e-01, -4.8610e-01, -8.2767e-01,  6.2348e-01, -7.4487e-01,
        -1.5865e-01,  2.3452e-01,  1.3936e+00,  3.9029e-01, -1.1516e-01,
        -4.3166e-01,  3.9568e-02,  2.4710e-01,  5.4658e-01,  1.8438e-01,
         2.6648e-01,  2.6914e-01,  3.0439e-01,  1.1347e+00, -9.2216e-01,
        -2.9446e-01,  7.2455e-01,  7.0777e-01, -2.6942e-01, -8.7005e-01,
         1.1464e-01,  1.2804e+00, -6.9863e-01,  1.1850e+00, -7.4482e-01,
         9.6578e-01, -1.4243e+00, -3.5251e-01,  1.1709e-01, -8.8172e-01,
         8.3028e-01,  7.1712e-02,  4.0010e-01, -1.5525e-01,  8.5936e-01,
         8.9244e-01, -5.7238e-01, -1.0051e+00, -1.2120e+00, -2.1394e-01,
        -1.3318e-02, -2.7730e-01, -3.9027e-01, -2.3010e-01, -2.3354e-01,
         2.8084e-01,  2.0710e-01, -3.8065e-01,  4.7050e-02, -6.6335e-01,
         7.4576e-01,  6.4558e-01,  7.0509e-01, -2.2651e-01,  6.6270e-01,
        -3.4263e-01,  7.7974e-01, -3.3437e-01,  4.3595e-02, -1.3349e+00,
        -7.9381e-01, -1.2868e+00,  3.1224e-01,  2.9248e-01, -3.1136e-01,
         3.3955e-02, -2.3224e-01, -5.9156e-01,  7.8230e-01, -3.7439e-01,
         4.5496e-01,  2.7533e-01,  6.7456e-01,  2.1839e-01, -7.6967e-01,
         4.4214e-01,  4.2056e-01,  2.6364e-01,  2.3611e-01,  2.9878e-02,
         9.3781e-01, -7.5213e-01, -3.3782e-01, -3.4233e-01, -1.2909e-01,
        -6.8059e-01,  9.1675e-01,  6.1683e-01,  4.2624e-01, -1.0868e-01,
         4.9280e-01,  1.8157e-01, -1.3273e+00,  7.3725e-02,  7.6268e-01,
        -2.8979e-01, -1.1860e-01, -3.0108e-01,  6.9322e-02, -4.7993e-01,
        -4.0589e-01, -1.0033e+00, -4.3422e-02, -1.0186e+00, -4.5977e-01,
        -2.6789e-01, -1.4410e-01,  1.0215e+00, -3.9449e-01,  2.7582e-01,
         4.9043e-01,  8.8715e-02, -1.4125e+00, -3.8461e-01, -9.9781e-01,
        -6.6862e-01,  1.8791e-01,  7.8406e-02, -6.6983e-01, -1.5416e+00,
        -7.9033e-01, -1.4015e-02, -8.7429e-01, -1.0668e+00, -2.3135e-01,
        -1.5533e+00, -3.8707e-01,  3.3750e-01,  3.0395e-01,  6.3403e-01,
        -4.1312e-01,  4.9945e-01,  1.3238e-01, -5.9920e-02, -1.6046e+00,
        -8.3704e-02,  4.7049e-02,  7.7549e-01, -6.9031e-01,  4.6298e-01,
        -1.6375e-01, -1.5068e-03,  5.1905e-01,  2.5467e-01, -3.9307e-01,
        -5.8855e-02, -9.1028e-02,  1.0039e+00,  9.0064e-01,  8.5076e-01,
         4.0644e-01,  1.4390e+00, -1.1990e+00,  6.0676e-01, -5.4963e-02,
        -1.8231e-01, -4.8436e-01, -4.2604e-02,  5.8347e-01,  6.4045e-02,
         9.0467e-02, -2.1107e-01,  9.8832e-01,  2.1206e-01, -4.6485e-01,
        -2.0797e-01, -5.4036e-01,  4.1524e-01,  6.9835e-01, -1.5284e-01,
         2.9449e-01, -1.1495e-01, -1.5297e-01,  6.7632e-01, -1.1770e+00,
         3.3260e-02,  1.6490e-02], device='cuda:3', requires_grad=True)
net_guide.net.0.bias.scale torch.Size([512]) tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010],
       device='cuda:3', grad_fn=<AddBackward0>)
net_guide.net.2.0.weight.loc torch.Size([512, 512]) Parameter containing:
tensor([[-0.2695,  0.5979, -1.0677,  ..., -1.0531, -0.5521, -0.0482],
        [-0.8514,  0.6629,  0.4158,  ..., -0.2034,  0.2634,  1.0528],
        [-1.2195, -0.3566,  0.5227,  ...,  0.7565, -0.9628, -0.0689],
        ...,
        [ 0.0406, -0.5168, -0.5181,  ..., -0.9291, -1.1571, -0.3827],
        [-0.3841,  1.9650,  0.0881,  ...,  0.4715, -1.3347,  0.6877],
        [ 0.8102, -0.5285,  1.4740,  ...,  0.6189,  0.4587,  0.4859]],
       device='cuda:3', requires_grad=True)
net_guide.net.2.0.weight.scale torch.Size([512, 512]) tensor([[0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        ...,
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]],
       device='cuda:3', grad_fn=<AddBackward0>)
net_guide.net.2.0.bias.loc torch.Size([512]) Parameter containing:
tensor([ 1.0277e+00,  4.5352e-01, -3.6311e-01, -5.9447e-01, -3.1371e-01,
         1.2083e+00,  1.2246e-01,  5.4500e-02, -4.6837e-01, -9.0392e-02,
        -4.7320e-01, -1.3633e+00,  1.1550e-01,  7.2933e-01,  6.3747e-01,
         1.0686e-01,  3.6876e-01,  1.7747e-01,  6.1023e-01,  1.0589e-01,
         1.6059e-02,  1.2902e-01,  3.4326e-01,  1.5485e-01,  5.5155e-01,
        -5.5548e-01,  1.3761e+00,  9.3866e-01,  4.0180e-01, -8.7900e-01,
        -5.6322e-01,  7.6532e-01, -6.5780e-02, -1.2890e+00,  1.2948e+00,
        -4.8515e-01, -1.0855e+00, -4.1727e-01, -3.2692e-01,  8.5069e-01,
         1.2258e-01, -2.7082e-01,  7.1268e-01,  4.0534e-01, -7.6082e-01,
         9.4410e-01, -2.7210e-02,  6.5636e-01, -1.1289e+00, -5.3959e-01,
        -7.3380e-01,  3.2299e-01, -4.9279e-01, -9.4211e-02,  9.9338e-02,
        -3.2765e-01, -1.3291e+00, -4.1118e-01,  7.1732e-01, -1.3040e+00,
        -5.0384e-01, -2.5518e-01, -2.0021e-01,  1.1093e+00,  5.2005e-01,
         1.2242e+00,  9.0595e-02, -4.7968e-01,  4.8369e-01, -1.0652e+00,
        -3.1590e-03,  7.4960e-01,  4.5996e-01,  5.0747e-01,  1.2569e+00,
        -9.7691e-01, -5.3111e-01,  2.1086e-01, -3.5921e-01, -9.4884e-02,
         4.1973e-01,  2.9831e-01, -1.0809e+00,  1.2684e+00, -2.9071e-02,
        -2.7905e-01,  2.9082e-03, -3.1736e-01, -8.8762e-02, -1.4507e-02,
         6.1100e-01,  3.5974e-01,  4.9047e-01, -5.2751e-01, -1.0894e+00,
         1.6963e-01, -3.2690e-01, -1.8414e-01,  6.6896e-01,  1.7734e-01,
        -8.5424e-01, -1.5661e-01,  3.1342e-01, -2.8536e-01, -5.3078e-01,
         3.1383e-02, -2.8386e-01,  1.2679e+00, -3.3550e-01, -8.7797e-01,
        -5.9533e-01,  4.1772e-01,  1.2491e-01,  2.9030e-01, -3.5152e-01,
        -1.0556e+00,  5.7293e-01, -7.2236e-01, -2.2590e-01, -3.0666e-01,
         7.7298e-02, -4.6070e-01,  9.6899e-01, -1.3078e+00,  3.4892e-01,
        -4.1997e-01, -4.8028e-01,  7.6189e-01,  1.0928e+00, -1.8460e-01,
         1.4560e+00, -1.0979e-01, -5.3275e-01,  3.6424e-01,  1.2663e-01,
         8.8232e-02, -2.6239e-01,  1.5539e+00,  3.3974e-02, -2.0129e-01,
        -8.4847e-01,  1.0734e+00, -2.1965e-01,  3.6852e-01, -3.1433e-01,
         3.0727e-01,  1.8984e-01, -7.1414e-01, -6.1570e-02, -9.5119e-02,
        -1.2320e+00,  3.2540e-01,  2.2021e-01, -3.6615e-01,  4.0594e-01,
        -7.4614e-01,  2.3560e-01, -1.7471e+00, -1.2716e+00, -1.8235e-01,
         9.0029e-01,  1.1750e+00, -4.0724e-02,  1.0406e+00,  2.5730e-01,
        -5.4774e-01,  6.7709e-01, -1.6398e-01, -6.7860e-02, -4.4257e-01,
        -2.2213e-01,  5.8118e-01,  6.4773e-01, -6.7630e-02, -7.5455e-01,
         1.1654e+00,  1.2493e+00, -5.0149e-01, -8.7560e-01,  1.1243e+00,
         2.4902e-01, -2.5797e-01,  2.5515e-01, -1.9106e-01,  4.0156e-01,
        -4.2294e-01, -3.9992e-01,  4.3316e-01, -9.2056e-01,  3.4304e-01,
        -3.5887e-01,  5.1335e-02,  5.3987e-01, -6.7253e-01, -6.6573e-01,
         4.2702e-01,  6.6119e-01,  1.7681e-01,  2.2369e-01, -1.8682e+00,
        -7.0731e-01, -8.1702e-01,  3.8476e-01,  3.8358e-01,  1.2010e+00,
        -1.2260e+00, -1.5505e-01,  8.6738e-01,  3.9311e-01,  1.5084e-01,
         2.5200e-01,  3.6864e-01,  3.3361e-01,  1.8913e-01,  4.3978e-01,
         1.3068e-01,  6.1340e-01,  4.2008e-01, -6.9356e-02,  7.5090e-01,
        -1.5817e-01, -1.2674e-01,  1.0095e+00,  5.6557e-01, -1.3391e-01,
        -1.6483e-01, -9.0262e-01,  1.7474e+00, -2.4108e-01,  5.9821e-01,
        -1.5949e-03,  2.8260e-01,  4.8421e-01,  2.9444e-01,  4.4552e-02,
         1.2858e+00,  3.8751e-01,  4.6215e-01,  8.5240e-02, -2.1259e-01,
         9.9930e-01,  2.5746e-01, -1.0960e-01,  8.4552e-01, -5.4063e-01,
        -3.8574e-01, -5.6642e-01, -9.0987e-01, -2.3205e-01, -2.0580e-01,
        -2.9481e-01,  8.9068e-01,  1.0383e+00, -2.8861e-01, -1.5510e+00,
         3.2827e-01, -4.3094e-01,  6.9628e-01,  5.9100e-02,  2.4046e-01,
         5.4077e-01, -4.9028e-01, -5.1988e-01, -8.1886e-01,  1.2362e+00,
        -1.2834e-01,  2.9578e-01,  9.9963e-01,  1.1707e+00,  4.2134e-01,
        -1.5039e-01, -4.1978e-01, -1.2781e-01, -9.2630e-01,  4.9168e-01,
        -1.2387e+00,  3.8646e-02,  1.1439e+00, -5.9204e-01, -1.1374e-01,
        -9.6027e-01, -5.8668e-02,  9.8512e-02, -8.5687e-01,  2.8430e-01,
        -3.9256e-01, -1.1271e+00,  4.7541e-01, -3.9009e-01, -1.2189e-01,
         1.7358e+00,  3.1458e-01, -6.6906e-01,  8.5210e-02,  6.9542e-01,
         4.5788e-01,  1.7974e-01,  4.6948e-01,  7.4298e-01, -5.0694e-01,
         2.5784e-01, -7.4076e-01,  1.3744e-01, -5.6952e-01,  7.3465e-01,
        -2.9556e-01,  7.1509e-01,  1.0354e-01, -2.4931e-01,  2.9788e-02,
        -1.1535e-02, -9.5114e-01, -1.0371e+00,  2.0799e-01,  1.6227e-01,
         1.0616e+00, -9.6596e-01,  5.2433e-01,  2.3416e-01, -4.5310e-02,
         6.4829e-01,  6.4670e-01, -6.4974e-01, -7.2904e-01,  9.8557e-01,
         5.4192e-01, -5.1964e-01, -4.0233e-01, -4.8241e-01, -2.2851e-01,
        -1.4066e-01, -7.6253e-01, -7.6408e-01, -2.9033e-01, -6.3269e-01,
         4.9831e-01,  4.2654e-01, -5.3240e-01, -3.4576e-01,  4.3122e-02,
         5.4394e-01, -2.6295e-01,  1.7072e-01, -5.0939e-01,  3.9836e-01,
        -1.6526e-01, -6.5884e-01,  8.2126e-01, -4.4127e-01,  2.8993e-01,
         3.9533e-01, -2.4813e-01, -3.0813e-01, -1.0941e+00,  1.5561e-01,
        -9.2862e-01, -2.8863e-01,  1.9450e-01,  1.2103e+00, -1.1008e+00,
        -4.3830e-01, -4.7240e-01,  1.3059e-01,  1.7771e+00,  2.4100e-01,
        -5.7219e-01,  3.3444e-01,  9.2683e-01,  1.8802e-02, -1.9266e-01,
        -6.7272e-01,  8.3581e-01,  2.9454e-01,  9.0082e-01, -8.6592e-01,
        -6.6912e-02,  1.3618e-01, -3.8682e-01, -4.5189e-01,  3.0051e-01,
        -3.8466e-01, -4.6142e-02, -3.1518e-01,  4.8823e-01, -2.9865e-01,
        -1.5735e-01, -1.0379e+00, -3.6549e-01, -7.3304e-01,  7.9642e-01,
        -2.2616e-03,  2.2153e-01,  2.2544e-01,  2.8494e-01, -5.1180e-01,
        -5.2847e-01, -6.3965e-01,  1.0822e+00,  8.5451e-01,  8.5859e-02,
        -2.8986e-01,  8.0137e-01, -3.1769e-01, -9.1063e-01, -7.2868e-01,
        -5.2512e-01, -3.8628e-01, -6.1951e-01,  4.3893e-01,  2.5053e+00,
         9.2879e-02,  1.0949e-01, -8.6634e-02,  7.5235e-01, -7.4154e-01,
        -4.0894e-01, -2.4766e-01,  4.1384e-01,  2.7213e-01,  3.9032e-01,
         4.4550e-01,  3.4961e-01,  6.5877e-01, -1.0258e-01, -1.5435e+00,
        -5.4586e-01,  6.5072e-01, -2.5828e-01,  1.6796e-01,  7.2616e-02,
        -6.4731e-02, -5.8908e-01,  6.6714e-01, -2.0647e-01,  4.0377e-01,
         5.0205e-02,  8.5155e-01, -6.3768e-01,  8.1282e-01,  1.6323e-02,
         7.7944e-01, -3.0505e-01,  1.3162e+00, -6.1001e-01,  2.3408e-01,
        -6.9762e-01,  2.2105e-02, -6.1819e-01, -1.5451e-01,  7.3346e-01,
        -1.5313e-01,  1.8217e-02, -3.4658e-01,  5.2618e-01,  1.7947e-01,
        -9.0660e-01,  3.1140e-02, -9.6565e-01,  8.1622e-02, -6.4850e-02,
        -6.1105e-01,  1.9328e-01, -3.7598e-02,  3.5554e-02,  1.4601e+00,
         2.8196e-01,  2.0101e-01, -2.1412e-01, -3.4272e-01,  4.1837e-01,
         5.8986e-01, -1.7386e+00, -1.6904e-01, -9.3220e-01,  9.3762e-01,
         5.6714e-01,  5.8246e-01,  1.1258e+00, -1.5287e+00,  1.9825e-01,
        -3.1477e-01,  8.1812e-01,  3.1990e-01, -7.6725e-01,  2.8155e-02,
         4.3831e-01,  4.1449e-01, -2.1697e-01, -8.7664e-01, -8.7771e-01,
        -4.9194e-02,  6.1369e-01, -9.7765e-01, -8.9212e-02, -1.6649e+00,
        -6.0008e-01,  7.2375e-01, -3.7768e-01,  2.2996e-01, -4.4700e-01,
         3.6928e-01, -1.0119e-01,  7.5185e-01, -3.2913e-01,  1.9614e-01,
         5.3570e-01,  4.3309e-01,  4.8271e-01, -9.5943e-01,  3.8544e-01,
         3.4700e-01, -8.3223e-01], device='cuda:3', requires_grad=True)
net_guide.net.2.0.bias.scale torch.Size([512]) tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010],
       device='cuda:3', grad_fn=<AddBackward0>)
net_guide.net.3.0.weight.loc torch.Size([512, 512]) Parameter containing:
tensor([[-0.3461, -0.4554, -0.2617,  ..., -0.0127,  0.1428,  0.0179],
        [-0.6195, -0.7904,  0.2915,  ...,  0.3212, -0.6246,  0.4784],
        [-0.7769,  0.2560, -0.5302,  ..., -0.6548,  0.0761,  1.1731],
        ...,
        [-0.2275,  0.2942, -0.5214,  ..., -0.2118,  0.2479, -0.5496],
        [ 0.2044, -0.0882,  0.9777,  ...,  0.4841, -0.6618, -0.0427],
        [ 0.7446, -0.5091, -1.0720,  ...,  0.0207,  0.5858, -0.8490]],
       device='cuda:3', requires_grad=True)
net_guide.net.3.0.weight.scale torch.Size([512, 512]) tensor([[0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        ...,
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],
        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]],
       device='cuda:3', grad_fn=<AddBackward0>)
net_guide.net.3.0.bias.loc torch.Size([512]) Parameter containing:
tensor([ 2.8358e-01,  6.4421e-01, -1.1329e+00,  5.5712e-01,  8.1560e-01,
        -1.0493e+00, -8.9721e-01,  1.2738e+00,  2.4522e-01,  6.6405e-01,
         2.3702e-01,  7.0332e-01,  8.2000e-01, -1.3483e-01,  1.1507e+00,
         1.9612e-01,  9.4965e-02, -1.9072e-01,  1.1254e-01,  9.9798e-02,
         5.8646e-01,  1.1274e+00,  5.0709e-01, -1.4910e-01, -7.8712e-01,
         3.8624e-01, -8.5977e-03, -1.4125e-01, -3.5718e-01,  8.7591e-01,
        -7.6798e-01,  1.0561e-01, -2.5928e-01,  1.1315e-01, -2.8183e-01,
         3.3979e-01,  1.3491e-01, -6.1493e-01,  8.4045e-01,  6.1552e-01,
        -6.3206e-02,  3.5495e-01,  2.7084e-01, -5.7092e-01,  1.2895e+00,
         4.2698e-02, -1.5715e+00,  9.4798e-02, -3.8291e-02,  1.7232e-03,
         9.3474e-01,  6.0617e-01, -1.7108e-01, -5.1861e-02, -3.5012e-01,
        -6.7260e-01,  3.2992e-01, -4.2320e-01,  1.7775e-01,  1.9497e-01,
         3.5534e-01,  1.7091e+00,  7.5105e-01,  3.4579e-01,  6.3457e-01,
        -2.3919e-01,  1.2701e+00, -7.3402e-01, -6.4913e-01,  8.0801e-01,
         6.4510e-01, -1.2070e+00,  4.3312e-02, -6.2832e-01, -6.8936e-01,
        -6.5677e-01,  2.4487e-01,  4.7142e-01,  1.1872e+00,  4.7151e-01,
         5.8913e-01,  5.1744e-01,  1.1630e+00, -8.8679e-01, -1.0774e+00,
        -4.1604e-01,  9.2920e-01, -5.1883e-01, -3.2739e-01, -7.9985e-01,
        -9.0215e-01,  3.1466e-01,  2.5109e-03,  2.5210e-01,  3.5455e-01,
        -2.1798e-01,  9.2269e-01, -2.3450e-01, -3.6461e-01, -6.1646e-01,
         2.0972e-02,  1.3842e-03, -3.5298e-01,  4.0424e-01, -2.2255e-01,
        -5.8400e-01, -8.6709e-01, -5.2439e-02, -7.8697e-01,  1.5827e-01,
         2.7103e-01, -1.0345e+00, -3.8684e-01, -1.9558e-01,  1.5796e-02,
        -6.2111e-01, -6.8682e-01, -2.7185e-01,  3.9792e-01, -3.5854e-01,
        -1.0952e+00, -4.4397e-01,  8.5220e-01,  1.6487e-01, -4.0346e-01,
         4.8080e-02, -3.6685e-01, -4.3957e-01,  7.1768e-01, -1.5492e+00,
         4.6647e-01,  2.7215e-01, -7.8898e-01,  8.2125e-01, -1.0658e+00,
         2.3593e-01, -7.3321e-01,  1.1956e+00, -5.4822e-01,  1.7556e-01,
         2.9768e-01, -6.0561e-01, -1.2774e+00, -2.3935e-01,  4.9542e-01,
         1.0949e+00, -2.9883e-01,  4.6520e-02,  7.9232e-04, -8.5541e-01,
        -8.0941e-01, -4.0088e-01,  6.5745e-01,  9.3302e-02,  4.8743e-01,
         3.9969e-01,  3.1274e-01, -1.6925e-01,  1.6087e-01,  3.3510e-01,
         4.8344e-01, -1.0242e+00,  3.7521e-01, -4.9322e-01,  3.0034e-01,
        -8.2853e-01,  6.3635e-01, -4.9486e-02, -1.2536e-01,  3.0941e-01,
         2.9869e-01,  4.4067e-01,  2.4284e-01,  4.2562e-01,  1.0462e+00,
         3.4823e-01,  5.5554e-01,  3.9099e-01,  1.0735e+00,  2.3300e-01,
        -2.7831e-01, -1.3944e+00,  1.3776e+00,  5.1806e-01, -2.1703e-01,
         3.0554e-01,  6.4966e-01, -5.9174e-02, -5.0320e-01, -1.6283e-01,
         1.5906e-01, -5.3942e-01,  1.4137e+00, -1.8530e-01, -5.5197e-01,
        -5.6620e-01, -6.0489e-01,  5.0084e-01, -4.1323e-01, -2.6935e-01,
        -7.7464e-01, -6.7722e-01, -5.6216e-01, -6.1732e-01, -1.3472e-01,
         7.1690e-01, -2.2983e-01, -5.2349e-01,  1.5956e+00,  1.3397e-01,
        -7.1951e-01,  8.9661e-01,  4.6523e-01, -7.7719e-01,  6.5862e-01,
        -1.0030e+00,  7.9815e-01,  1.2653e+00,  2.1728e-01,  7.1252e-02,
         9.2303e-01, -8.3202e-01,  4.0252e-01,  5.7802e-01, -5.8099e-01,
         3.1272e-01,  3.0629e-01, -5.3380e-01,  4.1262e-01, -2.4687e-01,
         1.0022e-01, -5.7652e-01, -2.6406e-01, -2.1866e-01, -2.5479e-01,
        -3.2727e-01, -6.5079e-02, -8.2869e-02,  4.1110e-01,  5.5261e-01,
        -2.6257e-01,  3.8837e-01,  4.3061e-01,  6.0928e-01,  2.5106e-01,
        -8.7116e-03,  7.0296e-03,  9.1320e-02, -5.2692e-01, -2.5226e-01,
        -3.2012e-01,  5.0791e-01,  4.7088e-03,  5.5418e-01,  5.4731e-01,
         3.1950e-01, -4.0858e-01,  5.2615e-01,  2.2465e-01, -3.5040e-01,
        -5.8685e-02,  3.9972e-01,  7.4702e-01,  3.6643e-03,  5.6287e-01,
         3.3923e-01,  2.2333e-01, -9.4684e-01,  5.0429e-01,  2.4930e-01,
        -3.5148e-01, -4.6974e-01, -6.5693e-02, -6.7022e-01, -3.2794e-01,
         1.8573e-01,  1.3768e+00, -2.5439e-01,  7.6715e-03, -3.7455e-01,
         2.3194e-01,  2.0907e-01, -5.2308e-01,  4.2403e-01, -9.0445e-01,
         4.0793e-01, -1.2735e+00, -2.0585e-01, -5.4770e-01, -7.9439e-01,
         3.3845e-01,  1.7609e-01,  2.2259e-01, -7.6917e-01, -7.5759e-01,
         1.0234e+00,  8.3058e-01, -7.6347e-01, -2.5876e-01,  6.5356e-01,
         8.8282e-01,  1.1449e+00,  1.1467e+00,  4.5874e-01,  3.4955e-01,
         6.0291e-01,  4.1110e-01, -1.7538e+00,  5.3613e-01,  7.8550e-01,
         7.7179e-02, -6.3889e-01, -1.0601e-01,  2.9268e-02,  2.8805e-01,
        -4.1698e-01,  2.6475e-01,  3.0889e-01, -4.4919e-02,  4.8240e-01,
         2.4056e-01, -3.4557e-01,  8.5602e-01, -1.5230e+00, -4.2205e-01,
         1.2580e+00, -3.2029e-01,  1.0348e-01,  9.5348e-01,  1.0759e-01,
        -3.2309e-01,  2.0562e-01, -1.1493e+00,  4.3184e-01, -2.5317e-01,
         9.6699e-02,  7.0887e-02,  2.2856e-01, -9.1763e-01, -1.8274e-01,
        -1.6077e-01, -1.1378e-01,  1.5783e-01,  3.3778e-02,  1.8892e-01,
        -2.1692e-02,  2.9204e-01,  5.9948e-01, -2.5634e-01,  2.8473e-01,
        -1.0257e+00, -9.0347e-01,  7.4229e-01, -1.2807e-01,  7.8683e-01,
         6.0296e-01, -1.6097e-01, -1.5069e-01, -7.4875e-01, -2.3119e-01,
        -1.5283e+00,  2.3881e-01,  6.5892e-01,  3.2836e-01,  5.0298e-01,
         5.6315e-01, -6.2128e-01, -4.2234e-01, -7.2268e-01, -3.5893e-01,
        -7.6133e-01, -3.6884e-02,  1.0836e+00,  2.1652e-01, -8.4977e-01,
         1.9757e-01, -3.9773e-01, -3.9888e-01, -5.2379e-01,  6.5831e-01,
         5.4264e-01, -5.4214e-01,  3.9443e-01, -6.8726e-02, -6.9472e-01,
         1.5377e+00,  1.5322e+00,  2.6600e-01,  2.0634e-01, -1.9930e-01,
        -3.1773e-01,  6.6759e-01,  2.3633e-01,  1.2218e+00, -1.9796e-01,
         6.4066e-02, -6.4987e-01,  1.2690e+00, -3.7931e-02, -2.1116e-01,
         3.7774e-01,  4.9840e-02, -9.5734e-01,  3.3290e-03,  3.2808e-01,
        -4.2349e-01,  1.0872e+00, -3.9122e-01, -1.2412e+00, -1.0625e+00,
         3.6612e-01,  1.0208e+00,  5.2421e-01,  9.5936e-01,  8.0700e-01,
         3.4014e-01, -1.3024e-01,  6.4890e-02, -4.8995e-01,  7.7922e-02,
         6.7750e-01, -4.7519e-01,  8.3424e-01,  3.2092e-01, -4.8268e-01,
         2.8394e-01, -3.9667e-01,  8.1237e-01,  5.3554e-01,  4.9203e-01,
         1.9318e-01,  4.4595e-02,  9.2419e-01,  7.7851e-01,  3.3007e-01,
         3.2616e-01, -5.5803e-01, -3.5015e-01, -2.1740e-01,  8.3474e-02,
         2.5031e-01, -3.2578e-01,  5.7669e-01, -1.0056e+00,  5.8670e-01,
         1.1519e+00, -4.0732e-01,  9.3527e-02, -5.2625e-01,  9.4711e-01,
        -6.7130e-01,  4.9491e-01, -1.6056e-01,  6.4270e-02, -1.2019e+00,
         9.8734e-01, -6.2289e-01,  5.2020e-01,  1.2680e-01, -2.2133e-02,
        -5.6620e-01, -1.1828e+00,  3.9788e-02, -1.1376e+00,  8.7420e-01,
        -3.7022e-01,  2.8505e-01, -9.5549e-01, -2.0153e-01, -5.0530e-01,
         2.0403e-01, -4.8269e-01, -6.6071e-01,  9.5064e-02,  3.8489e-01,
        -3.8374e-01,  7.1591e-02,  5.6884e-01, -5.8589e-01,  4.6659e-02,
         5.6902e-01, -2.3597e-01,  5.2906e-01,  2.8037e-01, -1.4306e-01,
         2.0320e+00,  4.2144e-01,  3.8793e-01, -2.4331e-01, -1.2848e-01,
        -3.3187e-01,  4.8011e-01, -5.9198e-01, -3.3818e-01,  1.8296e-02,
        -1.0145e-01, -6.2425e-01,  9.7119e-01,  7.9402e-01,  2.5271e-01,
        -1.0614e+00, -1.6053e-01,  7.4006e-01, -7.0434e-01,  1.7492e-01,
         1.0987e+00, -9.9728e-01,  2.0992e-01,  2.8779e-01, -1.4419e+00,
         3.4709e-01, -2.0985e-01], device='cuda:3', requires_grad=True)
net_guide.net.3.0.bias.scale torch.Size([512]) tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010],
       device='cuda:3', grad_fn=<AddBackward0>)
net_guide.net.4.weight.loc torch.Size([1, 512]) Parameter containing:
tensor([[ 1.5140,  0.0142,  0.2779,  1.3334,  0.3424,  0.7123,  1.2452, -0.7783,
          1.0082, -0.3679, -0.6404, -0.3939,  0.3230,  0.1344,  1.3421, -0.7055,
         -0.6282, -0.5764, -1.7743,  0.3579, -0.6126,  0.8826, -2.1209, -0.5902,
         -0.6509, -0.1292,  0.4297, -1.1761, -0.4470, -0.1507,  1.1473, -1.1087,
         -0.0513, -0.3979, -0.8509, -0.2682,  0.0979, -0.7809, -0.5529, -0.7133,
          0.3958,  1.2157, -0.3103, -0.9244,  1.1743, -1.0709, -0.6445, -0.1609,
         -0.6197, -0.0896,  1.4118,  1.2377,  0.5666,  0.4762, -0.5706, -0.3018,
         -0.8101, -0.4087, -0.4458, -0.8846,  0.3871, -0.5512, -1.2544, -0.1126,
          0.0258,  0.1897,  0.1553,  0.1330,  0.0442, -0.3266, -0.5727,  0.6594,
          0.7306,  0.4770, -0.3203,  0.0425,  0.0828,  0.8687, -0.2852,  0.6418,
         -0.2661, -0.1430,  0.3333, -0.3476, -1.1444, -1.1907, -0.0370, -1.2383,
          0.8389,  0.6838,  0.1717,  0.4107,  0.5238, -0.4266, -0.9472,  0.0079,
         -0.6255, -0.7463, -0.5404,  0.2269,  0.5835,  0.5447, -0.4787, -0.0712,
          0.7187, -0.0359, -0.0565,  0.4291,  0.4366,  0.8727, -0.1932,  1.0023,
          0.9476, -0.4601,  0.6753,  1.0364,  0.4925, -0.5669, -0.4091, -0.1316,
          0.8064,  0.4448, -0.5511,  1.6670,  0.5037, -0.4665,  0.0564,  0.0347,
         -0.4534,  0.6505, -0.0998,  0.0911, -0.5479,  0.6239, -0.2151, -0.6684,
          0.4065, -0.6733, -0.4061,  0.3407, -0.2928, -0.6372,  0.2697, -0.5324,
         -0.9949,  0.3702,  0.4614,  0.0250, -0.2684,  1.0057, -0.6882, -0.1667,
         -1.1993,  0.2217,  0.3925,  0.1974, -1.2367,  0.1157,  0.3330,  0.6390,
          0.4452,  0.7231, -1.5733, -0.6707, -0.1488,  0.5124, -0.2494,  0.5298,
         -0.7078, -0.0432,  0.1591,  0.0595, -0.0280,  0.1307,  0.1706, -0.0354,
          0.3522, -0.2223,  0.2582, -0.9014, -0.6901, -0.4789,  0.8869,  0.8209,
         -0.8273, -0.1862, -1.1792,  0.1144, -0.6734, -0.6021,  0.1816, -0.2127,
         -1.1374,  0.3670, -0.3780, -0.1494,  0.4542,  0.3030, -0.1874,  0.0211,
         -1.1958,  1.0241,  0.4453,  0.4789, -0.3592, -1.1192, -0.2952, -0.7208,
          0.1227, -1.2927, -0.5768,  0.0997,  0.0952, -0.2477,  0.0065, -0.3620,
          0.5983, -1.4402, -0.0131,  1.3520,  0.1676, -0.4400,  1.1199, -0.8025,
          0.0158,  0.8675,  0.1536,  1.0466,  0.0102, -0.2047, -0.5495,  0.3197,
         -0.0143,  0.6273,  0.3998, -0.1163,  0.2948, -0.8405,  0.6257, -0.1442,
          0.3600, -1.2868,  0.5590,  0.1927,  0.3350, -0.5010,  1.1891,  0.1763,
         -0.6841, -0.9166,  0.4636, -0.3455,  0.6297, -0.4573, -0.1596, -0.3592,
          0.5118,  0.8884, -0.3797, -0.4741, -1.0978, -0.9629,  0.0869, -0.6338,
          0.9328,  0.0426,  0.1438, -0.1839,  0.0097,  0.1435, -0.4996, -0.3024,
          0.1539, -0.6877,  0.1553, -0.7543,  0.7955, -0.7731,  0.0027,  0.6290,
         -0.5307,  0.6557, -1.1713, -1.2873, -0.6741,  0.5218, -0.0209, -0.0311,
          0.2195,  0.4683,  0.3130,  0.4152,  0.1771, -0.7518, -0.3972,  0.5358,
          0.4368,  0.0374, -0.5219, -0.0969,  0.4641,  0.4240, -0.7592, -0.3197,
         -0.5461, -0.4805, -1.5177, -0.1667,  0.4556,  0.3921,  0.6826, -0.1973,
          0.8346, -0.1246, -1.0334, -1.0480, -0.6389, -0.4565,  0.9348, -0.0511,
         -1.1094,  0.9597, -0.8764, -0.0839, -0.2352,  0.1863, -0.1002,  0.9443,
          1.3330, -0.1723,  1.2960, -0.0890, -0.7570, -0.0588,  0.6344, -0.2284,
          0.1428, -0.3146,  0.1802, -0.7998,  0.5468,  0.6703,  0.2441,  0.2307,
         -0.5889,  0.8234, -0.5115, -0.0543, -0.1057, -0.2286, -0.7396,  0.6038,
         -0.7875, -0.0812,  0.8284, -0.0455,  0.3087,  0.2809,  1.2519, -0.6562,
         -0.2837,  1.2478,  0.1556, -0.4487, -0.4999,  0.1451, -0.8534, -0.8929,
          1.0882, -0.0045, -0.5001,  0.3241, -0.5044,  0.5110, -0.3234, -0.2569,
         -0.0630,  0.2841, -0.2515, -0.0692,  0.0747,  0.4422, -1.2239,  0.2496,
         -0.7783, -0.3953,  0.7999,  0.5303,  0.2777, -0.2162,  1.2199,  0.4935,
         -0.1979,  0.4710,  0.9273, -0.4537,  0.8902, -0.4241, -1.0004, -0.0817,
          0.5072,  0.7537, -1.3419,  0.5512, -0.4452, -0.9790, -1.0950,  0.0348,
          0.8464,  0.7180,  1.3534,  0.7020, -0.1690, -0.1690, -0.8657, -0.4311,
         -0.1662,  0.2815,  0.6930,  0.6322,  0.6513,  0.3633, -0.9673,  0.5389,
         -0.2815, -0.5390,  0.4107,  1.7112, -0.2350, -0.2051,  0.2155,  1.0022,
         -0.6539,  0.4537, -0.3516, -0.5141,  0.1980, -0.8476, -0.4286, -0.8678,
          1.0985,  0.0734, -0.0493,  0.4248,  0.7994, -0.5936, -1.2456,  0.9133,
          0.5379, -1.3622,  0.4243,  0.1771,  0.5248,  0.8673,  0.3198,  0.8649,
          1.1913, -1.0205,  1.7356, -0.7521, -0.7804, -0.4090, -0.2296,  0.2221,
         -0.6576, -0.3000,  1.5000, -1.0286,  0.8194, -0.5274,  0.5322, -0.6642,
          0.3890,  0.1811, -0.1387,  0.4460, -0.1036,  0.0527,  1.4624,  0.0408,
         -0.7673, -0.0471, -0.1947,  0.8558, -0.2134, -0.9208,  0.6301,  0.4775,
          0.1838,  0.6812, -0.4727, -0.7212,  1.0399,  0.2643, -0.5485,  0.3185,
         -0.9968,  0.0873, -0.4661, -0.0517,  0.1074, -0.8505,  0.7510, -0.3667,
         -0.4117, -1.0909,  0.3202, -0.3684, -0.5491, -0.7392, -0.6134,  0.6986]],
       device='cuda:3', requires_grad=True)
net_guide.net.4.weight.scale torch.Size([1, 512]) tensor([[0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,
         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010]],
       device='cuda:3', grad_fn=<AddBackward0>)
net_guide.net.4.bias.loc torch.Size([1]) Parameter containing:
tensor([-0.3343], device='cuda:3', requires_grad=True)
net_guide.net.4.bias.scale torch.Size([1]) tensor([0.0010], device='cuda:3', grad_fn=<AddBackward0>)
likelihood_guide.likelihood._scale.loc torch.Size([]) Parameter containing:
tensor(0.4195, device='cuda:3', requires_grad=True)
likelihood_guide.likelihood._scale.scale torch.Size([]) tensor(0.0010, device='cuda:3', grad_fn=<AddBackward0>)
Using device: cuda:3
===== Training profile tensin-3x512-sl - 1 =====
[0:00:03.733064] epoch: 0 | elbo: 5779943815.679999 | train_rmse: 861.4254 | val_rmse: 853.6079 | val_ll: -6290.0488
[0:03:12.584708] epoch: 50 | elbo: 172904019.28000003 | train_rmse: 212.1458 | val_rmse: 252.7415 | val_ll: -758.8267
[0:06:21.259478] epoch: 100 | elbo: 73072834.58 | train_rmse: 143.1476 | val_rmse: 206.791 | val_ll: -573.488
[0:09:30.496365] epoch: 150 | elbo: 36718810.190000005 | train_rmse: 104.3423 | val_rmse: 184.9854 | val_ll: -491.1919
[0:12:39.842841] epoch: 200 | elbo: 20366158.715000004 | train_rmse: 79.4229 | val_rmse: 172.5356 | val_ll: -451.2154
[0:15:48.288052] epoch: 250 | elbo: 12386471.335000003 | train_rmse: 61.9296 | val_rmse: 165.3123 | val_ll: -427.8344
[0:18:57.543018] epoch: 300 | elbo: 8072006.209999998 | train_rmse: 48.5296 | val_rmse: 159.7026 | val_ll: -395.581
[0:22:05.858836] epoch: 350 | elbo: 5889795.555 | train_rmse: 38.3633 | val_rmse: 156.2142 | val_ll: -363.8901
[0:25:14.550853] epoch: 400 | elbo: 4721251.644999999 | train_rmse: 30.0767 | val_rmse: 153.3324 | val_ll: -319.3695
[0:28:24.820668] epoch: 450 | elbo: 4049906.8724999996 | train_rmse: 23.5955 | val_rmse: 151.0955 | val_ll: -271.4278
[0:31:34.950866] epoch: 500 | elbo: 3682975.4737500013 | train_rmse: 18.2059 | val_rmse: 149.6823 | val_ll: -225.9272
[0:34:46.557767] epoch: 550 | elbo: 3463129.8324999996 | train_rmse: 13.1704 | val_rmse: 148.3235 | val_ll: -178.2486
[0:37:58.111291] epoch: 600 | elbo: 3300551.7612500014 | train_rmse: 9.9346 | val_rmse: 147.6212 | val_ll: -134.003
[0:41:05.899911] epoch: 650 | elbo: 3173581.0962499995 | train_rmse: 7.1862 | val_rmse: 146.7184 | val_ll: -98.8683
[0:44:14.720840] epoch: 700 | elbo: 3068837.11875 | train_rmse: 6.7872 | val_rmse: 145.9887 | val_ll: -71.7503
[0:47:22.719931] epoch: 750 | elbo: 2968687.7625 | train_rmse: 5.4206 | val_rmse: 145.106 | val_ll: -52.2727
[0:50:30.929628] epoch: 800 | elbo: 2869391.90125 | train_rmse: 5.7684 | val_rmse: 144.0736 | val_ll: -36.9527
[0:53:41.870901] epoch: 850 | elbo: 2768309.8074999996 | train_rmse: 5.6855 | val_rmse: 142.6805 | val_ll: -27.0792
[0:56:51.577877] epoch: 900 | elbo: 2667946.1150000007 | train_rmse: 6.0202 | val_rmse: 140.8598 | val_ll: -19.748
[1:00:00.586141] epoch: 950 | elbo: 2568122.204999999 | train_rmse: 9.5236 | val_rmse: 138.7427 | val_ll: -14.8528
[1:03:10.704923] epoch: 1000 | elbo: 2467609.664999999 | train_rmse: 9.067 | val_rmse: 136.1102 | val_ll: -11.6811
[1:06:21.217989] epoch: 1050 | elbo: 2365965.2162499996 | train_rmse: 9.683 | val_rmse: 132.249 | val_ll: -9.5234
